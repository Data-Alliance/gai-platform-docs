{"config":{"lang":["en","ko"],"separator":"[\\s\\-]+","pipeline":[" "],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\uac1c\uc694","text":"<p>\ud6a8\uc728\uc801 GPU \uacf5\uc720 \ud50c\ub7ab\ud3fc</p>"},{"location":"#gcube","title":"gcube \uac00\uc774\ub4dc \ubb38\uc11c\uc5d0 \uc624\uc2e0 \uac83\uc744 \ud658\uc601\ud569\ub2c8\ub2e4!","text":"<p>\uc804 \uc138\uacc4\uc758 \uc720\ud734 GPU\ub97c \uc774\uc6a9\ud574 \uacf5\uae09\uc790 \ucd94\uac00\uc218\uc775\uacfc \uc18c\ube44\uc790\uc758 \ube44\uc6a9\uc808\uac10 \ud61c\ud0dd\uc744 \ub204\ub824\ubcf4\uc138\uc694.</p> <p>\uc774\uc6a9\ud558\uae30 \uc55e\uc11c gcube\ub97c \ucc98\uc74c \uc0ac\uc6a9\ud560 \ub54c \uaf2d \uc54c\uc544\uc57c \ud558\ub294 \ub0b4\uc6a9\uc744 \uc124\uba85\ud574 \ub4dc\ub9b4\uac8c\uc694.</p>"},{"location":"user-guide/node/NVIDIA-graphic-driver-error/","title":"NVIDIA \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc778\uc2dd \uc624\ub958","text":"<p>\ub178\ub4dc \uacf5\uae09 \uc911 \uc0c1\ud0dc\uac00 \ub178\ub4dc \uc0c1\ud0dc\uac00 \uc2e4\ud328\ub85c \ud45c\uae30\ub418\ub294 \uc624\ub958\uac00 \ubc1c\uc0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc774\ub7f0 \ud604\uc0c1\uc740 OS\uc5d0\uc11c \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84\uac00 2\uac1c \uc774\uc0c1 \uad6c\ub3d9\ud558\uace0 \uc788\uc744 \uc2dc \ubc1c\uc0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc608\uc2dc) NVIDIA\uc640 IGPU(amd) \ub450 \uac1c\uc758 \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84\ub97c \uad6c\ub3d9\ud558\uace0 \uc788\uc744 \uc2dc</p> <p>|  |  |</p> <p>gcube\uc5d0\uc11c\ub294 Nvidia \uadf8\ub798\ud53d \uce74\ub4dc\ub9cc \ubc1b\uc544\ub4e4\uc774\uace0 \uc788\uc73c\ubbc0\ub85c \uc774 \uacbd\uc6b0 iGPU(amd)\ub97c \uc0ad\uc81c\ud574\uc57c \ud569\ub2c8\ub2e4.</p> <p>amd \uc81c\uc870\uc0ac \ub4dc\ub77c\uc774\ubc84 \uc0ad\uc81c \uc720\ud2f8\ub9ac\ud2f0(DDU)\ub85c iGPU \ub4dc\ub77c\uc774\ubc84\ub97c \uc0ad\uc81c\ud55c \ub4a4 gcube Agent \uc7ac\uc124\uce58\ub97c \uc9c4\ud589\ud569\ub2c8\ub2e4. </p> <p>\uc774\uc678 \ud574\uacb0 \ubc29\ubc95\uc73c\ub85c Bios\uc5d0\uc11c iGPU \uae30\ub2a5 \uc911\uc9c0, \uc7a5\uce58 \uad00\ub9ac\uc790\uc5d0\uc11c iGPU \uc815\ubcf4 \ud655\uc778 \ud6c4 \uc0ac\uc6a9 \uc911\uc9c0 \ubc0f \ub4dc\ub77c\uc774\ubc84 \uc0ad\uc81c \ub4f1\uc774 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>Nvidia \uc774\uc678\uc758 \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84\ub97c \uc81c\uac70, Agent \uc7ac\uc124\uce58\ub97c \uc9c4\ud589\ud558\uc2e0 \ud6c4 \ub178\ub4dc\ub97c \uc2e4\ud589\ud558\uc2dc\uba74 \uc544\ub798\uc640 \uac19\uc774 \ud45c\uae30\ub418\uba70 \ud574\uacb0\ub429\ub2c8\ub2e4. </p>"},{"location":"user-guide/node/Ubuntu-OS-setup/","title":"Tier 2 Ubuntu OS \uc138\ud305 \uac00\uc774\ub4dc","text":"<p>Ubuntu Server 22.04 LTS \uc774\ubbf8\uc9c0 \ud30c\uc77c \ub2e4\uc6b4\ub85c\ub4dc \ubc0f \ubd80\ud305\ub514\uc2a4\ud06c \uc0dd\uc131  Ubuntu Server 22.04 LTS \ub2e4\uc6b4\ub85c\ub4dc</p> <ul> <li> <p>Ubuntu Server 22.04 LTS \uc2e4\ud589</p> <p></p> </li> <li> <p>\uae30\ubcf8 \uc5b8\uc5b4 \uc120\ud0dd (English)</p> <p></p> </li> <li> <p>Installer Update \uc9c4\ud589\ud558\uc9c0 \uc54a\uc74c</p> <p></p> </li> <li> <p>\ud0a4\ubcf4\ub4dc \uc124\uc815(Korean)</p> <p></p> </li> <li> <p>Ubuntu \uc124\uce58 \ud0c0\uc785 \uc124\uc815</p> <ul> <li>Ubuntu Server \uc124\uce58</li> </ul> <p></p> </li> <li> <p>\uc124\uce58 \uc2dc OS \ub124\ud2b8\uc6cc\ud06c\ub294, \uc678\ubd80 \uc778\ud130\ub137 \uc5f0\uacb0\uc774 \uac00\ub2a5\ud558\ub3c4\ub85d \uc124\uc815 (\ucd5c\uc18c 100Mbps \uc774\uc0c1 \uad8c\uc7a5)</p> <ul> <li>DHCPv4 \uc606 IP\uc8fc\uc18c \ud45c\uc2dc \ud655\uc778 \ud6c4 \uc774\ub3d9</li> </ul> <p></p> </li> <li> <p>\ubbf8\ub7ec \uc11c\ubc84 \uc124\uc815</p> <ul> <li>Mirror Address\uc5d0 \uae30\ubcf8 \uc8fc\uc18c \ub300\uc2e0, http://mirror.kakao.com/ubuntu \ub85c \ubcc0\uacbd</li> </ul> <p></p> </li> <li> <p>\uc2a4\ud1a0\ub9ac\uc9c0 \uc124\uc815</p> <ul> <li>Custom Storage Layout \uc120\ud0dd</li> </ul> <p></p> <ul> <li>free space \u2192 Add GPT Partition \uc120\ud0dd</li> </ul> <p></p> <ul> <li>OS \uc124\uce58\ud558\ub824\ub294 \uc601\uc5ed\uc758 \uacf5\uac04 \uc804\ubd80 \uc0ac\uc6a9<ul> <li>[/boot\uc5d0 2GB\ub97c \uba3c\uc800 \ubc30\uc815]</li> <li>[\ub098\uba38\uc9c0 \uc6a9\ub7c9\uc744 \ubaa8\ub450 /(\ub8e8\ud2b8) \uacf5\uac04\uc5d0 \ubc30\uc815]</li> </ul> </li> </ul> <p></p> </li> <li> <p>\ud504\ub85c\ud544 \uc124\uc815</p> <ul> <li>Ubuntu OS user \uacc4\uc815 ID/PW \uc124\uc815</li> <li>\u203b ID/PW\ub294 \ucd94\ud6c4 Agent \uc124\uce58 \uc2dc \ud544\uc694\ud55c \uc815\ubcf4\uc774\ubbc0\ub85c \ubcc4\ub3c4\ub85c \uc800\uc7a5\ud558\ub294 \uac83\uc744 \ucd94\ucc9c \ub4dc\ub9bd\ub2c8\ub2e4.</li> </ul> <p></p> </li> <li> <p>Ubuntu Pro Upgrade \uc9c4\ud589\ud558\uc9c0 \uc54a\uc74c</p> <p></p> </li> <li> <p>SSH \uc11c\ubc84</p> <ul> <li>OpenSSH server \uc124\uce58 \uccb4\ud06c</li> <li>SSH KEY\ub294 \uc785\ub825\ud558\uc9c0 \uc54a\uc74c</li> </ul> <p></p> </li> <li> <p>\uae30\ud0c0 \uc11c\ubc84 \uc124\uc815</p> <ul> <li>\uae30\ud0c0 \uc11c\ubc84\ub294 \ubbf8\uc124\uce58</li> </ul> <p></p> </li> <li> <p>\uc774\ud6c4 Install \uc9c4\ud589 \ubc0f Install \uc644\ub8cc \uc2dc \uc7ac\ubd80\ud305 \uc9c4\ud589</p> </li> </ul>"},{"location":"user-guide/node/agent-setup/","title":"\uc5d0\uc774\uc804\ud2b8 \uc138\ud305","text":"<p>\uc5d0\uc774\uc804\ud2b8 \uc138\ud305\uc740 \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84\uc758 \uc5c5\ub370\uc774\ud2b8\uc640 VM\uc758 \uc124\uc815\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. </p> <p></p> <p>1. \u201cSetting\u201d \ud074\ub9ad </p> <p></p> <p>2. \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc7ac\uc124\uce58 \ub610\ub294 VM\uc0ad\uc81c \ub4f1\uc758 \uc138\ud305 \uc218\uc815\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/check-agent-node-monitoring/","title":"\uc5d0\uc774\uc804\ud2b8 Node \ubaa8\ub2c8\ud130\ub9c1 \ud655\uc778","text":"<p>\uc5d0\uc774\uc804\ud2b8\uc758 \ubaa8\ub2c8\ud130\ub9c1\uc744 \ud1b5\ud574 \uacf5\uc720 \ud604\ud669\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \u201cMonitoring\u201d \ud074\ub9ad </p> <p></p> <p>2. Node Monitoring \ud654\uba74\uc744 \ud1b5\ud574 \ud604\uc7ac \uacf5\uc720 \uc911\uc778 Node\uc758 GPU, VRAM, CPU, Memory, Disk \uc0ac\uc6a9\ub7c9\uacfc \uc810\uc720\uc728, Network Traffic\ub4f1\uc758 \uc815\ubcf4\ub4e4\uc744 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/check-gpu-sharing-income/","title":"GPU \uacf5\uc720\uc218\uc775 \uc0c1\uc138\ub0b4\uc5ed","text":"<p>\u201c\uc774\uc6a9\uc0c1\uc138\u201d \uc870\ud68c\ub97c \ud1b5\ud574 GPU \uacf5\uc720\ub85c \ubc1c\uc0dd\ud55c \uc218\uc775\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uacf5\uc720 \uc911\uc778 GPU \uc815\ubcf4 \ud654\uba74\uc758 \u201c\uc774\uc6a9\uc0c1\uc138\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud574\uc8fc\uc138\uc694.</p> <p></p> <p>2. \uc218\uc785\ub0b4\uc5ed \ub9ac\uc2a4\ud2b8\ub97c \ud1b5\ud574 \ub0a0\uc9dc\ubcc4\ub85c \ucd5c\uadfc\ub0b4\uc5ed \uc815\ubcf4\ub97c \ud655\uc778 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. 3. \uc138\ubd80\ub0b4\uc5ed \ud655\uc778\uc774 \ud544\uc694\ud560 \uacbd\uc6b0 \uc6b0\uce21\uc758 \u201c\uc138\ubd80\ub0b4\uc5ed\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694.</p> <p></p> <p>4. \uc704\uc5d0 \ud654\uba74\uacfc \uac19\uc774 \uc218\uc785 \uc138\ubd80\ub0b4\uc5ed \uc815\ubcf4\ub97c \uc2dc\uac04 \ubcc4\ub85c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/check-gpu-sharing-info/","title":"GPU \uacf5\uc720 \uc815\ubcf4 \ud655\uc778","text":"<p>\ub178\ub4dc \ud654\uba74\uc5d0\uc11c \ud604\uc7ac \uacf5\uc720 \uc911\uc778 \ub178\ub4dc\uc758 \ud604\ud669\uc744 \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. GPU \uacf5\uc720 \uae30\uae30\uac00 \ud55c \ub300\uc77c \uacbd\uc6b0 \uc704\uc758 \ud654\uba74\uacfc \uac19\uc774 \ub0b4 \uacf5\uc720 \uc815\ubcf4\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. 2. \ub178\ub4dc\uc758 \uc2e4\ud589 \uc0c1\ud0dc\uc640 \ub178\ub4dc\uba85\uc774 \ud45c\uc2dc\ub418\uba70 \ub178\ub4dc\uba85\uc744 \ud074\ub9ad \uc2dc \ub178\ub4dc\uc758 \uc0c1\uc138 \uc815\ubcf4\ub97c \ud655\uc778\ud560 \uc218 \uc788\ub294 \uc0c1\uc138 \ud398\uc774\uc9c0\ub85c \uc774\ub3d9\ud569\ub2c8\ub2e4. 3. GPU \uc2a4\ud399, \uc7a5\uce58 \uc2a4\ud399, \uc2e4\ud589\uc2dc\uac04, \uacf5\uc720\uc0c1\ud0dc(\uc2e4\ud589/\uc911\uc9c0) , \ucd1d \uc218\uc775 , \uae30\ubcf8\ub8cc, \uc0ac\uc6a9\ub8cc, \uc5c5\ub370\uc774\ud2b8 \uc77c\uc2dc \ub4f1\uc758 \uc815\ubcf4\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p></p> <p>4. GPU \uacf5\uc720 \uae30\uae30\uac00 \uc5ec\ub7ec \ub300\uc77c \uacbd\uc6b0 \uc704\uc640 \uac19\uc740 \ud654\uba74\uc73c\ub85c \ud45c\uc2dc\ub418\uba70, \uac01 GPU\ubcc4\ub85c \uc815\ubcf4 \ud655\uc778\uacfc \uae30\ub2a5 \uc2e4\ud589\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p> <p></p> <p>5. GPU \uacf5\uc720 \uae30\uae30\uc758 \uac2f\uc218\uac00 \ub9ce\uc740 \uacbd\uc6b0 \ubaa9\ub85d\ud615 \ubcf4\uae30\ub97c \ud1b5\ud574 \ud55c \ub208\uc5d0 \uc694\uc57d \uc815\ubcf4\ub97c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/check-gpu-sharing-monitoring/","title":"GPU \uacf5\uc720 \ubaa8\ub2c8\ud130\ub9c1 \ud655\uc778","text":"<p>\ub178\ub4dc\ub97c \ud1b5\ud55c GPU \uacf5\uc720\uc758 \ud604\ud669\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  </p> <p></p> <p>1. \uacf5\uc720 \uc911\uc778 GPU \uc815\ubcf4 \ud654\uba74\uc758 \u201c\ubaa8\ub2c8\ud130\ub9c1\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud574\uc8fc\uc138\uc694. </p> <p></p> <p>2. \uc704\uc5d0 \ud654\uba74\uacfc \uac19\uc774 \ub178\ub4dc \ubaa8\ub2c8\ud130\ub9c1 \uc804\uccb4 \uc815\ubcf4\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>3. \u201c\uc2dc\uac04 \ubc94\uc704 \uc120\ud0dd\u201d \ud074\ub9ad \uc2dc \uc774\uc804 \uae30\ub85d\uc744 \uc2dc\uac04\ub300 \ubcc4\ub85c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>4. \u201c\uc0ac\uc6a9\uc790 \uc2dc\uac04 \ubc94\uc704\u201d \ud074\ub9ad \uc2dc \u201c\uc2dc\uc791\uc2dc\uac04\u201d\uacfc \u201c\uc885\ub8cc\uc2dc\uac04\u201d\uc744 \uc124\uc815\ud558\uc5ec \uc6d0\ud558\ub294 \uc2dc\uac04\ub300\uc758 \uc815\ubcf4\ub9cc \ud655\uc778 \uac00\ub2a5\ud569\ub2c8\ub2e4. </p> <p></p> <p>5. \u201c\uc0d8\ud50c\ub9c1 \uac04\uaca9\u201d \ud074\ub9ad \uc2dc \uadf8\ub798\ud504\ub97c \uc2dc\uac04 \ub2e8\uc704\ub85c \uc870\uc808 \uac00\ub2a5\ud569\ub2c8\ub2e4. (\uae30\ubcf8\uac12 10\ubd84, \ucd5c\uc18c 1\ubd84~\ucd5c\ub300 5\uc2dc\uac04 \uc124\uc815 \uac00\ub2a5)</p>"},{"location":"user-guide/node/connect-new-node/","title":"\uc0c8\ub178\ub4dc \uc5f0\uacb0","text":"<p>GPU \uacf5\uc720\ub97c \uc704\ud574\uc11c\ub294 \uc0c8\ub85c\uc6b4 \ub178\ub4dc\ub97c \uc5f0\uacb0\ud574\uc57c \ud569\ub2c8\ub2e4. </p> <p></p> <p>1. Share mode \uc758 \uc88c\uce21\uba54\ub274\uc5d0\uc11c \uc5d0\uc11c \u201c\uc0c8 \ub178\ub4dc \uc5f0\uacb0\u201d \uba54\ub274\ub97c \ud074\ub9ad\ud558\uc138\uc694.</p> <p></p> <p>2. \uc5d0\uc774\uc804\ud2b8 \ud504\ub85c\uadf8\ub7a8\uc744 \ub2e4\uc6b4\ubc1b\uae30 \uc704\ud574 \u201cDownload Program\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694.</p> <p></p> <p>3. \uc5d0\uc774\uc804\ud2b8 \ud504\ub85c\uadf8\ub7a8\uc744 \uc124\uce58\ud574 \uc90d\ub2c8\ub2e4.</p> <p></p> <p>4. \uc5d0\uc774\uc804\ud2b8\ub97c \ub2e4\uc6b4\ub85c\ub4dc \ud6c4 \uc2e4\ud589 \ub4a4 \uc5d0\uc774\uc804\ud2b8 \uc2e4\ud589 \uba54\ub274\uc758 \uc808\ucc28 \uc124\uba85\uc744 \ub530\ub77c \uc124\uce58\ub97c \uc9c4\ud589\ud574\uc8fc\uc138\uc694.</p> <p></p> <p>5. \uc124\uce58\uac00 \uc644\ub8cc\ub418\uba74 \ud654\uba74\uacfc \uac19\uc774 \uc790\ub3d9\uc73c\ub85c \uacf5\uc720\uac00 \uc9c4\ud589\ub429\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/","title":"\ub178\ub4dc \uc0ac\uc6a9\uc790 \uac00\uc774\ub4dc","text":"<p>Home</p> <p>\uc0c8 \ub178\ub4dc \uc5f0\uacb0</p> <p>GPU \uacf5\uc720 \uc911\ub2e8</p> <p>\uc5d0\uc774\uc804\ud2b8 Node \ubaa8\ub2c8\ud130\ub9c1 \ud655\uc778</p> <p>\uc5d0\uc774\uc804\ud2b8 \uc138\ud305</p> <p>GPU \uacf5\uc720 \uc815\ubcf4 \ud655\uc778</p> <p>GPU \uacf5\uc720 \uac00\uaca9 \uc124\uc815</p> <p>GPU \uacf5\uc720\uc218\uc775 \uc0c1\uc138\ub0b4\uc5ed</p> <p>GPU \uacf5\uc720 \ubaa8\ub2c8\ud130\ub9c1 \ud655\uc778</p> <p>\uc5d0\uc774\uc804\ud2b8 \uc0ac\uc6a9 \uc624\ub958 \ud574\uacb0</p> <p>Tier 2 Ubuntu OS \uc138\ud305 \uac00\uc774\ub4dc</p> <p>Tier 2 \ub178\ub4dc \uacf5\uae09\uc790 \uc138\ud305 \uac00\uc774\ub4dc</p> <p>NVIDIA \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc778\uc2dd \uc624\ub958</p>"},{"location":"user-guide/node/node-home/","title":"Home","text":"<p>\u2018\ub300\uc26c\ubcf4\ub4dc\u2019 \ud0ed\uc73c\ub85c \uc774\ub3d9\ud558\uc5ec \ub178\ub4dc \ud074\ub7ec\uc2a4\ud130\uc758 \uc804\uccb4 \ud604\ud669\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p> </p> <p>1. \uc88c\uce21 \uba54\ub274\uc5d0\uc11c \u201cHome\u201d \uba54\ub274\ub97c \ud074\ub9ad\ud558\uba74 \ud3ec\uc778\ud2b8 \ud604\ud669\uacfc \ub178\ub4dc \uac04\ub7b5 \uc815\ubcf4\uc640 \ud604\ud669\ub4e4\uc744 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>2. Home \uc5d0\uc11c\ub294 \uc6b4\uc601\ud558\uace0 \uc788\ub294 \ub178\ub4dc\ub97c \ud1b5\ud55c \ucd1d \uc218\uc775\ub0b4\uc5ed\uacfc \uc815\uc0b0 \ud6c4 \uc794\uc5ec \uc218\uc775\ud3ec\uc778\ud2b8\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c \ub178\ub4dc \uc6b4\uc601\uacfc \uc0ac\uc774\ud2b8 \uc774\uc6a9\uc5d0 \ud544\uc694\ud55c \uc8fc\uc694 \uc54c\ub9bc\uc774 \ud45c\uc2dc\ub418\uc5b4 \uccb4\ud06c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>3. \uc6b4\uc601\uc911\uc778 \ub178\ub4dc\uc758 \ud604\uc7ac \uc6b4\uc601 \uc0c1\ud0dc\ub97c \ud55c \ub208\uc5d0 \ubcfc \uc218 \uc788\uc73c\uba70, \ub178\ub4dc\uba85 \ud074\ub9ad \uc2dc \ub178\ub4dc \uc0c1\uc138\uc815\ubcf4 \ud398\uc774\uc9c0\ub85c \uc774\ub3d9\ud569\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/set-gpu-sharing-pricing/","title":"GPU \uacf5\uc720 \uac00\uaca9 \uc124\uc815","text":"<p>\ub178\ub4dc\uc758 \uac00\uaca9\uc124\uc815\uc744 \ud1b5\ud574 \uae30\ubcf8\uac00\uaca9\uacfc \uc774\uc6a9\ub2e8\uac00\ub97c \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uacf5\uc720 \uc911\uc778 GPU \uc815\ubcf4 \ud654\uba74\uc758 \u201c\uac00\uaca9\uc124\uc815\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud574\uc8fc\uc138\uc694.</p> <p></p> <p>2. \uc704\uc5d0 \ud654\uba74\uacfc \uac19\uc774 \uc774\uc6a9 \ub2e8\uac00 \uc218\uc815\uc774 \uac00\ub2a5\ud55c \ud654\uba74\uc774 \ub098\uc635\ub2c8\ub2e4. \u201c\uc2dc\uac04 \ub2f9 \uc774\uc6a9 \uc694\uae08\u201d \ubd80\ubd84\uc5d0 \uc6d0\ud558\ub294 \uae08\uc561\uc744 \uc785\ub825\ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4.  3. \ub3d9\uc77c\ud55c \uae08\uc561 \uc785\ub825 \uc2dc \ud654\uba74\uacfc \uac19\uc774 \u201c\uae30\ubcf8 \uac12\uacfc \uac19\uc2b5\ub2c8\ub2e4.\u201d \uba54\uc138\uc9c0\uac00 \ud45c\uc2dc \ub429\ub2c8\ub2e4. </p> <p>4. \uc124\uc815\ub41c \uac00\uaca9\uc774 \uae30\uc900 \uae08\uc561 \uc774\uc0c1\uc774\ub098 \uc774\ud558\ub85c \uc785\ub825\ud560 \uacbd\uc6b0 \uc704\uc5d0 \ud654\uba74\uacfc \uac19\uc774 \uac00\uaca9 \uae30\uc900\uc774 \uba54\uc138\uc9c0\ub85c \ud45c\ucd9c \ub418\uba70 \uc785\ub825\uc774 \ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.</p> <p></p> <p>5. \u201c\uc2dc\uac04\ub2f9 \uc774\uc6a9 \ub2e8\uac00\u201d \ubd80\ubd84\uc758 \uae08\uc561\uc744 \uc6d0\ud558\ub294 \uae08\uc561\uc73c\ub85c \uc785\ub825\ud558\uace0 \u201c\uac00\uaca9 \uc124\uc815\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud574\uc8fc\uc138\uc694.</p> <p></p> <p>6. \uc815\uc0c1\uc801\uc778 \uae08\uc561\uc774 \uc785\ub825\ub418\uba74 \uc704\uc758 \ud654\uba74\uacfc \uac19\uc774 \ud31d\uc5c5\uc774 \ub098\uc635\ub2c8\ub2e4. 7. \uae08\uc561\uc744 \ucd5c\uc885 \ud655\uc778\ud558\uace0, \u201c\uac00\uaca9\uc124\uc815\u201d \ubc84\ud2bc\uc744 \ub204\ub974\uba74 \uae08\uc561 \uc218\uc815\uc774 \uc644\ub8cc \ub429\ub2c8\ub2e4.  8. \uae08\uc561\uc744 \ub2e4\uc2dc \uc218\uc815\ud558\uace0 \uc2f6\uc744\uacbd\uc6b0 \u201c\ucde8\uc18c\u201d\ub97c \ub204\ub974\uba74 \uc774\uc804 \ud654\uba74\uc73c\ub85c \ub3cc\uc544\uac00\uc11c \ub2e4\uc2dc \uae08\uc561 \uc218\uc815\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/stop-gpu-sharing/","title":"GPU \uacf5\uc720 \uc911\ub2e8","text":"<p>\uc5d0\uc774\uc804\ud2b8\ub97c \ud1b5\ud574 GPU \uacf5\uc720\ub97c \uc911\ub2e8 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uc5d0\uc774\uc804\ud2b8 \uc911\uc559 status\uc758 \u201cRurning\u201d \ud56d\ubaa9\uc744 \ud074\ub9ad \u2192 Run \uacfc Stop\uc911 \u201cStop\u201d\uc744 \ud074\ub9ad\ud558\uc138\uc694.</p> <p></p> <p>2. \uacf5\uc720 \uc911\ub2e8 \uacfc\uc815\uc5d0\uc11c \uc704 \ud654\uba74\uacfc \uac19\uc774 \u201cTurning off\u201d \uc0c1\ud0dc\ub85c \ubcc0\uacbd\ub429\ub2c8\ub2e4.</p> <p></p> <p>3. \uacf5\uc720 \uc911\ub2e8\uc774 \uc644\ub8cc\ub418\uba74 \u201cStopped\u201d\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4.</p>"},{"location":"user-guide/node/tier-2-ubuntu-setting-guide/","title":"Tier 2 \ub178\ub4dc \uacf5\uae09\uc790 \uc138\ud305 \uac00\uc774\ub4dc","text":"<p>Tier 2 \uc774\uc6a9\uc790\ub4e4\uc744 \uc9c4\ud589 \uc804 \uc544\ub798 \uac00\uc774\ub4dc\uc5d0 \ub530\ub77c Ubuntu OS \uc138\ud305\uc744 \uc644\ub8cc\ud558\uc2e0 \ud6c4, \uc9c4\ud589\ud574\uc8fc\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.  Tier 2 Ubuntu OS \uc138\ud305 \uac00\uc774\ub4dc </p>"},{"location":"user-guide/node/tier-2-ubuntu-setting-guide/#1-nvidia","title":"1. Nvidia \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc124\uce58","text":"<ul> <li>Ubuntu \uc811\uc18d \ud6c4, Nvidia \uadf8\ub798\ud53d \uce74\ub4dc \uc778\uc2dd\uc744 \uc704\ud55c \ub4dc\ub77c\uc774\ubc84 \uc124\uce58</li> <li> <p>\uae30\uc874 \ub4dc\ub77c\uc774\ubc84 \uc0ad\uc81c</p> <pre><code>$ sudo apt-get purge nvidia*\n$ sudo apt-get autoremove\n$ sudo apt-get autoclean\n\n$ sudo dpkg -l | grep nvidia\n$ sudo apt remove --purge {\uc704 \uba85\ub839\uc5b4\ub85c \ucd9c\ub825\ub41c \ud328\ud0a4\uc9c0 \uc774\ub984}\n</code></pre> </li> <li> <p>\uc2e0\uaddc \ub4dc\ub77c\uc774\ubc84 \uc124\uce58</p> <ul> <li>\uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc124\uce58\ub97c \uc704\ud55c \uc0ac\uc804 \ud328\ud0a4\uc9c0 \uc124\uce58</li> </ul> <pre><code>$ sudo apt install ubuntu-drivers-common\n$ sudo add-apt-repository ppa:graphics-drivers/ppa\n$ sudo apt update\n$ sudo apt install alsa-utils -y\n</code></pre> </li> <li> <p>\ud574\ub2f9 \uba85\ub839\uc5b4 \uc218\ud589 \ud6c4, recommended\ub85c \ud45c\uc2dc\ub418\ub294 \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc124\uce58</p> <ul> <li>ex : NVIDIA GeForce RTX 3060 \uadf8\ub798\ud53d \uce74\ub4dc\uc778 \uacbd\uc6b0</li> </ul> <pre><code>$ sudo ubuntu-drivers devices\n\n== /sys/devices/pci0000:00/0000:00:03.1/0000:09:00.0 ==\nmodalias : pci:v000010DEd00002504sv00001458sd0000407Bbc03sc00i00\nvendor   : NVIDIA Corporation\nmodel    : GA106 [GeForce RTX 3060 Lite Hash Rate]\ndriver   : nvidia-driver-550-open - distro non-free\ndriver   : nvidia-driver-545 - distro non-free\ndriver   : nvidia-driver-535 - distro non-free\ndriver   : nvidia-driver-535-server-open - distro non-free\n**driver   : nvidia-driver-550 - distro non-free recommended**\ndriver   : nvidia-driver-545-open - distro non-free\ndriver   : nvidia-driver-535-server - distro non-free\ndriver   : nvidia-driver-535-open - distro non-free\ndriver   : nvidia-driver-470 - distro non-free\ndriver   : nvidia-driver-470-server - distro non-free\ndriver   : xserver-xorg-video-nouveau - distro free builtin\n\n$ sudo apt install nvidia-driver-550\n\n# \uacf5\uae09\uc790 \ubcf8\uc778 \ud654\uba74\uc5d0 \ud45c\uc2dc\ub41c recommended driver\ub97c install \ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4.\n</code></pre> </li> <li> <p>\uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84 \uc124\uce58 \uc774\ud6c4, OS \uc7ac\uae30\ub3d9</p> <pre><code>$ sudo reboot\n</code></pre> </li> <li> <p>OS \uae30\ub3d9 \uc774\ud6c4,  nvidia-smi \uba85\ub839\uc5b4 \uc218\ud589\ud558\uc5ec \uadf8\ub798\ud53d \ub4dc\ub77c\uc774\ubc84\uac00 \uc815\uc0c1 \uc124\uce58\ub418\uc5c8\ub294\uc9c0 \ud655\uc778</p> <pre><code>$ nvidia-smi\n\nTue Feb 25 09:47:42 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce RTX 3060        On  |   00000000:09:00.0 Off |                  N/A |\n|  0%   42C    P8             23W /  170W |       2MiB /  12288MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n</code></pre> </li> </ul>"},{"location":"user-guide/node/tier-2-ubuntu-setting-guide/#2-gcube-agent","title":"2. Gcube agent \uc124\uce58","text":"<ul> <li>Agent \uc124\uce58 \uc804 \uc0ac\uc804 \uc900\ube44<ol> <li>\uacf5\uae09\uc790\ub294 \ud558\uae30 \ud56d\ubaa9\uc744 gcube\uce21\uc5d0 \uc815\ubcf4 \uc804\ub2ec\uc774 \ud544\uc694<ul> <li>gcube.ai  \ud648\ud398\uc774\uc9c0 \uc0ac\uc6a9\uc790 \uacc4\uc815 \uc815\ubcf4</li> <li>Ubuntu OS user \uacc4\uc815 ID/PW</li> <li>\ud30c\uc77c\uacfc \ud1a0\ud070\uc744 \ubc1b\uc73c\uc2e4 \uc774\uba54\uc77c \uc8fc\uc18c</li> </ul> </li> <li>gcube\uc5d0\uc11c \uace0\uac1d\ub2d8\uc758 \uc815\ubcf4\ub97c \ubc1b\uc740 \ud6c4,  agent \uc124\uce58 \ud30c\uc77c \ubc0f \uc124\uce58 \uc9c4\ud589 \uc2dc \ud544\uc694\ud55c \uac1c\uc778 \uc0ac\uc6a9\uc790 \ud1a0\ud070 \uc804\ub2ec \u203b \ubcf4\ub0b4\uc8fc\uc2e0 \uc774\uba54\uc77c\uc744 \ud1b5\ud574 \uc804\ub2ec\ud574 \ub4dc\ub9b4 \uc608\uc815\uc785\ub2c8\ub2e4.<ul> <li>gai_svr_inst (\uc124\uce58 \ud30c\uc77c)</li> <li>\uac1c\uc778 \uc0ac\uc6a9\uc790 \ud1a0\ud070</li> </ul> </li> </ol> </li> <li> <p>\uc774\ud6c4 Ubuntu \uc811\uc18d \ud6c4 \ud574\ub2f9 \uacfc\uc815 \uc9c4\ud589</p> </li> <li> <p>agent \uc124\uce58 \ub514\ub809\ud130\ub9ac \uc0dd\uc131 \ubc0f agent \uc124\uce58 \ud30c\uc77c \uad8c\ud55c \ubd80\uc5ec</p> <pre><code># \ub514\ub809\ud1a0\ub9ac \uc0dd\uc131\n$ mkdir -p ~/work/gcube_instller\n\n# \ud574\ub2f9 \uacbd\ub85c\uc5d0 agent \uc124\uce58\ud30c\uc77c \uc704\uce58\n$ cd ~/work/gcube_installer/\n\n# agent \uc124\uce58 \ud30c\uc77c \uad8c\ud55c \ubd80\uc5ec\n$ chmod +x gai_svr_inst\n</code></pre> </li> <li> <p>\uae30\ubcf8 \ud30c\uc77c \uc124\uce58</p> <pre><code># \uae30\ubcf8 \ud30c\uc77c \uc124\uce58\n$ sudo ./gai_svr_inst base\n\nINFO[0000] Rnd initialized...                           \nINFO   [2025-02-25T06:11:15Z] Install Base All ...                         \nINFO   [2025-02-25T06:11:38Z] baseNetools complete.                        \nINFO   [2025-02-25T06:11:46Z] procWireGuard complete.                      \nINFO   [2025-02-25T06:11:46Z] PktPathBase: /root/packages/ubuntu22/ k8s_packages_u22_v1.28.tar.gz \nINFO   [2025-02-25T06:12:10Z] procK8sPackage complete.                     \nERROR  [2025-02-25T06:13:28Z] Failed to run                                 error=\"exit status 1\"\nWARNING[2025-02-25T06:13:28Z] util.ExecCommand dpkg crio                    error=\"exit status 1\"\nINFO   [2025-02-25T06:13:29Z] procCrio complete.                           \nINFO   [2025-02-25T06:14:31Z] procKubernetes complete.                     \nERROR  [2025-02-25T06:14:36Z] Failed to run                                 error=\"exit status 100\"\nWARNING[2025-02-25T06:14:36Z] ExecCommand apt install                       error=\"exit status 100\"\nINFO   [2025-02-25T06:14:36Z] apt fix broken                               \nINFO   [2025-02-25T06:14:42Z] retry install nvidia-container-toolkit       \nINFO   [2025-02-25T06:14:52Z] procNvidiaPlugin complete.                   \nINFO   [2025-02-25T06:14:53Z] clearAutoUpdate complete.                    \nINFO   [2025-02-25T06:14:53Z] **procGaiClientInstaller complete.**  \n</code></pre> <ul> <li> <p>\ub9c8\uc9c0\ub9c9 \ub77c\uc778\uc5d0 \u2018procGaiClientInstaller complete\u2019 \ucd9c\ub825 \uc2dc, \uae30\ubcf8 \uad6c\uc131 \uc694\uc18c\ub4e4\uc758 \uc124\uce58\uac00 \uc644\ub8cc \uc0c1\ud669</p> </li> <li> <p>\uc2e4\ud589 \ud654\uba74 \uc608\uc2dc)</p> </li> </ul> <p></p> </li> <li> <p>\ub178\ub4dc \uac1c\ud1b5 \uc9c4\ud589</p> <ul> <li> <p>\uc774\ud6c4 \ud558\uae30 \uba85\ub839\uc5b4\ub97c \uc218\ud589\ud558\uc5ec, \ub178\ub4dc \uac1c\ud1b5 \uc9c4\ud589</p> <ul> <li>ethernet nic name : \uc124\uce58 \uc7a5\ube44\uc758 \ub124\ud2b8\uc6cc\ud06c \uc778\ud130\ud398\uc774\uc2a4 \uc774\ub984</li> <li>access token : \uc804\ub2ec\ubc1b\uc740 \uac1c\uc778 \uc0ac\uc6a9\uc790 \ud1a0\ud070 (\ud1a0\ud070\uac12 \uc785\ub825 \uc2dc \ub300\uc18c\ubb38\uc790 \uad6c\ubd84 \ud544\uc694)</li> </ul> <pre><code># \uc0ac\uc6a9\uc911\uc778 \uc774\ub354\ub137 \uc778\ud130\ud398\uc774\uc2a4 \ubaa8\ub450 \ubcf4\uae30\n\n$ ifconfig -a \n</code></pre> <pre><code># \ub178\ub4dc \uac1c\ud1b5\uc744 \uc704\ud55c \uba85\ub839\uc5b4\n\n$ sudo ./gai_svr_inst --nic &lt;ethernet nic name&gt; reg &lt;access token&gt;\n</code></pre> <pre><code># ex) \uc218\ud589 \uc608\uc2dc\n# \uc0ac\uc6a9\uc911\uc778 \uc678\ubd80\uc5f0\uacb0 \uc774\ub354\ub137 \uc778\ud130\ud398\uc774\uc2a4 \uc774\ub984 \ud655\uc778 -&gt; (enp5s0)\n\n$ ifconfig -a\n\ndocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::7807:f9ff:fe9c:6967  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 7a:07:f9:9c:69:67  txqueuelen 0  (Ethernet)\n        RX packets 1779  bytes 49812 (49.8 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 1189  bytes 130886 (130.8 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nenp5s0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 10.39.60.65  netmask 255.255.254.0  broadcast 10.39.61.255\n        inet6 fe80::642:1aff:fe94:5edd  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 04:42:1a:94:5e:dd  txqueuelen 1000  (Ethernet)\n        RX packets 2283880  bytes 2164088878 (2.1 GB)\n        RX errors 0  dropped 10  overruns 0  frame 0\n        TX packets 1513085  bytes 1359887094 (1.3 GB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n        device memory 0xfc400000-fc4fffff  \n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 46784  bytes 3534359 (3.5 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 46784  bytes 3534359 (3.5 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp4s0: flags=4098&lt;BROADCAST,MULTICAST&gt;  mtu 1500\n        *ether f4:b3:01:39:2b:91  txqueuelen 1000  (Ethernet)*\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre> <pre><code># \uc774\ud6c4 sudo ./gai_svr_inst --nic &lt;ethernet nic name&gt; reg &lt;access token&gt; \ud615\uc2dd\uc73c\ub85c \ub178\ub4dc \ub4f1\ub85d \uc9c4\ud589\n\n$ sudo ./gai_svr_inst --nic enp5s0 reg eyJh...\uc0dd\ub7b5...X63w\n\nINFO[0000] Rnd initialized...                           \nINFO   [2025-02-25T06:23:16Z] access token : &amp;[eyJh...X63w] enp5s0 \nINFO   [2025-02-25T06:23:16Z] MAC address                                   mac=\"00:00:00:00:00:00\"\nINFO   [2025-02-25T06:23:16Z] mac address 000000000000                     \nDEBUG  [2025-02-25T06:23:16Z] url https://api.gcube.ai/api/node/register   \nDEBUG  [2025-02-25T06:23:16Z] body {\"category\":\"svr\",\"macId\":\"000000000000\"} \nDEBUG  [2025-02-25T06:23:16Z] res &amp;{200 6150125230709283 eyJh...xsHS  } \nINFO   [2025-02-25T06:23:16Z] provision code 0000000000000000              \nINFO   [2025-02-25T06:23:16Z] start provision ...                          \nDEBUG  [2025-02-25T06:23:16Z] body {\"provision_code\":\"0000000000000000\"}\n</code></pre> </li> <li> <p>\uc2e4\ud589 \ud654\uba74 \uc608\uc2dc)</p> </li> </ul> <p></p> </li> <li> <p>\uc774\ud6c4 gcube.ai \ub178\ub4dc \ud398\uc774\uc9c0\uc5d0\uc11c \ub4f1\ub85d\ub41c \ub178\ub4dc \ud655\uc778 \uac00\ub2a5</p> <ul> <li>\ub178\ub4dc \ud398\uc774\uc9c0\ub85c \uc774\ub3d9\ud558\uae30</li> </ul> <p></p> </li> </ul>"},{"location":"user-guide/node/troubleshooting_agent_errors/","title":"\uc5d0\uc774\uc804\ud2b8 \uc0ac\uc6a9 \uc624\ub958 \ud574\uacb0","text":"<p>Initializing \uc624\ub958 \ubc1c\uc0dd \uc2dc, Hyper-V \ud65c\uc131\ud654\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  </p>"},{"location":"user-guide/node/troubleshooting_agent_errors/#hyper-v","title":"Hyper-V \ud65c\uc131\ud654 \ubc29\ubc95","text":"<p>1. \uc708\ub3c4\uc6b0 \uac80\uc0c9 \ucc3d\uc5d0 \u201cWindows \uae30\ub2a5 \ucf1c\uae30 / \ub044\uae30\u201d\ub97c \uac80\uc0c9\ud558\uc5ec \uc2e4\ud589\ud569\ub2c8\ub2e4. </p> <p></p> <p>2. \u201cHyper-V\u201d\ub97c \ucc3e\uc544 \uccb4\ud06c\ud574 \uc90d\ub2c8\ub2e4.</p> <p>\u203b HYPER-V \uae30\ub2a5\uc740 \uae30\ubcf8\uc801\uc73c\ub85c \uc708\ub3c4\uc6b0 PRO \ubc84\uc804\uc5d0\uc11c\ub9cc \uc0ac\uc6a9\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. </p> <p></p> <p>3. \ub2e4\uc2dc \uc2dc\uc791\uc744 \ub20c\ub7ec \uc7ac\ubd80\ud305\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4. </p>"},{"location":"user-guide/node/troubleshooting_agent_errors/#hyper-v_1","title":"\uc7ac\ubd80\ud305 \uc644\ub8cc \ud6c4 Hyper-V \uc124\uc815","text":"<p>1. \uac80\uc0c9 \ucc3d\uc5d0\uc11c \u201cHyper-V \uad00\ub9ac\uc790\u201d\ub97c \uac80\uc0c9 \ud6c4 \uc2e4\ud589\ud569\ub2c8\ub2e4. </p> <p></p> <p>2. \ubcf8\uc778 \ucef4\ud4e8\ud130 \uc774\ub984\uc5d0\uc11c \ub9c8\uc6b0\uc2a4 \uc6b0\ud074\ub9ad \ud6c4, \u201c\uc0c8\ub85c \ub9cc\ub4e4\uae30\u201d &gt; \u201c\uac00\uc0c1 \ucef4\ud4e8\ud130 \u201c\uc21c\uc73c\ub85c \ud074\ub9ad\ud569\ub2c8\ub2e4. </p> <p></p> <p>3. \ub2e4\uc74c\uc73c\ub85c \uac00\uc0c1 \uba38\uc2e0\uc758 \uc774\ub984\uacfc, \uc800\uc7a5 \uc704\uce58\ub97c \uc124\uc815\ud558\uace0 \ub2e4\uc74c\uc744 \ud074\ub9ad\ud569\ub2c8\ub2e4. </p> <p>\u203b \uac00\uc0c1 \uc708\ub3c4\uc6b0\ub294 \uc6a9\ub7c9\uc774 \ud06c\uae30\ub54c\ubb38\uc5d0 \uc5ec\uc720 \uacf5\uac04\uc774 \ucda9\ubd84\ud55c \ub4dc\ub77c\uc774\ube0c\ub97c \uc9c0\uc815\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>4. \uac00\uc0c1 \ucef4\ud4e8\ud130 \uc138\ub300\ub97c \uc120\ud0dd\ud569\ub2c8\ub2e4. 1\uc138\ub300 \uac00\uc0c1 \ucef4\ud4e8\ud130\ub294 32\ube44\ud2b8 \ubc84\uc804\uc758 \uc708\ub3c4\uc6b0\ub97c \uc124\uce58\ud560 \uc218 \uc788\uc73c\ub098, 2\uc138\ub300 \uac00\uc0c1 \ucef4\ud4e8\ud130\uc758 \uacbd\uc6b0 64\ube44\ud2b8 \ubc84\uc804\uc758 \uc708\ub3c4\uc6b0\ub9cc \uc124\uce58\uac00 \uac00\ub2a5\ud569\ub2c8\ub2e4. </p> <p>\u203b \ud55c \ubc88 \uc120\ud0dd\ud55c \ud6c4\uc5d0\ub294 \uc138\ub300\ub97c \ubcc0\uacbd\ud560 \uc218\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud55c \uacbd\uc6b0 \uac00\uc0c1 \uba38\uc2e0\uc744 \uc0ad\uc81c\ud558\uace0 \uc7ac\uc0dd\uc131\ud558\uc138\uc694. </p> <p></p> <p>5. \uac00\uc0c1 \ucef4\ud4e8\ud130\uc5d0 \ud560\ub2f9\ud560 \uba54\ubaa8\ub9ac \uc6a9\ub7c9\uc744 \uc124\uc815\ud569\ub2c8\ub2e4. \ud604\uc7ac \ucef4\ud4e8\ud130\uc758 RAM \uc6a9\ub7c9\uacfc \uac00\uc0c1 \ucef4\ud4e8\ud130\uc5d0\uc11c \uc791\uc5c5\ud558\ub824\ub294 \uc5c5\ubb34\ub97c \uace0\ub824\ud558\uc5ec \uc124\uc815\ud574 \uc90d\ub2c8\ub2e4. (1GB=1024MB) </p> <p></p> <p>6. \ub2e4\uc74c\uc73c\ub85c \uac00\uc0c1 \ud558\ub4dc \ub514\uc2a4\ud06c\uc758 \uc704\uce58\uc640 \ud06c\uae30\ub97c \uc785\ub825\ud569\ub2c8\ub2e4. \uc6a9\ub7c9\uc740 \ub098\uc911\uc5d0 \ud655\uc7a5\uc774 \uac00\ub2a5\ud558\ub2c8 \uc124\uce58\ub41c \ud558\ub4dc \ub514\uc2a4\ud06c \uc6a9\ub7c9\uc744 \uace0\ub824\ud558\uc5ec \uc124\uc815\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4. </p> <p>\u203b \uc608\uc2dc\ub294 \ub178\ud2b8\ubd81 \ub514\uc2a4\ud06c\ub97c D\ub4dc\ub77c\uc774\ube0c\ub85c \ud560\ub2f9\ud558\uace0, \uc808\ubc18 \uc815\ub3c4\ub97c \uc9c0\uc815\ud558\uc600\uc2b5\ub2c8\ub2e4. </p>"},{"location":"user-guide/node/troubleshooting_agent_errors/#failed-to-change-vm-state","title":"Failed to change VM state \uba54\uc138\uc9c0\uac00 \ucd9c\ub825\ub418\uba70 \ucd08\uae30\ud654\uc5d0 \uc2e4\ud328\ud560 \uc2dc","text":""},{"location":"user-guide/node/troubleshooting_agent_errors/#bios","title":"BIOS \uc124\uc815","text":"<p>\ubc14\uc774\uc624\uc2a4(BIOS) \uc9c4\uc785\ud558\ub294 \ubc29\ubc95</p> <p>\uc804\uc6d0\uc744 \ucf1c\uace0  [F2] \ud0a4\ub97c \ube60\ub978 \uc18d\ub3c4\ub85c \uc5ec\ub7ec \ubc88 \ub20c\ub7ec\uc8fc\uc138\uc694.</p> <p>\u203b SSD \uac00 \ud0d1\uc7ac\ub41c \uc81c\ud488\uc758 \uacbd\uc6b0 \ubd80\ud305 \uc18d\ub3c4\uac00 \ub9e4\uc6b0 \ube68\ub77c \uc2dc\uc2a4\ud15c \uc804\uc6d0\uc744 \ucf1c\uc790\ub9c8\uc790 \ud0a4\ubcf4\ub4dc [F2] \ub97c \uc5f0\ud0c0\ub85c \ub20c\ub7ec\uc8fc\uc138\uc694.</p> <p>\uc81c\uc870\uc0ac\ubcc4 \uc9c4\uc785 \ubc29\ubc95</p> \uc81c\uc870\uc0ac BIOS\u00a0\uc9c4\uc785\u00a0\ub2e8\ucd95\ud0a4 \ubd80\ud2b8 \uc21c\uc704 \uc120\ud0dd \uc0ac\uc774\ud2b8 \ub9c1\ud06c \uc778\ud154(Intel) F2 F10 \ub9c1\ud06c AMD F2 F10 \ub9c1\ud06c MSI DEL F11 \ub9c1\ud06c \uc544\uc218\uc2a4(ASUS) F2 or Del ESC or F8 or F12 \ub9c1\ud06c <p>\u203b \uc778\ud154\uc758 \uacbd\uc6b0 BIOS \uc124\uc815 \ubc29\ubc95\uc785\ub2c8\ub2e4. \uac01 \uc81c\uc870\uc0ac \ubcc4\ub85c \ub2e4\ub97c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc790\uc138\ud55c \ubc29\ubc95\uc740 <code>Failed to change VM state (0x???????)</code>\ub77c\ub294 \uc624\ub958\uac00 \ub098\ud0c0\ub098\ub294 \uacbd\uc6b0 \uad04\ud638 \uc548 \uc624\ub958 \ucf54\ub4dc\uc640 \ud568\uaed8 \uc81c\uc870\uc0ac\uc5d0 \ubb38\uc758\ud574\uc8fc\uc138\uc694.</p>"},{"location":"user-guide/node/troubleshooting_agent_errors/#intel-bios","title":"\uc778\ud154(Intel) \ubc14\uc774\uc624\uc2a4(BIOS) \uc9c4\uc785\ud558\ub294 \ubc29\ubc95","text":"<p>1. \ubd80\ud305 \uc911\uc5d0 \ub85c\uace0 \ud654\uba74\uc774 \ucc98\uc74c \ud45c\uc2dc \ub418\uba74\u00a0F2\u00a0\ud0a4\ub97c \ub204\ub985\ub2c8\ub2e4.  2. \uae30\ubcf8 \ud0ed\uc5d0\uc11c\u00a0\uc790\ub3d9 \ubd80\ud305\uc744 \uc0ac\uc6a9 \uc548 \ud568\uc73c\ub85c \ubcc0\uacbd\u00a0\ud569\ub2c8\ub2e4. </p> <p></p> <p>3. \ucd5c\uc0c1\uc704 \ud0ed\uc73c\ub85c \ub2e4\uc2dc \ub3cc\uc544\uac11\ub2c8\ub2e4.\u00a0\uc800\uc7a5 &amp; \ub05d\ub0b4\uae30\u00a0\ud0ed\uc774 \ud45c\uc2dc \ub420 \ub54c\uae4c\uc9c0 \uc624\ub978\ucabd \ud654\uc0b4\ud45c \ud0a4\ub97c \ud074\ub9ad\ud569\ub2c8\ub2e4. 4. \ubcc0\uacbd \ub0b4\uc6a9 \uc800\uc7a5\uc744 \uc120\ud0dd\ud558\uace0 \uc885\ub8cc\u00a0\ud558\uc5ec \ubcc0\uacbd \uc0ac\ud56d\uc774 \uc800\uc7a5\ub41c \uc2dc\uc2a4\ud15c\uc744 \ubd80\ud305\ud569\ub2c8\ub2e4.</p>"},{"location":"user-guide/platform-guide/QnA-user-guide/","title":"QnA \uc0ac\uc6a9 \uac00\uc774\ub4dc v1.2","text":"<p>\uc6cc\ud06c\ub85c\ub4dc, \ub178\ub4dc \uc0ac\uc6a9 \uc2dc \ubb38\uc758\uac00 \uc788\ub294 \uacbd\uc6b0 \uace0\uac1d\uc9c0\uc6d0\uc744 \uc774\uc6a9\ud558\uc5ec \uad81\uae08\ud55c \ub0b4\uc6a9\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/platform-guide/QnA-user-guide/#qna","title":"QnA \ud398\uc774\uc9c0 \uc785\uc7a5","text":"<p>\uc88c\uce21\uba54\ub274\uc758 \uc5d0 \uc704\uce58\ud55c \u201c\uace0\uac1d \uc9c0\uc6d0\u201d\uc744 \ud074\ub9ad\ud569\ub2c8\ub2e4. Deploy mode, Share mode \ub3d9\uc77c\ud558\uac8c \uc774\uc6a9 \uac00\ub2a5\ud569\ub2c8\ub2e4.  [\uc6cc\ud06c\ub85c\ub4dc]</p> <p></p>"},{"location":"user-guide/platform-guide/QnA-user-guide/#qna-faq","title":"QnA FAQ \uc124\uba85","text":"<p>1. QnA \ud398\uc774\uc9c0\uc5d0\uc11c FAQ \uce74\ud14c\uace0\ub9ac\ub4e4\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4. 2. \uce74\ud14c\uace0\ub9ac\ub294 \u201c\uc804\uccb4\u201d, \u201c\uacb0\uc81c\u201d, \u201c\uae30\uc220\u201d, \u201c\uacc4\uc815\u201d, \u201c\uc11c\ube44\uc2a4\u201d, \u201c\uae30\ud0c0\u201d \ucd1d 6\uac00\uc9c0 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uce74\ud14c\uace0\ub9ac\uc5d0 \uc790\uc8fc \ubb3b\ub294 \uc9c8\ubb38\ub4e4\uc774 3\uac1c\uc529 \ud45c\uc2dc\ub429\ub2c8\ub2e4. </p> <p></p> <p>3. FAQ\uc5d0 \ud544\uc694\ud55c \ub0b4\uc6a9\uc774 \uc5c6\ub294 \uacbd\uc6b0 \uc9c1\uc811 QnA\uc744 \uc791\uc131\ud558\uc5ec \uc9c8\ubb38\uc744 \ubb38\uc758\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubb38\uc758 \uc720\ud615\uc744 \uc120\ud0dd\ud558\uace0 \ud544\uc694\ud55c \uacbd\uc6b0 \uc6b4\uc601\uc911\uc778 node \ub098 Workload \ub300\uc0c1\uc744 \uc120\ud0dd\ud558\uc5ec \ubb38\uc758\ud558\uba74 \ubcf4\ub2e4 \uc0c1\uc138\ud55c \ub2f5\ubcc0\uc744 \ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ubb38\uc758\ub294 \uc774\uba54\uc77c\ub85c \uc811\uc218\ub418\uba70, \ub2f5\ubcc0\uc774 \ub610\ud55c \uacc4\uc815\uc758 \uc774\uba54\uc77c\ub85c \ubc1c\uc1a1\ub418\uc5b4\uc9d1\ub2c8\ub2e4.  \uc544\ub798\uc5d0\ub294 \u201cFAQ \ub9c1\ud06c\u201d\uc640 \u201c\uce74\uce74\uc624 \ucc44\ub110 \ub9c1\ud06c\u201d\uac00 \uc788\uc2b5\ub2c8\ub2e4. \ubcf4\ub2e4 \uc790\uc138\ud55c FAQ \ubaa9\ub85d\uc744 \ud655\uc778\ud558\uace0 , \uce74\uce74\uc624\ucc44\ub110\uc744 \ud1b5\ud574 \uc2e4\uc2dc\uac04 \ubb38\uc758\ub97c \uc774\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/","title":"Wan2.2 \uc0ac\uc6a9 \uac00\uc774\ub4dc","text":"<p>\uc0ac\uc804 \uc900\ube44 \uc0ac\ud56d\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:</p> <p>1. gcube \ud68c\uc6d0\uac00\uc785</p> <p>\uba3c\uc800 [gcube \ud648\ud398\uc774\uc9c0]\uc5d0\uc11c \ud68c\uc6d0\uac00\uc785\uc744 \uc9c4\ud589\ud574\uc8fc\uc138\uc694. \ud68c\uc6d0 \uac00\uc785\uc740 Microsoft \ub610\ub294 Google\ub85c \uac00\ub2a5\ud569\ub2c8\ub2e4. </p> <p>2. \ud3ec\uc778\ud2b8 \ucda9\uc804</p> <p>gcube \ub85c\uadf8\uc778 \ud6c4, \ud3ec\uc778\ud2b8\ub97c \ucda9\uc804\ud558\uc154\uc57c \ubaa8\ub378 \uc2e4\ud589\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. [\ud3ec\uc778\ud2b8 \ucda9\uc804 \ud398\uc774\uc9c0]\uc5d0\uc11c \ucda9\uc804\uc744 \uc9c4\ud589\ud574\uc8fc\uc138\uc694.</p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#wan22-ai","title":"Wan2.2\ub294 \uc5b4\ub5a4 AI \ubaa8\ub378\uc778\uac00?","text":"<p>\ud574\ub2f9 \ubb38\uc11c\ub294 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ube44\ub514\uc624\ub85c \uc790\ub3d9 \ubcc0\ud658\ud574\uc8fc\ub294 AI \ubaa8\ub378 \uac00\uc774\ub4dc\uc5d0 \ub300\ud55c \ubb38\uc11c\uc785\ub2c8\ub2e4. </p> <p>\uc790\uc138\ud55c \uc791\ub3d9 \uc6d0\ub9ac \ub610\ub294 \uae30\uc220\uc801\uc778 \ubb38\uc758\ub294 \uc544\ub798 Huggingface\uc5d0\uc11c \uac00\ub2a5\ud558\uba70  \ub3c4\ucee4 \uc774\ubbf8\uc9c0\uc5d0 \uad00\ud55c \uc0c1\uc138 \uc124\uba85\uc740 \uadf8 \uc544\ub798 \ub9c1\ud06c\uc5d0\uc11c \ud655\uc778 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p> <p>https://huggingface.co/QuantStack/Wan2.2-I2V-A14B-GGUF</p> <p>https://hub.docker.com/r/nykk3/comfyui-wan2.2-gguf</p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#_1","title":"\uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131\ud558\uae30","text":"<p>\uc0ac\uc804 \uc900\ube44\ub97c \ubaa8\ub450 \ub9c8\uce58\uc168\ub2e4\uba74 \uc774\uc81c \uc6cc\ud06c\ub85c\ub4dc\uc5d0\uc11c \uc0dd\uc131\ud574\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4. </p> <p>1. gcube:\uc9c0\ud050\ube0c \ud648\ud398\uc774\uc9c0\uc5d0 \ub85c\uadf8\uc778\ud55c \ub2e4\uc74c, \uc6cc\ud06c\ub85c\ub4dc \uba54\uc778 \ud398\uc774\uc9c0\ub85c \ub4e4\uc5b4\uac00 \uc90d\ub2c8\ub2e4.</p> <p>2. \uc88c\uce21 &gt; \uc0c8 \uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131 \ud074\ub9ad</p> <p></p> <p>3. \uc124\uba85\ub780\uc5d0 \uc6d0\ud558\ub294 \uc6cc\ud06c\ub85c\ub4dc \uc81c\ubaa9\uc744 \uc785\ub825</p> <p></p> <p>3. \ucee8\ud14c\uc774\ub108 \uc800\uc7a5\uc18c \uc720\ud615: \ub3c4\ucee4 \ud5c8\ube0c \uc120\ud0dd</p> <p>4. \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0: [ nykk3/comfyui-wan2.2-gguf:q4ks-14b-i2v-cuda12.8 ] \uc785\ub825 \ud6c4 \uc774\ubbf8\uc9c0 \uac80\uc99d \ud074\ub9ad / \uac80\uc99d \uc644\ub8cc \ud6c4 \ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8\uc5d0 [8188] \uc785\ub825 ****</p> <p></p> <p>5. \uc635\uc158 \ud56d\ubaa9\uc5d0\uc11c [\ucee8\ud14c\uc774\ub108 \ud658\uacbd \ubcc0\uc218]\ub97c \uc785\ub825</p> Key Value WEB_PASSWORD Str0ngP@ssw0rd123! COMFYUI_USERNAME admin COMFYUI_PASSWORD MyS3cureP@ssw0rd! COMFYUI_ARGS --listen 0.0.0.0 --port 8188 --use-sage-attention <p>\u203b \ube44\ubc00\ubc88\ud638(PASSWORD)\ub294 \uc6d0\ud558\uc2dc\uba74 12\uc790 \uc774\uc0c1\uc73c\ub85c \uc790\uc720\ub86d\uac8c \uc124\uc815\ud558\uc154\ub3c4 \ub429\ub2c8\ub2e4.</p> <p></p> <p>6. \uc0ac\uc6a9\ud558\uace0 \uc2f6\uc740 GPU \uc120\ud0dd (\u203b \ub9ce\uc740 VRAM\uc744 \uc694\uad6c\ud558\uae30\uc5d0 RTX 5090\uc744 \uc801\uadf9 \ucd94\ucc9c)</p> <p></p> <p>7. \uc989\uc2dc\ubc30\ud3ec \uccb4\ud06c / \ub9c8\uc9c0\ub9c9\uc73c\ub85c \ub4f1\ub85d \ubc84\ud2bc \ud074\ub9ad</p> <p></p> <p>8. \uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131\uc774 \uc644\ub8cc\ub418\uba74, \uc11c\ube44\uc2a4 URL\uc744 \ud074\ub9ad\ud558\uc5ec Wan 2.2 \ubaa8\ub378\uc744 \uc9c1\uc811 \uccb4\ud5d8\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\u203b \uc6cc\ud06c\ub85c\ub4dc\ub294 \ubc30\ud3ec \ud6c4, \uc644\uc804 \uc0dd\uc131\uae4c\uc9c0 \uc57d 3~5\ubd84 \uc815\ub3c4 \uc18c\uc694\ub429\ub2c8\ub2e4. (GPU \uc0ac\uc591\uc5d0 \ub530\ub77c \ucc28\uc774 \uc788\uc74c)</p> <p></p> <p>\uc11c\ube44\uc2a4 URL\uc5d0\uc11c \uc704\uc640 \uac19\uc740 \ud654\uba74\uc774 \ub098\uc628\ub2e4\uba74 \uc544\uc9c1 \uc900\ube44\ub418\uc9c0 \uc54a\uc558\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.</p> <p>2~3\ubd84 \ub4a4\uc5d0 \uc11c\ube44\uc2a4 URL\uc744 \ub2e4\uc2dc \ud074\ub9ad\ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4.</p> <p>9. \uc815\uc0c1\uc801\uc73c\ub85c \uc2e4\ud589\ub41c\ub2e4\uba74 \uc67c\ucabd \uc0ac\uc774\ub4dc\ubc14\uc5d0\uc11c \uc6cc\ud06c\ud50c\ub85c(\ud30c\uc77c \ubaa8\uc591)\uc5d0\uc11c Wan2.2 \ubaa8\ub378\uc744 \ub204\ub974\uba74 \uc544\ub798\uc640 \uac19\uc740 \ud654\uba74\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4.</p> <p></p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#wan22_1","title":"Wan2.2 \uc0ac\uc6a9 \ubc29\ubc95","text":"<p>Wan2.2\uac00 \uc815\uc0c1\uc801\uc73c\ub85c \uc2e4\ud589\ub418\uc5c8\ub2e4\uba74 \uc5ec\ub7ec\uac00\uc9c0 \uc124\uc815\uc744 \ud1b5\ud574 \uc774\ubbf8\uc9c0\ub97c \ube44\ub514\uc624\ub85c \uce58\ud658\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc774\ubc88 \uac00\uc774\ub4dc\uc5d0\uc11c\ub294 \uac04\ub2e8\ud788 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574\uc11c \uc124\uba85\ud558\uaca0\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#step-1","title":"Step 1. \uc774\ubbf8\uc9c0 \uc5c5\ub85c\ub4dc","text":"<p>\ube44\ub514\uc624\ub85c \uce58\ud658\ud558\uace0\uc790\ud558\ub294 \uc774\ubbf8\uc9c0\ub97c \uc5c5\ub85c\ub4dc \ud569\ub2c8\ub2e4.</p> <p></p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#step-2","title":"Step 2. \ube44\ub514\uc624 \uc124\uc815","text":"<p>\ube44\ub514\uc624\uc758 \ud53d\uc140 \ub108\ube44\uc640 \ub192\uc774, \uc601\uc0c1 \uae38\uc774, \uc601\uc0c1 \uc0dd\uc131 \uac1c\uc218\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.</p> <p></p> <p></p> <p>\u203b \ube44\ub514\uc624 \uc124\uc815\uc5d0 \uad00\ud55c \uba87 \uac00\uc9c0 \uad8c\uc7a5 \ubc0f \uc8fc\uc758 \uc0ac\ud56d\ub4e4\uc785\ub2c8\ub2e4.  1. Wan2.2\ub294 \ube44\ub514\uc624 \ud574\uc0c1\ub3c4 480P[854 x 480]\uc640 720P[1280 x 720]\ub97c \uad8c\uc7a5\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  2. \ud574\uc0c1\ub3c4\uac00 \ub192\uc744\uc218\ub85d, \uc601\uc0c1 \uae38\uc774\uac00 \uae38\uc5b4\uc9c8\uc218\ub85d \ube44\ub514\uc624 \uc0dd\uc131\uc5d0 \uc2dc\uac04\uc774 \uc624\ub798 \uac78\ub9bd\ub2c8\ub2e4. 3. \uc601\uc0c1 \uae38\uc774\ub294 \ud504\ub808\uc784 \uc218\ub85c \ud45c\uae30\ub429\ub2c8\ub2e4. FPS\uc640 \ud569\uccd0 \uc601\uc0c1 \uae38\uc774\uac00 \uacb0\uc815\ub429\ub2c8\ub2e4.  ex) [\uae38\uc774: 121 \ud504\ub808\uc784] / [FPS: 24] = \uc57d 5\ucd08 4.</p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#step-3","title":"Step 3. (\uc635\uc158) \ud504\ub86c\ud504\ud2b8 \uc124\uc815","text":"<p>\ud504\ub86c\ud504\ud2b8 \uc785\ub825\uc744 \ud1b5\ud574 AI\uc5d0\uac8c \ucd94\uac00\ud558\uace0 \uc2f6\uc740 \uc694\uc18c\ub098 \ube7c\uace0 \uc2f6\uc740 \uc694\uc18c\ub97c \uc720\ub3c4\ud558\ub3c4\ub85d \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\ud55c\uae00 \uc9c0\uc6d0)  \ud574\ub2f9 \ubd80\ubd84\uc740 \uc5b4\ub514\uae4c\uc9c0\ub098 \ubd80\uac00\uc801\uc778 \uc5ed\ud560\uc774\uae30\uc5d0 \uae30\ubcf8 \uc138\ud305 \uadf8\ub300\ub85c \uc9c4\ud589\ud558\uc154\ub3c4 \ubb34\ubc29\ud569\ub2c8\ub2e4.  (Negative Prompt)\uc5d0\ub294 \ube44\ub514\uc624 \ubcc0\ud658\uc5d0 \uc545\uc601\ud5a5\uc744 \ub07c\uce60 \ubd80\ubd84\ub4e4\uc774 \uc0ac\uc804\uc5d0 \uc785\ub825\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#step-4-image-2-video","title":"Step 4. image-2-video \ubcc0\ud658 \uc2e4\ud589","text":"<p>\ud654\uba74 \ud558\ub2e8\uc758 \uc2e4\ud589\uc744 \ud074\ub9ad\ud574 \ubcc0\ud658\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4. \uc124\uc815\uc5d0 \ub530\ub77c \uc9e7\uac8c\ub294 10\ubd84\uc5d0\uc11c \ucd5c\ub300 \ud55c\uc2dc\uac04 \ubc18\uc815\ub3c4\uc758 \uc2dc\uac04\uc774 \uac78\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p></p>"},{"location":"user-guide/platform-guide/Wan2.2-user-guide/#step-5","title":"Step 5. \uacb0\uacfc\ubb3c \ud655\uc778","text":"<p>\uc6d0\ud558\ub294\ub300\ub85c \ubcc0\ud658\uc774 \ub418\uc5c8\ub294\uc9c0 \ucd5c\uc885 \ud655\uc778\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4.  \ud544\uc694\uc5d0 \ub530\ub77c \uc800\uc7a5\ub3c4 \uc9c4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p>"},{"location":"user-guide/platform-guide/ollama-deepseek/","title":"Ollama \uc0ac\uc6a9 \uac00\uc774\ub4dc - DeepSeek \ubc84\uc804","text":""},{"location":"user-guide/platform-guide/ollama-deepseek/#0","title":"0. \uac1c\uc694","text":"<ul> <li>Ollama \ub780?<ul> <li>LLM\uc744 \uc2e4\ud589\ud558\uace0 \uad00\ub9ac\ud560 \uc218 \uc788\ub3c4\ub85d \uc9c0\uc6d0\ud558\ub294 \ud50c\ub7ab\ud3fc</li> <li>\ub85c\uceec\ud658\uacbd \uc5d0\uc11c \uc624\ud508\uc18c\uc2a4 \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ub2e4\uc6b4 \ubc1b\uace0 \uc0ac\uc6a9\ud574 \ubcfc \uc218 \uc788\uc74c</li> <li>\ub300\ud45c\uc801\uc778 \uc5b8\uc5b4 \ubaa8\ub378\uc740 \ub2e4\uc74c\uacfc \uac19\ub2e4<ul> <li>Llama3<ul> <li>Meta\uc5d0\uc11c \uac1c\ubc1c\ud55c \ucd5c\uc2e0 \uc5b8\uc5b4 \ubaa8\ub378\ub85c, \uc790\uc5f0\uc5b4 \ucc98\ub9ac \uc131\ub2a5\uc774 \uc6b0\uc218</li> </ul> </li> <li>Phi 3<ul> <li>Microsoft Research\uc5d0\uc11c \uac1c\ubc1c\ud55c \ubaa8\ub378\ub85c, \ub6f0\uc5b4\ub09c \ucd94\ub860 \ubc0f \uc5b8\uc5b4 \uc774\ud574 \ub2a5\ub825 \ubcf4\uc720</li> </ul> </li> <li>Mistral<ul> <li>\ub2e4\uc591\ud55c \uc5b8\uc5b4 \uc791\uc5c5\uc5d0 \ucd5c\uc801\ud654\ub41c \ubaa8\ub378\ub85c, \uace0\uc131\ub2a5\uc744 \uc790\ub791\ud568</li> </ul> </li> <li>Gemma 2<ul> <li>Google\uc5d0\uc11c \uac1c\ubc1c\ud55c \ubaa8\ub378\ub85c, \uc790\uc5f0\uc5b4 \ucc98\ub9ac \ubc0f \uc0dd\uc131 \uc791\uc5c5\uc5d0 \uac15\uc810</li> </ul> </li> <li>CodeGemma<ul> <li>\ucf54\ub4dc \uc0dd\uc131 \ubc0f \uc644\uc131\uc5d0 \ud2b9\ud654\ub41c \ubaa8\ub378\ub85c, \ub2e4\uc591\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uc791\uc5c5\uc744 \uc9c0\uc6d0</li> </ul> </li> </ul> </li> <li>\uc624\ud508\ub41c \uc5b8\uc5b4\ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\ubcf4\uac70\ub098, \ucee4\uc2a4\ud140 \ubaa8\ub378 \uc0dd\uc131 \ubc0f \ubc30\ud3ec\ub4f1\ub4f1 \uc0ac\uc6a9\uc790 \uce5c\ud654\uc801\uc778 \uc778\ud130\ud398\uc774\uc2a4\ub97c \ud1b5\ud55c \uc5b8\uc5b4 \ubaa8\ub378 \uc2e4\ud589 \ubc0f \uad00\ub9ac\ub97c ollama\ub97c \uc774\uc6a9\ud574 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c</li> </ul> </li> </ul>"},{"location":"user-guide/platform-guide/ollama-deepseek/#1-gcube","title":"1. Gcube \ud50c\ub7ab\ud3fc \uc6cc\ud06c\ub85c\ub4dc \uc11c\ube44\uc2a4 \ub4f1\ub85d \uc808\ucc28","text":"<ul> <li> <p>\uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131 \ubc0f \ubc30\ud3ec</p> <ul> <li>gcube.ai \uc811\uc18d \ubc0f \uc6cc\ud06c\ub85c\ub4dc \ud398\uc774\uc9c0 \uc774\ub3d9 ( https://gcube.ai/ko/demand/workload/list )</li> <li> <p>\ud574\ub2f9 \ud398\uc774\uc9c0\uc5d0\uc11c \uc0c8 \uc6cc\ud06c\ub85c\ub4dc\ub97c \ub4f1\ub85d\ud558\uac70\ub098 \uae30\uc874\uc5d0 \ub4f1\ub85d\ub41c \uc6cc\ud06c\ub85c\ub4dc\ub97c \uc218\uc815\ud558\uc5ec \uc815\ubcf4 \uc785\ub825</p> <p></p> </li> </ul> </li> <li> <p>\uc124\uba85 \uac1c\uc694</p> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc774\ub984 \uc791\uc131<ul> <li>ex : ollama</li> </ul> </li> </ul> </li> </ul> <p></p> <ul> <li> <p>\ucee8\ud14c\uc774\ub108 \uac1c\uc694</p> <ul> <li>\uc800\uc7a5\uc18c \uc720\ud615 \uc120\ud0dd \ubc0f \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc120\ud0dd<ul> <li>\ub3c4\ucee4\ud5c8\ube0c\uc5d0 ollama \uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uacf5\uc2dd \uc774\ubbf8\uc9c0\uac00 \uc788\uc73c\ubbc0\ub85c \ud574\ub2f9 \uc774\ubbf8\uc9c0 \uc0ac\uc6a9<ul> <li>\ucc38\uc870 url : https://hub.docker.com/r/ollama/ollama</li> </ul> </li> <li>\uc800\uc7a5\uc18c \uc720\ud615 : \ub3c4\ucee4\ud5c8\ube0c</li> <li>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 : ollama/ollama:latest</li> <li> <p>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \ub808\uc774\uc5b4\uc758 \uba54\ud0c0\ub370\uc774\ud130(ExposedPorts)\ub97c \ud655\uc778\ud558\uc5ec \ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8\uac00 \uc790\ub3d9\uc73c\ub85c \uc791\uc131\ub41c\ub2e4 (ollama \uc758 \uacbd\uc6b0 11434)</p> <p></p> </li> </ul> </li> </ul> </li> <li> <p>\ubaa9\uc801\uc2a4\ud399 \uac1c\uc694</p> <ul> <li>\uc0ac\uc6a9\ud558\uace0\uc790 \ud558\ub294 \uc2a4\ud399\uc744 \uc815\ud55c\ub2e4<ul> <li>Tier1 : \uace0\uc131\ub2a5</li> <li>Tier2 : \uace0\uc2e0\ub8b0\uc131</li> <li>Tier3 : \uac1c\uc778 \uc0ac\uc6a9\uc790\ub4e4</li> <li>GPU \uba54\ubaa8\ub9ac : \uac00\uc6a9 GPU \ud544\ud130\ub9c1<ul> <li>\ubcf8 \uc608\uc81c\uc5d0\uc11c\ub294 Tier3 RTX3060 \uc744 \uc120\ud0dd</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p></p> <ul> <li>\uc635\uc158 \uac1c\uc694 (optional)<ul> <li>\ucee8\ud14c\uc774\ub108 \uba85\ub839<ul> <li>Dockerfile \uc758 CMD \ud56d\ubaa9 (\ucee8\ud14c\uc774\ub108 \uc2e4\ud589 \uc2dc \uc2dc\uc791\ub420 \uba85\ub839\uc5b4)<ul> <li>\ud615\uc2dd : CMD [\"executable\", \"param1\", \"param2\"] / CMD [\u201cecho\u201c, \u201cHello, world!\u201c]</li> </ul> </li> </ul> </li> <li>\ucee8\ud14c\uc774\ub108 \ud658\uacbd\ubcc0\uc218<ul> <li>Dockerfile \uc758 ENV \ud56d\ubaa9 (\ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ud658\uacbd\ubcc0\uc218)<ul> <li>\ud615\uc2dd : ENV   / ENV DEF_PORT 9999 <li>\ub808\ud50c\ub9ac\uce74<ul> <li>\ucee8\ud14c\uc774\ub108\uc758 \uc778\uc2a4\ud134\uc2a4\uac00 \uc11c\ub85c \ub2e4\ub978 \ub178\ub4dc\uc5d0\uc11c \ub3d9\uc2dc\uc5d0 \uc2e4\ud589\ub418\ub294 \uac1c\uc218</li> <li>\ubaa9\uc801<ul> <li>\uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \uc2e0\ub8b0\uc131\uacfc \ucc98\ub9ac\ub7c9 \ud5a5\uc0c1</li> <li>\ud2b9\uc815 \ub178\ub4dc\uc5d0 \ubb38\uc81c \ubc1c\uc0dd\ud574\ub3c4 \uc11c\ube44\uc2a4 \uc720\uc9c0</li> <li>\ub300\uae30 \uc2dc\uac04\uc744 \uc904\uc774\uace0 \uac1c\ubc1c\uc790 \uacbd\ud5d8 \ud5a5\uc0c1</li> <li>L7 Consistent Hashing \uae30\ubc95<ul> <li>\uc694\uccad\uc744 \ud0a4(key) \uae30\ubc18\uc73c\ub85c \ud2b9\uc815 \ubc31\uc5d4\ub4dc\ub85c \ub77c\uc6b0\ud305</li> <li>\ud574\uc2dc \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud2b8\ub798\ud53d\uc744 \uc77c\uad00\ub418\uac8c \ubd84\ubc30</li> <li>\ub178\ub4dc\ub098 \uc11c\ubc84\uac00 \ucd94\uac00\ub418\uac70\ub098 \uc81c\uac70\ub420 \ub54c\uc5d0\ub3c4 \ucd5c\uc18c\ud55c\uc758 \uc694\uccad\ub9cc \ub2e4\ub978 \uc11c\ubc84\ub85c \uc774\ub3d9\ub418\ub3c4\ub85d \ubcf4\uc7a5</li> </ul> </li> </ul> </li> </ul> </li> <li>CUDA<ul> <li>\ubc84\uc804 \uc120\ud0dd</li> </ul> </li> <li>\uacf5\uc720 \uba54\ubaa8\ub9ac<ul> <li>\ub9ac\ub205\uc2a4 \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uacf5\uc720 \uba54\ubaa8\ub9ac \uc601\uc5ed (/dev/shm)</li> <li>\ud504\ub85c\uc138\uc2a4 \uac04 \ub370\uc774\ud130 \uacf5\uc720\ub97c \uc704\ud574 \uc124\uacc4\ub41c \uc601\uc5ed (\ub300\uaddc\ubaa8 \ub370\uc774\ud130 \ucc98\ub9ac\ub97c \uc704\ud55c \uace0\uc18d \uc784\uc2dc \uc2a4\ud1a0\ub9ac\uc9c0)</li> </ul> </li> <p></p> <ul> <li>\ucd1d \uc608\uc0c1\uae08\uc561 \uac1c\uc694<ul> <li>\uc120\ud0dd\ud55c \uc2a4\ud399\uc758 \ucd5c\ub300 \uc2dc\uac04\ub2f9 \uac00\uaca9 \uc815\ubcf4</li> <li>\ub0b4\uc6a9 \ud655\uc778 \ud6c4 \ub4f1\ub85d \uc9c4\ud589<ul> <li>\u2018\uc989\uc2dc\ubc30\ud3ec\u2019 \uc120\ud0dd \uc2dc \ub4f1\ub85d \ubc0f \ubc30\ud3ec \uc9c4\ud589</li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"user-guide/platform-guide/ollama-deepseek/#2-gcube","title":"2. Gcube \ud50c\ub7ab\ud3fc \uc6cc\ud06c\ub85c\ub4dc \uc11c\ube44\uc2a4 \uc0ac\uc6a9 \ubc29\ubc95","text":"<ul> <li>\uc0dd\uc131\ub41c \uc6cc\ud06c\ub85c\ub4dc \ud655\uc778<ul> <li>\uc6cc\ud06c\ub85c\ub4dc \ud398\uc774\uc9c0(https://gcube.ai/ko/demand/workload/list )\uc5d0\uc11c \uc0dd\uc131\ud55c \uc6cc\ud06c\ub85c\ub4dc \uc774\ub984 \ud074\ub9ad \uc2dc, \uc6cc\ud06c\ub85c\ub4dc \uc138\ubd80 \uc815\ubcf4 \uc9c4\uc785 \uac00\ub2a5</li> </ul> </li> </ul> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc138\ubd80 \uc815\ubcf4 \uac1c\uc694<ul> <li>\uac1c\uc694 : \uc6cc\ud06c\ub85c\ub4dc \ubc88\ud638, \uc124\uba85, \uc720\ud615, \uc0c1\ud0dc, \uc11c\ube44\uc2a4 URL \uc815\ubcf4 \ub4f1</li> <li>\ucee8\ud14c\uc774\ub108 : \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0, \ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8, \uc800\uc7a5\uc18c \uc720\ud615, \uc0dd\uc131\uc77c\uc2dc, \ubc30\ud3ec\uc77c\uc2dc, \uc885\ub8cc\uc77c\uc2dc \uc815\ubcf4 \ub4f1</li> <li>\ubaa9\uc801\uc2a4\ud399 : \ubaa9\uc801\ub178\ub4dc, GPU \uba54\ubaa8\ub9ac, GPU \uc815\ubcf4 \ub4f1</li> <li>\uc635\uc158 : \ucee8\ud14c\uc774\ub108 \uba85\ub839, \ucee8\ud14c\uc774\ub108 \ud658\uacbd\ubcc0\uc218, \ub808\ud50c\ub9ac\uce74, \ucd5c\uc18c CUDA \ubc84\uc804, \uacf5\uc720 \uba54\ubaa8\ub9ac \uc815\ubcf4 \ub4f1</li> <li>\ubc30\ud3ec\uc0c1\ud0dc : \ucee8\ud14c\uc774\ub108 \ubc30\ud3ec \uc774\ubca4\ud2b8, \ub178\ub4dc, \ud30c\ub4dc, \ud30c\ub4dc \uc0c1\ud0dc, \ucee8\ud14c\uc774\ub108 \ub85c\uadf8, \ucee8\ud14c\uc774\ub108 \ud130\ubbf8\ub110, \ucee8\ud14c\uc774\ub108 SSH \uc815\ubcf4 \ub4f1</li> </ul> </li> </ul> <ul> <li>\ud30c\ub4dc\uc0c1\ud0dc\uac00 \u2018\uc2e4\ud589\u2019 \uc778 \uacbd\uc6b0<ul> <li>'\ucee8\ud14c\uc774\ub108 SSH' \ud074\ub9ad\ud558\uc5ec \uacf5\uc778IP \uc870\ud68c \ubc0f \uc811\uc18d\uc815\ubcf4 \ub4f1\ub85d<ul> <li>\uc815\ubcf4 \ub4f1\ub85d \uc2dc SSH \uc811\uc18d \uad00\ub828 \uc815\ubcf4 \ud655\uc778</li> </ul> </li> </ul> </li> </ul> <ul> <li>\ud130\ubbf8\ub110 \ud504\ub85c\uadf8\ub7a8 (ex: putty) \uc2e4\ud589 \ud6c4 \uc704\uc5d0\uc11c \ud655\uc778\ud55c SSH \uc811\uc18d \uc815\ubcf4 \uc785\ub825\ud558\uc5ec \ucee8\ud14c\uc774\ub108 \uc811\uc18d<ul> <li>IP, Port, \uc0ac\uc6a9\uc790 \uc544\uc774\ub514, \uc0ac\uc6a9\uc790 \ube44\ubc00\ubc88\ud638 \ub4f1</li> </ul> </li> </ul> <ul> <li> <p>\ud574\ub2f9 CLI \uc5d0\uc11c \ud558\uae30 \ucee4\ub9e8\ub4dc \uc785\ub825\ud558\uc5ec deepseek \uc5b8\uc5b4 \ubaa8\ub378 \ub2e4\uc6b4 \ubc0f \uc2e4\ud589 (\uc57d 4.7GB)</p> <ul> <li>ollama run deepseek-r1:8b</li> </ul> <p></p> </li> <li> <p>\uc774\ud6c4 DeepSeek \ubaa8\ub378\ub85c, ChatGPT \ucc98\ub7fc AI \ucd94\ub860 \uc11c\ube44\uc2a4\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c</p> <ul> <li>ex)</li> </ul> </li> </ul> <p>Q : How to make pizza?</p> <p>A :</p> <p> <p></p> <p>Making pizza can be a fun and rewarding process! Here's a basic guide to making your own pizza at home:</p>"},{"location":"user-guide/platform-guide/ollama-deepseek/#pizza-dough","title":"Pizza dough:","text":"<ol> <li>Activate yeast: In a small bowl, mix 1 teaspoon of sugar with 1 cup of warm water (around 110\u00b0F). Sprinkle in the active dry yeast, cover, and let it sit for 5-10 minutes until it becomes frothy.</li> <li>Mix dough: In a large bowl, combine 2 cups of all-purpose flour, salt, and olive oil. Add the yeast mixture and mix until the dough forms a sticky ball.</li> <li>Knead dough: knead the dough on a floured surface for about 8-10 minutes until it becomes smooth and elastic.</li> </ol>"},{"location":"user-guide/platform-guide/ollama-deepseek/#assembling-the-pizza","title":"Assembling the pizza:","text":"<ol> <li>Prepare sauce: Make your favorite tomato sauce or pesto as the base.</li> <li>Build the pizza: Roll out the dough to your desired thickness (thinner for crispy crust, thicker for a chewy texture). Transfer to a baking sheet or pizza stone.</li> <li>Add toppings: Add your preferred toppings, such as cheese, vegetables, or meats, leaving space for the edges.</li> </ol>"},{"location":"user-guide/platform-guide/ollama-deepseek/#baking","title":"Baking:","text":"<ol> <li>Preheat oven: Preheat your oven to the highest temperature (around 500-550\u00b0F) for about 10-15 minutes.</li> <li>Cook pizza: Place the prepared pizza on a baking sheet or directly on the pizza stone. Cook for 10-15 minutes, or until the crust is golden and cheese is bubbly.</li> </ol>"},{"location":"user-guide/platform-guide/ollama-deepseek/#tips","title":"Tips:","text":"<ul> <li>For a crispy crust, brush the dough with olive oil before baking.</li> <li>Add toppings in even amounts to avoid overcrowding the pizza.</li> <li>Use a pizza peel or cardboard to slide the pizza off the stone.</li> </ul> <p>Enjoy your homemade pizza!</p> <p>ex2)</p> <p></p>"},{"location":"user-guide/platform-guide/ollama-llama3/","title":"Ollama \uc0ac\uc6a9 \uac00\uc774\ub4dc - llama3","text":""},{"location":"user-guide/platform-guide/ollama-llama3/#0","title":"0. \uac1c\uc694","text":"<ul> <li>Ollama \ub780?<ul> <li>LLM\uc744 \uc2e4\ud589\ud558\uace0 \uad00\ub9ac\ud560 \uc218 \uc788\ub3c4\ub85d \uc9c0\uc6d0\ud558\ub294 \ud50c\ub7ab\ud3fc</li> <li>\ub85c\uceec\ud658\uacbd \uc5d0\uc11c \uc624\ud508\uc18c\uc2a4 \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ub2e4\uc6b4 \ubc1b\uace0 \uc0ac\uc6a9\ud574 \ubcfc \uc218 \uc788\uc74c</li> <li>\ub300\ud45c\uc801\uc778 \uc5b8\uc5b4 \ubaa8\ub378\uc740 \ub2e4\uc74c\uacfc \uac19\ub2e4<ul> <li>Llama3<ul> <li>Meta\uc5d0\uc11c \uac1c\ubc1c\ud55c \ucd5c\uc2e0 \uc5b8\uc5b4 \ubaa8\ub378\ub85c, \uc790\uc5f0\uc5b4 \ucc98\ub9ac \uc131\ub2a5\uc774 \uc6b0\uc218</li> </ul> </li> <li>Phi 3<ul> <li>Microsoft Research\uc5d0\uc11c \uac1c\ubc1c\ud55c \ubaa8\ub378\ub85c, \ub6f0\uc5b4\ub09c \ucd94\ub860 \ubc0f \uc5b8\uc5b4 \uc774\ud574 \ub2a5\ub825 \ubcf4\uc720</li> </ul> </li> <li>Mistral<ul> <li>\ub2e4\uc591\ud55c \uc5b8\uc5b4 \uc791\uc5c5\uc5d0 \ucd5c\uc801\ud654\ub41c \ubaa8\ub378\ub85c, \uace0\uc131\ub2a5\uc744 \uc790\ub791\ud568</li> </ul> </li> <li>Gemma 2<ul> <li>Google\uc5d0\uc11c \uac1c\ubc1c\ud55c \ubaa8\ub378\ub85c, \uc790\uc5f0\uc5b4 \ucc98\ub9ac \ubc0f \uc0dd\uc131 \uc791\uc5c5\uc5d0 \uac15\uc810</li> </ul> </li> <li>CodeGemma<ul> <li>\ucf54\ub4dc \uc0dd\uc131 \ubc0f \uc644\uc131\uc5d0 \ud2b9\ud654\ub41c \ubaa8\ub378\ub85c, \ub2e4\uc591\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uc791\uc5c5\uc744 \uc9c0\uc6d0</li> </ul> </li> </ul> </li> <li>\uc624\ud508\ub41c \uc5b8\uc5b4\ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\ubcf4\uac70\ub098, \ucee4\uc2a4\ud140 \ubaa8\ub378 \uc0dd\uc131 \ubc0f \ubc30\ud3ec\ub4f1\ub4f1 \uc0ac\uc6a9\uc790 \uce5c\ud654\uc801\uc778 \uc778\ud130\ud398\uc774\uc2a4\ub97c \ud1b5\ud55c \uc5b8\uc5b4 \ubaa8\ub378 \uc2e4\ud589 \ubc0f \uad00\ub9ac\ub97c ollama\ub97c \uc774\uc6a9\ud574 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c</li> </ul> </li> </ul>"},{"location":"user-guide/platform-guide/ollama-llama3/#1-gcube","title":"1. gcube \ud50c\ub7ab\ud3fc \uc6cc\ud06c\ub85c\ub4dc \uc11c\ube44\uc2a4 \ub4f1\ub85d \uc808\ucc28","text":"<ul> <li> <p>\uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131 \ubc0f \ubc30\ud3ec</p> <ul> <li>gcube.ai \uc811\uc18d \ubc0f \uc6cc\ud06c\ub85c\ub4dc \ud398\uc774\uc9c0 \uc774\ub3d9</li> <li> <p>\ud574\ub2f9 \ud398\uc774\uc9c0\uc5d0\uc11c \uc0c8 \uc6cc\ud06c\ub85c\ub4dc\ub97c \ub4f1\ub85d\ud558\uac70\ub098 \uae30\uc874\uc5d0 \ub4f1\ub85d\ub41c \uc6cc\ud06c\ub85c\ub4dc\ub97c \uc218\uc815\ud558\uc5ec \uc815\ubcf4 \uc785\ub825</p> <p></p> </li> </ul> </li> <li> <p>\uc124\uba85 \uac1c\uc694</p> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc774\ub984 \uc791\uc131<ul> <li>ex : ollama</li> </ul> </li> </ul> </li> </ul> <p></p> <ul> <li> <p>\ucee8\ud14c\uc774\ub108 \uac1c\uc694</p> <ul> <li>\uc800\uc7a5\uc18c \uc720\ud615 \uc120\ud0dd \ubc0f \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc120\ud0dd<ul> <li>\ub3c4\ucee4\ud5c8\ube0c\uc5d0 ollama \uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uacf5\uc2dd \uc774\ubbf8\uc9c0\uac00 \uc788\uc73c\ubbc0\ub85c \ud574\ub2f9 \uc774\ubbf8\uc9c0 \uc0ac\uc6a9<ul> <li>\ucc38\uc870 url : https://hub.docker.com/r/ollama/ollama</li> </ul> </li> <li>\uc800\uc7a5\uc18c \uc720\ud615 : \ub3c4\ucee4\ud5c8\ube0c</li> <li>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 : ollama/ollama:latest</li> <li> <p>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \ub808\uc774\uc5b4\uc758 \uba54\ud0c0\ub370\uc774\ud130(ExposedPorts)\ub97c \ud655\uc778\ud558\uc5ec \ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8\uac00 \uc790\ub3d9\uc73c\ub85c \uc791\uc131\ub41c\ub2e4 (ollama \uc758 \uacbd\uc6b0 11434)</p> <p></p> </li> </ul> </li> </ul> </li> <li> <p>\ubaa9\uc801\uc2a4\ud399 \uac1c\uc694</p> <ul> <li>\uc0ac\uc6a9\ud558\uace0\uc790 \ud558\ub294 \uc2a4\ud399\uc744 \uc815\ud55c\ub2e4<ul> <li>Tier1 : \uace0\uc131\ub2a5</li> <li>Tier2 : \uace0\uc2e0\ub8b0\uc131</li> <li>Tier3 : \uac1c\uc778 \uc0ac\uc6a9\uc790\ub4e4</li> <li>GPU \uba54\ubaa8\ub9ac : \uac00\uc6a9 GPU \ud544\ud130\ub9c1<ul> <li>\ubcf8 \uc608\uc81c\uc5d0\uc11c\ub294 Tier3 RTX3060 \uc744 \uc120\ud0dd</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p></p> <ul> <li>\uc635\uc158 \uac1c\uc694 (optional)<ul> <li>\ucee8\ud14c\uc774\ub108 \uba85\ub839<ul> <li>Dockerfile \uc758 CMD \ud56d\ubaa9 (\ucee8\ud14c\uc774\ub108 \uc2e4\ud589 \uc2dc \uc2dc\uc791\ub420 \uba85\ub839\uc5b4)<ul> <li>\ud615\uc2dd : CMD [\"executable\", \"param1\", \"param2\"] / CMD [\u201cecho\u201c, \u201cHello, world!\u201c]</li> </ul> </li> </ul> </li> <li>\ucee8\ud14c\uc774\ub108 \ud658\uacbd\ubcc0\uc218<ul> <li>Dockerfile \uc758 ENV \ud56d\ubaa9 (\ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ud658\uacbd\ubcc0\uc218)<ul> <li>\ud615\uc2dd : ENV   / ENV DEF_PORT 9999 <li>\ub808\ud50c\ub9ac\uce74<ul> <li>\ucee8\ud14c\uc774\ub108\uc758 \uc778\uc2a4\ud134\uc2a4\uac00 \uc11c\ub85c \ub2e4\ub978 \ub178\ub4dc\uc5d0\uc11c \ub3d9\uc2dc\uc5d0 \uc2e4\ud589\ub418\ub294 \uac1c\uc218</li> <li>\ubaa9\uc801<ul> <li>\uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \uc2e0\ub8b0\uc131\uacfc \ucc98\ub9ac\ub7c9 \ud5a5\uc0c1</li> <li>\ud2b9\uc815 \ub178\ub4dc\uc5d0 \ubb38\uc81c \ubc1c\uc0dd\ud574\ub3c4 \uc11c\ube44\uc2a4 \uc720\uc9c0</li> <li>\ub300\uae30 \uc2dc\uac04\uc744 \uc904\uc774\uace0 \uac1c\ubc1c\uc790 \uacbd\ud5d8 \ud5a5\uc0c1</li> <li>L7 Consistent Hashing \uae30\ubc95<ul> <li>\uc694\uccad\uc744 \ud0a4(key) \uae30\ubc18\uc73c\ub85c \ud2b9\uc815 \ubc31\uc5d4\ub4dc\ub85c \ub77c\uc6b0\ud305</li> <li>\ud574\uc2dc \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud2b8\ub798\ud53d\uc744 \uc77c\uad00\ub418\uac8c \ubd84\ubc30</li> <li>\ub178\ub4dc\ub098 \uc11c\ubc84\uac00 \ucd94\uac00\ub418\uac70\ub098 \uc81c\uac70\ub420 \ub54c\uc5d0\ub3c4 \ucd5c\uc18c\ud55c\uc758 \uc694\uccad\ub9cc \ub2e4\ub978 \uc11c\ubc84\ub85c \uc774\ub3d9\ub418\ub3c4\ub85d \ubcf4\uc7a5</li> </ul> </li> </ul> </li> </ul> </li> <li>CUDA<ul> <li>\ubc84\uc804 \uc120\ud0dd</li> </ul> </li> <li>\uacf5\uc720 \uba54\ubaa8\ub9ac<ul> <li>\ub9ac\ub205\uc2a4 \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uacf5\uc720 \uba54\ubaa8\ub9ac \uc601\uc5ed (/dev/shm)</li> <li>\ud504\ub85c\uc138\uc2a4 \uac04 \ub370\uc774\ud130 \uacf5\uc720\ub97c \uc704\ud574 \uc124\uacc4\ub41c \uc601\uc5ed (\ub300\uaddc\ubaa8 \ub370\uc774\ud130 \ucc98\ub9ac\ub97c \uc704\ud55c \uace0\uc18d \uc784\uc2dc \uc2a4\ud1a0\ub9ac\uc9c0)</li> </ul> </li> <p></p> <p></p> <ul> <li>\ucd1d \uc608\uc0c1\uae08\uc561 \uac1c\uc694<ul> <li>\uc120\ud0dd\ud55c \uc2a4\ud399\uc758 \ucd5c\ub300 \uc2dc\uac04\ub2f9 \uac00\uaca9 \uc815\ubcf4</li> <li>\ub0b4\uc6a9 \ud655\uc778 \ud6c4 \ub4f1\ub85d \uc9c4\ud589<ul> <li>\u2018\uc989\uc2dc\ubc30\ud3ec\u2019 \uc120\ud0dd \uc2dc \ub4f1\ub85d \ubc0f \ubc30\ud3ec \uc9c4\ud589</li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"user-guide/platform-guide/ollama-llama3/#2-gcube","title":"2. gcube \ud50c\ub7ab\ud3fc \uc6cc\ud06c\ub85c\ub4dc \uc11c\ube44\uc2a4 \uc0ac\uc6a9 \ubc29\ubc95","text":"<ul> <li>\uc0dd\uc131\ub41c \uc6cc\ud06c\ub85c\ub4dc \ud655\uc778<ul> <li>\uc6cc\ud06c\ub85c\ub4dc \ud398\uc774\uc9c0(https://gcube.ai/ko/demand/workload/list )\uc5d0\uc11c \uc0dd\uc131\ud55c \uc6cc\ud06c\ub85c\ub4dc \uc774\ub984 \ud074\ub9ad \uc2dc, \uc6cc\ud06c\ub85c\ub4dc \uc138\ubd80 \uc815\ubcf4 \uc9c4\uc785 \uac00\ub2a5</li> </ul> </li> </ul> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc138\ubd80 \uc815\ubcf4 \uac1c\uc694<ul> <li>\uac1c\uc694 : \uc6cc\ud06c\ub85c\ub4dc \ubc88\ud638, \uc124\uba85, \uc720\ud615, \uc0c1\ud0dc, \uc11c\ube44\uc2a4 URL \uc815\ubcf4 \ub4f1</li> <li>\ucee8\ud14c\uc774\ub108 : \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0, \ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8, \uc800\uc7a5\uc18c \uc720\ud615, \uc0dd\uc131\uc77c\uc2dc, \ubc30\ud3ec\uc77c\uc2dc, \uc885\ub8cc\uc77c\uc2dc \uc815\ubcf4 \ub4f1</li> <li>\ubaa9\uc801\uc2a4\ud399 : \ubaa9\uc801\ub178\ub4dc, GPU \uba54\ubaa8\ub9ac, GPU \uc815\ubcf4 \ub4f1</li> <li>\uc635\uc158 : \ucee8\ud14c\uc774\ub108 \uba85\ub839, \ucee8\ud14c\uc774\ub108 \ud658\uacbd\ubcc0\uc218, \ub808\ud50c\ub9ac\uce74, \ucd5c\uc18c CUDA \ubc84\uc804, \uacf5\uc720 \uba54\ubaa8\ub9ac \uc815\ubcf4 \ub4f1</li> <li>\ubc30\ud3ec\uc0c1\ud0dc : \ucee8\ud14c\uc774\ub108 \ubc30\ud3ec \uc774\ubca4\ud2b8, \ub178\ub4dc, \ud30c\ub4dc, \ud30c\ub4dc \uc0c1\ud0dc, \ucee8\ud14c\uc774\ub108 \ub85c\uadf8, \ucee8\ud14c\uc774\ub108 \ud130\ubbf8\ub110, \ucee8\ud14c\uc774\ub108 SSH \uc815\ubcf4 \ub4f1</li> </ul> </li> </ul> <ul> <li>\ud30c\ub4dc\uc0c1\ud0dc\uac00 \u2018\uc2e4\ud589\u2019 \uc778 \uacbd\uc6b0<ul> <li>'\ucee8\ud14c\uc774\ub108 SSH' \ud074\ub9ad\ud558\uc5ec \uacf5\uc778IP \uc870\ud68c \ubc0f \uc811\uc18d\uc815\ubcf4 \ub4f1\ub85d<ul> <li>\uc815\ubcf4 \ub4f1\ub85d \uc2dc SSH \uc811\uc18d \uad00\ub828 \uc815\ubcf4 \ud655\uc778</li> </ul> </li> </ul> </li> </ul> <ul> <li>\ud130\ubbf8\ub110 \ud504\ub85c\uadf8\ub7a8 (ex: putty) \uc2e4\ud589 \ud6c4 \uc704\uc5d0\uc11c \ud655\uc778\ud55c SSH \uc811\uc18d \uc815\ubcf4 \uc785\ub825\ud558\uc5ec \ucee8\ud14c\uc774\ub108 \uc811\uc18d<ul> <li>IP, Port, \uc0ac\uc6a9\uc790 \uc544\uc774\ub514, \uc0ac\uc6a9\uc790 \ube44\ubc00\ubc88\ud638 \ub4f1</li> </ul> </li> </ul> <ul> <li>\ud574\ub2f9 CLI \uc5d0\uc11c \ud558\uae30 \ucee4\ub9e8\ub4dc \uc785\ub825\ud558\uc5ec llama3 \uc5b8\uc5b4 \ubaa8\ub378 \ub2e4\uc6b4 \ubc0f \uc2e4\ud589 (\uc57d 4.7GB)<ul> <li>ollama run llama3</li> </ul> </li> </ul> <ul> <li>\uc774\ud6c4 Llama3 \ubaa8\ub378\ub85c, ChatGPT \ucc98\ub7fc AI \ucd94\ub860 \uc11c\ube44\uc2a4\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c<ul> <li>ex)</li> </ul> </li> </ul> <p>Q : How to make pizza?</p> <p>A : Ingredients:</p> <ul> <li>2 cups of warm water</li> <li>1 tablespoon of sugar</li> <li>2 teaspoons of active dry yeast</li> <li>3 1/2 cups of all-purpose flour</li> <li>1 teaspoon of salt</li> <li>2 tablespoons of olive oil</li> <li>Pizza sauce (homemade or store-bought)</li> <li>Shredded mozzarella cheese (and any other toppings you like!)</li> <li>Fresh basil leaves, chopped (optional)</li> </ul> <p>Instructions:</p> <ol> <li>Make the dough: In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for 5-10 minutes until the yeast is activated and foamy.</li> <li>Add the flour, salt, and olive oil to the bowl. Mix until a shaggy dough forms.</li> <li>Knead the dough: Turn the dough out onto a floured surface and knead for 5-10 minutes, until the dough becomes smooth and elastic.</li> <li>Let it rise: Place the dough in a lightly oiled bowl, cover it with plastic wrap or a damp cloth, and let it rise in a warm place for about an hour, or until it has doubled in size.</li> <li>Punch down the dough: Gently punch down the dough to release any air bubbles.</li> <li>Shape the crust: Use your hands to shape the dough into your desired pizza crust shape (e.g., circle, rectangle, etc.).</li> <li>Roll out the crust: Roll out the crust to your desired thickness (about 1/4 inch is a good starting point).</li> <li>Preheat the oven: Preheat your oven to 425\u00b0F (220\u00b0C) with a baking sheet or pizza stone inside.</li> <li>Add sauce and toppings: Spread a thin layer of pizza sauce over the crust, leaving a small border around the edges. Add your desired toppings, such as shredded mozzarella cheese, pepperoni slices, mushrooms, bell peppers, olives, etc.</li> <li>Bake the pizza: Place the pizza on the preheated baking sheet or stone and bake for 12-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.</li> <li>Add fresh basil (optional): Sprinkle some chopped fresh basil leaves over the top of the pizza for a pop of color and flavor.</li> <li>Enjoy your pizza: Remove the pizza from the oven and let it cool for a few minutes before slicing and serving.</li> </ol> <p>Tips and Variations:</p> <ul> <li>Use a pizza peel or piece of parchment paper to transfer the dough to the preheated baking sheet or stone if you don't have a pizza stone.</li> <li>Try different topping combinations, such as Hawaiian-style with ham and pineapple, or Mediterranean-style with feta cheese and olives.</li> <li>Experiment with various crust flavors by adding herbs, spices, or garlic powder to the dough before kneading.</li> <li>Make mini pizzas using individual portions of dough and toppings for a fun appetizer or snack.</li> </ul> <p>Remember, making pizza is all about having fun and being creative! Don't be afraid to try new things and experiment with different flavors and combinations. Happy baking!</p> <p>ex2)</p> <p></p>"},{"location":"user-guide/platform-guide/stable-diffusion/","title":"Stable Diffusion \uc0ac\uc6a9 \uac00\uc774\ub4dc","text":""},{"location":"user-guide/platform-guide/stable-diffusion/#0","title":"0. \uc0ac\uc804\uc900\ube44","text":"<ul> <li> <p>Stable Diffusion\ub780?</p> <ul> <li>Text-to-Image, Image-to Image \uc624\ud508\uc18c\uc2a4 \uc0dd\uc131\ud615 \uc778\uacf5\uc9c0\ub2a5 \ubaa8\ub378</li> <li>\ucef4\ud4e8\ud305 \ub9ac\uc18c\uc2a4\ub97c \ub300\ud3ed \uc904\uc5ec GPU\uac00 \uc7a5\ucc29\ub41c \uac1c\uc778 \ucef4\ud4e8\ud130\uc5d0\uc11c\ub3c4 \uc2e4\ud589 \uac00\ub2a5</li> <li>\uc628\ub77c\uc778 \ud658\uacbd\uc774 \uc544\ub2cc \uac1c\uc778\uc758 PC\uc5d0\uc11c \u2018\ub85c\uceec \ud658\uacbd\u2019\uc73c\ub85c \uc124\uce58 \ubc0f \uc2e4\ud589 \uac00\ub2a5 </li> </ul> </li> <li> <p>gcube \ud68c\uc6d0 \uac00\uc785 \ubc0f \ud3ec\uc778\ud2b8 \uad6c\ub9e4</p> <ul> <li>gcube \ud648\ud398\uc774\uc9c0(http://gcube.ai)\uc5d0\uc11c \ud68c\uc6d0 \uac00\uc785 \uc9c4\ud589</li> </ul> <p></p> <p></p> <ul> <li>\ub85c\uadf8\uc778\ud558\uc5ec \uc0ac\uc6a9\uc790 \ubaa8\ub4dc\ub85c \uc811\uc18d</li> </ul> <p></p> <ul> <li>\uc88c\uce21\uc758 \u201c\ud3ec\uc778\ud2b8 \ucda9\uc804\u201d \uba54\ub274\ub97c \ud074\ub9ad</li> </ul> <p></p> <ul> <li>\uc6d0\ud558\ub294 \ub9cc\ud07c\uc758 \ucda9\uc804 \ud3ec\uc778\ud2b8\ub97c \ud074\ub9ad \ud6c4 \uacb0\uc81c \ubc29\ubc95\uc744 \uc120\ud0dd, \u201c\uacb0\uc81c\u201d \ubc84\ud2bc\uc73c\ub85c \uacb0\uc81c \uc9c4\ud589</li> </ul> <p></p> </li> </ul>"},{"location":"user-guide/platform-guide/stable-diffusion/#1-gcube-stable-diffusion","title":"1. gcube \ud50c\ub7ab\ud3fc stable diffusion \uc6cc\ud06c\ub85c\ub4dc \uc900\ube44","text":"<ul> <li> <p>\uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d</p> <ul> <li>\ub85c\uadf8\uc778 \ud6c4 \uc88c\uce21\uce21\uc758 \u201c\uc0c8 \uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131\u201d \uba54\ub274\ub97c \ud074\ub9ad</li> </ul> <p></p> </li> <li> <p>\uc6cc\ud06c\ub85c\ub4dc \uc815\ubcf4 stable diffusion \uc138\ud305</p> <ul> <li>\uc124\uba85 : \uc6cc\ud06c\ub85c\ub4dc \uc124\uba85\uc5d0 [ Stable Diffusion ]\uc744 \uc785\ub825</li> </ul> <p></p> <ul> <li>\ucee8\ud14c\uc774\ub108 : stable diffusion\uc744 \uc0ac\uc6a9\ud560 \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc124\uc815<ul> <li>\uc800\uc7a5\uc18c \uc720\ud615 : \ub3c4\ucee4\ud5c8\ube0c</li> <li>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 : [ universonic/stable-diffusion-webui ]<ul> <li>\uc785\ub825\ub780 \uc606 \uc774\ubbf8\uc9c0 \uac80\uc99d \ubc84\ud2bc \ud074\ub9ad\ud558\uc5ec \uac80\uc99d \uc644\ub8cc \uc2dc \ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8\ub294 \uc790\ub3d9\uc73c\ub85c \uc785\ub825</li> </ul> </li> <li>\ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8 : 8080 (\uc790\ub3d9\uc73c\ub85c \ud3ec\ud2b8 \uc124\uc815)</li> </ul> </li> </ul> <p></p> <ul> <li>\ubaa9\uc801 \uc2a4\ud399 : stable diffusion\uc774 \uad6c\ub3d9 \ub420 \ud658\uacbd\uc744 \uc124\uc815<ul> <li>\ubaa9\uc801\ub178\ub4dc : Tier 3 (\uac1c\uc778 \uc0ac\uc6a9\uc790\ub4e4\uc744 \uc704\ud55c \ud2f0\uc5b4)</li> <li>GPU \uba54\ubaa8\ub9ac : 8GB</li> <li>GPU : RTX 3080 X 1 10GB</li> </ul> </li> </ul> <p></p> <ul> <li>\uc635\uc158 (\uc120\ud0dd \uc0ac\ud56d) : \ucee8\ud14c\uc774\ub108 \uc138\ubd80 \uc124\uc815<ul> <li>\ucee8\ud14c\uc774\ub108 \uba85\ub839 : \ucee8\ud14c\uc774\ub108 \uc2dc\uc791 \uba85\ub839\uc5b4\ub97c \uc124\uc815. \uacf5\ub780\uc77c \ub54c \uae30\ubcf8 \uba85\ub839\uc5b4 \uc2e4\ud589</li> <li>\ucee8\ud14c\uc774\ub108 \ud658\uacbd\ubcc0\uc218 : \ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ud658\uacbd \ubcc0\uc218\ub97c \uc124\uc815</li> <li>\ub808\ud50c\ub9ac\uce74 : \ub3d9\uc77c\ud55c \ucee8\ud14c\uc774\ub108\uc758 \ubcd1\ub82c \uc2e4\ud589 \uac1c\uc218\ub97c \uc124\uc815</li> <li>\ucd5c\uc18c CUDA \ubc84\uc804 : \ucee8\ud14c\uc774\ub108\uac00 \uc694\uad6c\ud558\ub294 \ucd5c\uc18c CUDA \ubc84\uc804\uc744 \uc9c0\uc815</li> <li>\uacf5\uc720 \uba54\ubaa8\ub9ac : \ucee8\ud14c\uc774\ub108\uac00 \uacf5\uc720 \uac00\ub2a5\ud55c \uba54\ubaa8\ub9ac \ud06c\uae30\ub97c \uc9c0\uc815</li> <li>\u203b \uc774\ubc88 \uac00\uc774\ub4dc\uc5d0\uc11c\ub294 \uc635\uc158 \uc124\uc815\uc744 \ud558\uc9c0 \uc54a\uace0 \uc9c4\ud589</li> </ul> </li> </ul> <p></p> <ul> <li>\ucd1d \uc608\uc0c1 \uae08\uc561 : \uc120\ud0dd\ud55c \uc11c\ube44\uc2a4\uc5d0 \ub300\ud55c \uc608\uc0c1 \uc0ac\uc6a9 \uc694\uae08\uc744 \uc0b0\uc815<ul> <li>\uc989\uc2dc \ubc30\ud3ec \uc606 \uccb4\ud06c\ubc15\uc2a4\ub97c \ud074\ub9ad\ud558\uc5ec \ub4f1\ub85d\uacfc \ub3d9\uc2dc\uc5d0 \ubc30\ud3ec</li> <li>\u201c\ub4f1\ub85d\u201d \ubc84\ud2bc\uc73c\ub85c \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d</li> </ul> </li> </ul> <p></p> </li> </ul>"},{"location":"user-guide/platform-guide/stable-diffusion/#2-gcube-stable-diffusion","title":"2. gcube \ud50c\ub7ab\ud3fc stable diffusion \uc6cc\ud06c\ub85c\ub4dc \uc2e4\ud589","text":"<ul> <li>\uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \ud6c4 \ud654\uba74</li> </ul> <ul> <li> <p>\uc0dd\uc131\ub41c \uc6cc\ud06c\ub85c\ub4dc \uc815\ubcf4 \ud655\uc778</p> <ul> <li>\u201cStable Diffusion\u201d\uc744 \ud074\ub9ad</li> </ul> <p></p> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc815\ubcf4 \ud654\uba74 \uac00\uc7a5 \ud558\ub2e8\uc758 \u201c\ubc30\ud3ec \uc0c1\ud0dc\u201d\ub97c \ud655\uc778</li> </ul> <p></p> <ul> <li>\ubc30\ud3ec \uc0c1\ud0dc\uc758 \ud53c\ub4dc \uc0c1\ud0dc\uac00 \u201c\uc2e4\ud589\u201d\uc778\uc9c0 \ud655\uc778</li> <li>\u201c\ucee8\ud14c\uc774\ub108 \ub85c\uadf8\u201d \ubc84\ud2bc \ud074\ub9ad</li> </ul> <p></p> <ul> <li>\ucee8\ud14c\uc774\ub108 \ub85c\uadf8\uc5d0\uc11c \uc774\ubbf8\uc9c0\uc640 \uac19\uc740 \ubb38\uad6c\uac00 \ub098\uc624\uba74 \uc124\uce58 \uc644\ub8cc</li> <li>\u203b \ucee8\ud14c\uc774\ub108 \uc124\uc815\uacfc \uc2e4\ud589\ud558\ub294 \uae30\uae30\uc5d0 \ub530\ub77c\uc11c \uc2dc\uac04\uc774 \ub2e4\uc18c \uac78\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.(\ucd5c\ub300 30\ubd84)</li> </ul> <p></p> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc815\ubcf4 \ud654\uba74\uc73c\ub85c \ub3cc\uc544\uc640 \u201c\uc11c\ube44\uc2a4 URL \ub9c1\ud06c\u201d\uc744 \ud074\ub9ad</li> <li>\u203b \ucee8\ud14c\uc774\ub108 \ub85c\uadf8 \ud655\uc778 \uc5c6\uc774 \ub9c1\ud06c\ub97c \ud074\ub9ad \uc2dc \uc791\ub3d9 \ud654\uba74\uc774 \ud45c\uc2dc\ub418\uc9c0 \uc54a\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> </ul> <p></p> <ul> <li>\uc544\ub798\uc640 \uac19\uc740 \ud654\uba74\uc774 \ub098\uc628\ub2e4\uba74 Stable Diffusion \uc791\ub3d9 \uc131\uacf5</li> </ul> <p></p> </li> </ul>"},{"location":"user-guide/platform-guide/stable-diffusion/#3-gcube-stable-diffusion","title":"3. gcube \ud50c\ub7ab\ud3fc stable diffusion \uc2e4\ud589 \uc608\uc2dc","text":"<ul> <li> <p>Stable Diffusion \uc2e4\ud589 \uc608\uc2dc</p> <ul> <li>txtimg\uce78\uc5d0 \u201cA cat in a Hat\u201d \ubb38\uad6c\ub97c \uc785\ub825 \ud6c4 \u201cGenerate\u201d \ubc84\ud2bc \ud074\ub9ad</li> </ul> <p></p> <ul> <li>\uc544\ub798\uc640 \uac19\uc740 \uc774\ubbf8\uc9c0\uac00 \uc0dd\uc131\ub418\ub294 \uac83\uc744 \ud655\uc778</li> <li>\u203b \ud45c\uc2dc\ub418\ub294 \uc774\ubbf8\uc9c0\ub294 \uc0c1\uc774\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> </ul> <p></p> </li> </ul>"},{"location":"user-guide/sign-up/sign-up/","title":"\uacc4\uc815\uc0dd\uc131","text":""},{"location":"user-guide/sign-up/sign-up/#_2","title":"\ud68c\uc6d0\uac00\uc785&amp;\ub85c\uadf8\uc778","text":"<p>1. \ud648\ud398\uc774\uc9c0 \uc6b0\uce21 \uc0c1\ub2e8\uc758 \u201c\ub85c\uadf8\uc778\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694.</p> <p></p> <p>2. \ub85c\uadf8\uc778 \ud654\uba74 \ud558\ub2e8\uc758 \u2018\ud68c\uc6d0\uac00\uc785\u2019 \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694.</p> <p></p> <p>3. \uad6c\uae00 / \ub9c8\uc774\ud06c\ub85c\uc18c\ud504\ud2b8 \uc911 \uc6d0\ud558\ub294 \uacc4\uc815\uc73c\ub85c \uac04\ud3b8 \ud68c\uc6d0\uac00\uc785\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4.</p> <p></p> <p>4. \uc0ac\uc6a9\ud558\uc2e4 \uacc4\uc815\uc744 \uc120\ud0dd\ud558\uc2e0 \ud6c4, \uc57d\uad00\ub3d9\uc758\ub97c \uc9c4\ud589\ud558\uc2e0 \ub2e4\uc74c \ud68c\uc6d0 \uc815\ubcf4\ub97c \uc785\ub825\ud558\uc5ec \ud68c\uc6d0\uac00\uc785\uc744 \uc644\ub8cc\ud569\ub2c8\ub2e4. </p> <p></p> <p>5. \ub85c\uadf8\uc778 \ud398\uc774\uc9c0\ub85c \uc774\ub3d9\ud558\uc5ec \uac00\uc785\ud55c \uc774\uba54\uc77c \uacc4\uc815\uc744 \uc120\ud0dd\ud558\uc5ec \ub85c\uadf8\uc778\ud569\ub2c8\ub2e4. </p> <p></p> <p>6. \ub85c\uadf8\uc778 \ud6c4, gcube\uc758 \ubaa8\ub4e0 \uc11c\ube44\uc2a4\ub97c \uc774\uc6a9\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc88c\uce21 \uba54\ub274 \uc0c1\ub2e8 \ubaa8\ub4dc \ubcc0\uacbd \ubc84\ud2bc\uc744 \ud1b5\ud574 \uc6cc\ud06c\ub85c\ub4dc \ubc30\ud3ec \ubaa8\ub4dc\uc640 \ub178\ub4dc \uacf5\uae09\ubaa8\ub4dc\ub97c \uc804\ud658\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p>GCUBE \ub85c\uadf8\uc778 \ubc14\ub85c\uac00\uae30</p>"},{"location":"user-guide/workload/deploy-workload/","title":"\uc6cc\ud06c\ub85c\ub4dc \ubc30\ud3ec","text":"<p>\ub4f1\ub85d\ub41c \uc6cc\ud06c\ub85c\ub4dc\ub294 \ubc30\ud3ec\ub97c \ud1b5\ud574 \uc790\uc6d0 \ud65c\uc6a9\uc744 \uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uc6cc\ud06c\ub85c\ub4dc\uc5d0\uc11c \ubc30\ud3ec\ud560 \uc6cc\ud06c\ub85c\ub4dc \ud56d\ubaa9\uc758 \u201c\ubc30\ud3ec\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad \ud6c4, \u201c\ud655\uc778\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694. </p> <p></p> <p>2. \uc6b0\uce21 \uc0c1\ub2e8\uc758 \uc6cc\ud06c\ub85c\ub4dc \uc0c1\ud0dc\uac00 \ubbf8\ubc30\ud3ec \u2192 \ubc30\ud3ec \uc0c1\ud0dc\ub85c \ubcc0\uacbd\ub418\uba70, \uc11c\ube44\uc2a4 URL\uc774 \ud65c\uc131\ud654 \ub418\ub294 \uac83\uc744 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\uba87 \ubd84\uc815\ub3c4 \uc2dc\uac04\uc774 \uc18c\uc694\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.)</p>"},{"location":"user-guide/workload/example-workload/","title":"\uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \uc608\uc2dc","text":"<p>\uc774 \ubb38\uc11c\ub294 \ub525\ub7ec\ub2dd \uac1c\ubc1c\uc744 \uc704\ud55c \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \uc608\uc2dc\ub97c \uc124\uba85\ud569\ub2c8\ub2e4.  \uc2e4\uc81c \ub4f1\ub85d \ubc29\ubc95\uc740 \uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \ubb38\uc11c\ub97c \ucc38\uace0\ud574 \uc8fc\uc138\uc694. </p>"},{"location":"user-guide/workload/example-workload/#_2","title":"\uac1c\uc694","text":"<p><code>koojy717/lora-tuning-blackwell:1.01</code> \uc774\ubbf8\uc9c0\ub294 \ub525\ub7ec\ub2dd \uac1c\ubc1c\uc744 \ud544\uc694\ud55c \uc8fc\uc694 \ud504\ub808\uc784\uc6cc\ud06c\uc640 \ub3c4\uad6c\ub4e4\uc774 \ud3ec\ud568 \ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/workload/example-workload/#_3","title":"\uc8fc\uc694 \uad6c\uc131 \uc694\uc18c","text":"<ul> <li>PyTorch 2.7.0 (CUDA 12.8 \uc9c0\uc6d0)</li> <li>TensorFlow 2.12.0</li> <li>Transformers 4.28.0</li> <li>PEFT 0.3.0</li> <li>Jupyter Notebook/Lab \ud658\uacbd</li> <li>\uc2dc\uc2a4\ud15c \uad00\ub9ac \ub3c4\uad6c (net-tools, ping, traceroute)</li> </ul> <p>\u203b Pytorch 2.7.0 \ubc84\uc804\uc740 Nvidia\uc758 blackwell \uc544\ud0a4\ud14d\ucc98\uc5d0 \ub9de\ucdb0 \uae09\ud558\uac8c \uac1c\ubc1c\ub41c nightly \ubc84\uc804\uc73c\ub85c \uc77c\uad00\ub41c \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0 \uc54a\uc744 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc774\uc804 \ubc84\uc804\uc758 Pytorch\ub97c \uc0ac\uc6a9\ud558\uace0 \uc2f6\uc73c\uc2dc\ub2e4\uba74 <code>koojy717/lora-tuning:1.02</code> \uc774\ubbf8\uc9c0\ub97c \uc774\uc6a9\ud558\uc2dc\uba74 \ub418\uaca0\uc2b5\ub2c8\ub2e4.  \u203bPytorch 2.01(CUDA 11.8 \uc9c0\uc6d0) \uc0ac\uc6a9</p>"},{"location":"user-guide/workload/example-workload/#_4","title":"\uc6cc\ud06c\ub85c\ub4dc \uc124\uc815 \uac00\uc774\ub4dc","text":""},{"location":"user-guide/workload/example-workload/#_5","title":"\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0","text":"<pre><code>=== \"GitHub\"\n    ```\n    data-alliance/lora-tuning-blackwell:1.01\n    ```\n\n=== \"Docker Hub\"\n    ```\n    koojy717/lora-tuning-blackwell:1.01\n    ```\n\n=== \"\ud558\uc704 Pytorch \ubc84\uc804 Docker Hub\"\n        ```\n        koojy717/lora-tuning:1.02\n        ```\n</code></pre>"},{"location":"user-guide/workload/example-workload/#_6","title":"\ubaa9\uc801\uc2a4\ud399 \uc124\uc815","text":"<p>\uc791\uc5c5 \uaddc\ubaa8\uc5d0 \ub530\ub978 \uad8c\uc7a5 \uc124\uc815:</p> \ubaa9\uc801 Tier GPU \uba54\ubaa8\ub9ac \uc6a9\ub3c4 \ub300\uaddc\ubaa8 \ud559\uc2b5 Tier 1 (A100, H100) 40GB+ \ub300\uaddc\ubaa8 \ubaa8\ub378 \ud559\uc2b5, \ub192\uc740 \uc131\ub2a5 \ud544\uc694 \uc2dc \uc911\uaddc\ubaa8 \uc2e4\ud5d8 Tier 2 (\uc804\uc6a9 \uc11c\ubc84) 20GB \uc77c\ubc18\uc801\uc778 \ubaa8\ub378 \uac1c\ubc1c, \uc911\uaddc\ubaa8 \uc2e4\ud5d8 \uac1c\ubc1c/\ud14c\uc2a4\ud2b8 Tier 3 (PC\ubc29, \uac1c\uc778) 10GB \ucf54\ub4dc \uac1c\ubc1c, \uc18c\uaddc\ubaa8 \uc2e4\ud5d8 <p>\u26a1 \uc790\uc138\ud55c \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \ubc29\ubc95\uc740 \uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \ud398\uc774\uc9c0\ub97c \ucc38\uace0\ud574 \uc8fc\uc138\uc694.</p>"},{"location":"user-guide/workload/example-workload/#jupyter-notebook","title":"Jupyter Notebook \uc2dc\uc791\ud558\uae30","text":"<p>\uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131 \uc644\ub8cc \ud6c4, \uc0c1\uc138 \ud398\uc774\uc9c0\uc5d0\uc11c \uc81c\uacf5\ub418\ub294 Service URL\ub85c \uc811\uc18d\ud558\uc138\uc694.</p> <p>\uae30\ubcf8 \uc791\uc5c5 \ub514\ub809\ud1a0\ub9ac\uc5d0\uc11c \uc0c8 \ub178\ud2b8\ubd81\uc744 \uc0dd\uc131\ud558\uc5ec \uac1c\ubc1c \ud658\uacbd\uc744 \ud655\uc778\ud558\uace0, \uae30\ubcf8 \uc5f0\uc0b0 \ud14c\uc2a4\ud2b8\ub97c \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/workload/example-workload/#1","title":"1. \uae30\ubcf8 \ud658\uacbd \ud655\uc778","text":"<p>\uc2e4\ud589 \ucf54\ub4dc:</p> <pre><code>import torch\nimport tensorflow as tf\nimport transformers\n# \ubc84\uc804 \ud655\uc778print(f\"PyTorch: {torch.__version__}\")\nprint(f\"TensorFlow: {tf.__version__}\")\nprint(f\"Transformers: {transformers.__version__}\")\n# GPU \ud655\uc778print(f\"PyTorch GPU: {torch.cuda.is_available()}\")\nprint(f\"TensorFlow GPU: {tf.config.list_physical_devices('GPU')}\")\n</code></pre> <p>\uacb0\uacfc:</p> <pre><code>PyTorch: 2.0.1+cu118\nTensorFlow: 2.12.0\nTransformers: 4.28.0\nPyTorch GPU: True\nTensorFlow GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n</code></pre>"},{"location":"user-guide/workload/example-workload/#2-pytorch","title":"2. PyTorch \ud658\uacbd \ud14c\uc2a4\ud2b8","text":"<p>\uc2e4\ud589 \ucf54\ub4dc:</p> <pre><code>import torch\nif torch.cuda.is_available():\n    # GPU \uc815\ubcf4    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"\uba54\ubaa8\ub9ac: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    # \ud589\ub82c \uc5f0\uc0b0 \ud14c\uc2a4\ud2b8    a = torch.tensor([[1.0, 2.0], [3.0, 4.0]]).cuda()\n    b = torch.tensor([[5.0, 6.0], [7.0, 8.0]]).cuda()\n    # \ud589\ub82c \uacf1 \uc5f0\uc0b0    c = torch.matmul(a, b)\n    print(\"\\n\ud589\ub82c A:\")\n    print(a.cpu().numpy())\n    print(\"\\n\ud589\ub82c B:\")\n    print(b.cpu().numpy())\n    print(\"\\n\ud589\ub82c \uacf1 \uacb0\uacfc (A \u00d7 B):\")\n    print(c.cpu().numpy())\n</code></pre> <p>\uacb0\uacfc:</p> <pre><code>GPU: NVIDIA GeForce RTX 3060\n\uba54\ubaa8\ub9ac: 12.88 GB\n\n\ud589\ub82c A:\n[[1. 2.]\n [3. 4.]]\n\n\ud589\ub82c B:\n[[5. 6.]\n [7. 8.]]\n\n\ud589\ub82c \uacf1 \uacb0\uacfc (A \u00d7 B):\n[[19. 22.]\n [43. 50.]]\n</code></pre> <p>\ud83d\udd17 PyTorch \ud29c\ud1a0\ub9ac\uc5bc \ub354 \ubcf4\uae30</p>"},{"location":"user-guide/workload/example-workload/#3-tensorflow","title":"3. TensorFlow \ud658\uacbd \ud14c\uc2a4\ud2b8","text":"<p>\uc2e4\ud589 \ucf54\ub4dc:</p> <pre><code>import tensorflow as tf\nif tf.config.list_physical_devices('GPU'):\n    # GPU \uba54\ubaa8\ub9ac \uc124\uc815    gpus = tf.config.experimental.list_physical_devices('GPU')\n    tf.config.experimental.set_memory_growth(gpus[0], True)\n    # \uac04\ub2e8\ud55c \uc5f0\uc0b0 \ud14c\uc2a4\ud2b8    with tf.device('/GPU:0'):\n        x = tf.random.normal([1000, 1000])\n        y = tf.matmul(x, x)\n        print(\"GPU \uc5f0\uc0b0 \ud14c\uc2a4\ud2b8 \uc644\ub8cc\")\n</code></pre> <p>\uacb0\uacfc:</p> <pre><code>GPU \uc5f0\uc0b0 \ud14c\uc2a4\ud2b8 \uc644\ub8cc\n</code></pre> <p>\ud83d\udd17 TensorFlow \uc2dc\uc791\ud558\uae30</p>"},{"location":"user-guide/workload/example-workload/#4-transformers","title":"4. Transformers \ud658\uacbd \ud14c\uc2a4\ud2b8","text":"<p>\uc2e4\ud589 \ucf54\ub4dc:</p> <pre><code>from transformers import AutoModel, AutoTokenizer\nmodel_name = \"bert-base-uncased\"tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\nif torch.cuda.is_available():\n    model = model.cuda()\n    print(\"\ubaa8\ub378 GPU \ub85c\ub4dc \uc644\ub8cc\")\n</code></pre> <p>\uacb0\uacfc:</p> <pre><code>\ubaa8\ub378 GPU \ub85c\ub4dc \uc644\ub8cc\n</code></pre> <p>\ud83d\udd17 Transformers \ud29c\ud1a0\ub9ac\uc5bc \ub354 \ubcf4\uae30</p> <p>Warning</p> <p>\uc6cc\ud06c\ub85c\ub4dc \uc885\ub8cc \uc2dc, \uc791\uc5c5 \uc911\uc774\ub358 \ub370\uc774\ud130 \ubc0f \ud658\uacbd\uc740 \uc800\uc7a5\ub418\uc9c0 \uc54a\uc73c\ub2c8 \uc720\uc758\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.</p> <p>(\ud5a5\ud6c4 \uc678\ubd80 \uc2a4\ud1a0\ub9ac\uc9c0\ub97c \uc774\uc6a9\ud558\uc5ec \uc800\uc7a5\ud560 \uc218 \uc788\ub3c4\ub85d \uc5c5\ub370\uc774\ud2b8 \ud560 \uc608\uc815\uc785\ub2c8\ub2e4.)</p>"},{"location":"user-guide/workload/example-workload/#_7","title":"\ucc38\uace0 \uc790\ub8cc","text":"<ul> <li>PyTorch \ubb38\uc11c</li> <li>TensorFlow GPU \uac00\uc774\ub4dc</li> <li>Transformers \ubb38\uc11c</li> </ul> <p>\ubb38\uc81c\uac00 \ubc1c\uc0dd\ud558\uac70\ub098 \ucd94\uac00 \uc9c0\uc6d0\uc774 \ud544\uc694\ud55c \uacbd\uc6b0 gcube \uc9c0\uc6d0\ud300(gcube.ai@data-alliance.com)\uc5d0 \ubb38\uc758\ud574 \uc8fc\uc138\uc694.</p>"},{"location":"user-guide/workload/","title":"\uc6cc\ud06c\ub85c\ub4dc \uc0ac\uc6a9\uc790 \uac00\uc774\ub4dc","text":"<p>\ub300\uc26c\ubcf4\ub4dc</p> <p>\ud504\ub85c\ud544 \uc124\uc815</p> <p>\uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d</p> <p>\uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \uc608\uc2dc</p> <p>\uc6cc\ud06c\ub85c\ub4dc \ubc30\ud3ec</p> <p>\uc6cc\ud06c\ub85c\ub4dc \ubaa8\ub2c8\ud130\ub9c1</p> <p>\uc6cc\ud06c\ub85c\ub4dc \uc774\uc6a9\ub0b4\uc5ed</p> <p>\uc6cc\ud06c\ub85c\ub4dc \uc885\ub8cc</p> <p>\uc800\uc7a5\uc18c \uad00\ub9ac \uc124\uc815</p>"},{"location":"user-guide/workload/monitor-workload/","title":"\uc6cc\ud06c\ub85c\ub4dc \ubaa8\ub2c8\ud130\ub9c1","text":"<p>\ub4f1\ub85d\ub41c \uc6cc\ud06c\ub85c\ub4dc\uc758 \uc790\uc6d0\uc740 \u2018\ubaa8\ub2c8\ud130\ub9c1\u2019 \uae30\ub2a5\uc744 \ud1b5\ud574 \uc0ac\uc6a9\ub7c9\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p></p> <p>1. \uc6cc\ud06c\ub85c\ub4dc \ud56d\ubaa9 \uc6b0\uce21 \ud558\ub2e8\uc758 \u201c\ubaa8\ub2c8\ud130\ub9c1\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud569\ub2c8\ub2e4. </p> <p>2. \uc2e4\uc2dc\uac04 \ubaa8\ub2c8\ud130\ub9c1 \ud604\ud669\uc774 \ucd9c\ub825\ub418\uba70, \uc544\ub798\uc640 \uac19\uc740 \ud56d\ubaa9\uc744 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. - GPU \uc0ac\uc6a9\ub7c9 (%)  - GPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 (MB)  - CPU \uc0ac\uc6a9\ub7c9 (%)  - \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 (MB)  - \ub124\ud2b8\uc6cc\ud06c \ubc1b\uc740 \ud328\ud0b7 (Kbps)  - \ub124\ud2b8\uc6cc\ud06c \ubcf4\ub0b8 \ud328\ud0b7 (Kbps) </p> <p></p> <p></p> <p></p>"},{"location":"user-guide/workload/profile-settings/","title":"\ud504\ub85c\ud544 \uc124\uc815","text":"<p>\ud504\ub85c\ud544 \uc124\uc815\uc744 \ud1b5\ud574 \uacc4\uc815\uc758 \uc815\ubcf4\ub97c \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uc774\ub984 \uc606 \ud654\uc0b4\ud45c \ud074\ub9ad \u2192 \u201c\ub0b4 \ud504\ub85c\ud544\u201d \ud074\ub9ad</p> <p></p> <p>2. \uc704 \ud654\uba74\uacfc \uac19\uc774 \u201c\uc0ac\uc6a9\uc790 \uc815\ubcf4\u201d \ud655\uc778\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p> <p></p> <p>3. \u201c\ud504\ub85c\ud544 \uc218\uc815\u201d \ud074\ub9ad \u2192 \ud504\ub85c\ud544 \uc815\ubcf4 \uc218\uc815 \ud31d\uc5c5 \ud654\uba74\uc5d0\uc11c \uc6d0\ud558\ub294 \uc815\ubcf4\ub97c \uc218\uc815\ud558\uc5ec \u201c\uc218\uc815\u201d \ubc84\ud2bc \ud074\ub9ad\ud558\uba74 \ud504\ub85c\ud544 \uc815\ubcf4 \uc218\uc815\uc774 \uc644\ub8cc\ub429\ub2c8\ub2e4.</p>"},{"location":"user-guide/workload/pv-user-guide/","title":"\uc800\uc7a5\uc18c \uad00\ub9ac \uc124\uc815","text":"<p>\uc800\uc7a5\uc18c \uad00\ub9ac\ub97c \ud1b5\ud574 \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc800\uc7a5\uc18c\uc640 \ubc31\uc5c5 \ub370\uc774\ud130 Storage \uc815\ubcf4\ub97c \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uc774\ub984 \uc606 \ud654\uc0b4\ud45c \ud074\ub9ad \u2192 \u201c\uc800\uc7a5\uc18c \uad00\ub9ac\u201d \ud074\ub9ad </p> <p></p> <p>2. \uc704 \ud654\uba74\uacfc \uac19\uc774 \u201c\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc800\uc7a5\uc18c \uc778\uc99d\uc815\ubcf4 \ub4f1\ub85d\u201d \uacfc \u201c\ubc31\uc5c5 \ub370\uc774\ud130 \uac1c\uc778 \uc800\uc7a5\uc18c \uc5f0\uacb0\u201d \uc124\uc815\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. </p> <ul> <li>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc800\uc7a5\uc18c \uc778\uc99d\uc815\ubcf4 : \uc6cc\ud06c\ub85c\ub4dc \uc124\uc815 \uc2dc \uac1c\uc778 \uc800\uc7a5\uc18c\uc5d0 \uc788\ub294 \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud560 \uacbd\uc6b0 \uac1c\uc778 \uc800\uc7a5\uc18c \uc778\uc99d \uc815\ubcf4\ub97c \ub4f1\ub85d\ud574\uc57c \uc774\ubbf8\uc9c0 \uc815\ubcf4\ub97c \uc6cc\ud06c\ub85c\ub4dc \uc0ac\uc6a9 \uc2dc \uc774\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> <li>\ubc31\uc5c5 \ub370\uc774\ud130 \uac1c\uc778 \uc800\uc7a5\uc18c : \ud559\uc2b5\ud55c \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud560 \uc218 \uc788\ub294 \uac1c\uc778 Storage\ub97c \uc5f0\uacb0\ud558\uc5ec \uc800\uc7a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.   </li> </ul> <p></p> <p>3. \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 \uc800\uc7a5\uc18c \uc778\uc99d\uc815\ubcf4 \ub4f1\ub85d : \u201c+ \uc778\uc99d \uc815\ubcf4 \ub4f1\ub85d\u201d \ud074\ub9ad *\u2192 \uc0ac\uc6a9\ud560 \u201c*\uc800\uc7a5\uc18c\u201d \uc81c\uacf5 \uc5c5\uccb4\ub97c \uc120\ud0dd \ud6c4 \ud544\uc694\ud55c \uc815\ubcf4 \uc785\ub825  \u2192 \u201c\ub4f1\ub85d\u201d \ubc84\ud2bc \ud074\ub9ad \uc2dc \ub4f1\ub85d \uc644\ub8cc\ub418\uc5b4\uc9d1\ub2c8\ub2e4. </p> <p></p> <p>4. \uc0ac\uc6a9\uc790 \uc778\uc99d\uc815\ubcf4 \u201c\ud3b8\uc9d1\u201d \ubc84\ud2bc \ud074\ub9ad \u2192 \uc0ac\uc6a9\uc790 \uc778\uc99d\uc815\ubcf4 \ud31d\uc5c5 \ud654\uba74\uc5d0\uc11c \uad00\ub828 \uc815\ubcf4 \uc218\uc815\ud558\uc5ec \u201c\uc218\uc815\u201d \ubc84\ud2bc \ud074\ub9ad\ud558\uba74 \uc0ac\uc6a9\uc790 \uc778\uc99d\uc815\ubcf4 \uc218\uc815\uc774 \uc644\ub8cc\ub429\ub2c8\ub2e4. </p> <p></p> <p>5. \ubc31\uc5c5 \ub370\uc774\ud130 \uac1c\uc778 \uc800\uc7a5\uc18c \uc5f0\uacb0 : \u201c+ \uac1c\uc778 \ubc31\uc5c5 \uc800\uc7a5\uc18c \uc5f0\uacb0\u201d \ud074\ub9ad *\u2192 \uc800\uc7a5\uc18c \uc815\ubcf4 \ub4f1\ub85d \ud31d\uc5c5 \ud654\uba74\uc5d0\uc11c \u201c*\uc720\ud615\u201d\uc744 \uc120\ud0dd \u2192 \uc0ac\uc6a9\ud560 \u201c\uc800\uc7a5\uc18c\u201d \uc81c\uacf5 \uc5c5\uccb4\ub97c \uc120\ud0dd \ud6c4 \ud544\uc694\ud55c \uc815\ubcf4 \uc785\ub825  \u2192 \u201c\ub4f1\ub85d\u201d \ubc84\ud2bc \ud074\ub9ad \uc2dc \ub4f1\ub85d \uc644\ub8cc\ub418\uc5b4\uc9d1\ub2c8\ub2e4.  6. \uc800\uc7a5\uc18c \uc815\ubcf4 \ub4f1\ub85d \uc2dc \ubaa9\ub85d\uc5d0 \ud45c\uc2dc\ub420 \uc800\uc7a5\uc18c \uc124\uba85\uc744 \uc124\uc815\ud55c \ud6c4 \uc800\uc7a5\uc18c \ub0b4 \uc5f0\ub3d9\ud560 \ud3f4\ub354 \uacbd\ub85c\ub97c \uc124\uc815 \ud6c4 \uc800\uc7a5\ud574\uc8fc\uc138\uc694.   [\uc608: \u201c/data/data\u201d\ub294 \ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc5d0\uc11c dropbox\uac00 \ub9c8\uc6b4\ud2b8\ub418\ub294 \uacbd\ub85c\uc785\ub2c8\ub2e4. \uc774 \uc704\uce58\uc5d0 \ud30c\uc77c\uc744 \uc77d\uace0 \uc4f8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.] </p> <p>\uc811\uadfc \ubc29\uc2dd \ubc0f \uc6a9\ub7c9\uc740 \ud544\uc694\uc5d0 \ub530\ub77c \uc870\uc815\ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4. </p> <ul> <li> <p>dropbox </p> </li> <li> <p>aws s3 [AWS \uc800\uc7a5\uc18c\ub294 IAM\uc758 access key\uc640 secret access key, bucket\uc758 region\uc744 \ub123\uc5b4\uc57c \ud569\ub2c8\ub2e4.]  </p> </li> </ul>"},{"location":"user-guide/workload/register-new-workload/","title":"\uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d","text":"<p>gcube\uc758 GPU \uc790\uc6d0\uc744 \uc0ac\uc6a9\ud558\uae30 \uc704\ud574, \u2018\uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d\u2019\uc774 \ud544\uc694\ud569\ub2c8\ub2e4. </p> <p></p> <p>1. Deploy mode\uc5d0\uc11c  \u201c\uc0c8 \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d\u201d \uba54\ub274\ub97c \ud074\ub9ad\ud558\uc138\uc694.</p> <p>2. \uc6cc\ud06c\ub85c\ub4dc \ub4f1\ub85d \ud398\uc774\uc9c0\uc5d0 \uac01 \ud56d\ubaa9\uc744 \uc785\ub825\ud569\ub2c8\ub2e4.</p> <p></p> <ul> <li>\uc6cc\ud06c\ub85c\ub4dc \uc124\uba85: \uc6cc\ud06c\ub85c\ub4dc\uc758 \uc6a9\ub3c4\uc640 \ud2b9\uc9d5\uc744 \uac04\ub2e8\ud788 \uc791\uc131\ud569\ub2c8\ub2e4.</li> </ul>"},{"location":"user-guide/workload/register-new-workload/#_2","title":"\ucee8\ud14c\uc774\ub108","text":"<ul> <li>\uc800\uc7a5\uc18c \uc720\ud615: \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0\uac00 \uc800\uc7a5\ub41c \ud50c\ub7ab\ud3fc\uc744 \uc120\ud0dd\ud558\uc138\uc694.</li> <li>\ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0: \uc544\ub798 \uc800\uc7a5\uc18c\ubcc4 \uc774\ubbf8\uc9c0 \uc785\ub825 \ud615\uc2dd\uc744 \ucc38\uace0\ud558\uc5ec \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0 URL\uc744 \uc785\ub825\ud558\uc138\uc694.</li> <li>\ucee8\ud14c\uc774\ub108 \ud3ec\ud2b8\u00a0: \ucee8\ud14c\uc774\ub108\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ub124\ud2b8\uc6cc\ud06c \ud3ec\ud2b8\uc785\ub2c8\ub2e4. \uc774\ubbf8\uc9c0 \uac80\uc99d \uc2dc \uc790\ub3d9\uc73c\ub85c \uc785\ub825\ub429\ub2c8\ub2e4.</li> </ul> <pre><code>=== \"Docker Hub\"\n    ```\n    username/repository:tag\n    ```\n    \uc608\uc2dc: `ollama/ollama:latest`\n\n=== \"NVIDIA NGC\"\n    ```\n    nvcr.io/nvidia/repository:tag\n    ```\n    \uc608\uc2dc: `nvcr.io/nvidia/cuda:12.0.0-base-ubuntu22.04`\n\n=== \"GitHub\"\n    ```\n    ghcr.io/owner/repository:tag\n    ```\n    \uc608\uc2dc: `ghcr.io/organization/app:1.0`\n\n=== \"Red Hat Quay\"\n    ```\n    quay.io/namespace/repository:tag\n    ```\n    \uc608\uc2dc: `quay.io/redhat/ubi8:latest`\n\n=== \"Hugging Face\"\n    ```\n    registry.hf.space/username/repository:tag\n    ```\n    \uc608\uc2dc: `registry.hf.space/username/model-server:v1`\n</code></pre> <p>\uc608\uc2dc:</p> <pre><code>ollama/ollama:latest\n</code></pre> <p>\uc774\ubbf8\uc9c0 \uac80\uc99d \ud655\uc778</p> <ul> <li>\uc815\ud655\ud55c \uc774\ubbf8\uc9c0 URL\uc744 \uc785\ub825\ud558\uba74 \ub179\uc0c9 \uccb4\ud06c \ud45c\uc2dc\uac00 \ub098\ud0c0\ub098\uace0 \ud3ec\ud2b8\uac00 \uc790\ub3d9\uc73c\ub85c \uc785\ub825\ub429\ub2c8\ub2e4.</li> <li> <p>\uc720\ud6a8\ud558\uc9c0 \uc54a\uc740 \uc774\ubbf8\uc9c0\ub294 \ube68\uac04\uc0c9 \uccb4\ud06c \ud45c\uc2dc\uac00 \ub098\ud0c0\ub098\uba70 \ud3ec\ud2b8\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.</p> </li> <li> <p>\ucee8\ud14c\uc774\ub108 \uba85\ub839 : Dockerfile\uc758 CMD \ud56d\ubaa9(\ucee8\ud14c\uc774\ub108 \uc2e4\ud589 \uc2dc \uc2dc\uc791\ub420 \uba85\ub839\uc5b4)\uc744 \uc124\uc815\ud569\ub2c8\ub2e4.</p> </li> <li>\ucee8\ud14c\uc774\ub108 \ud658\uacbd\ubcc0\uc218 : Dockerfile\uc758 ENV \ud56d\ubaa9(\ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ud658\uacbd\ubcc0\uc218)\uc744 \uc124\uc815\ud569\ub2c8\ub2e4.</li> <li>\uac1c\uc778 Storage : \ud559\uc2b5\ud55c \ub370\uc774\ud130\ub97c \ubc31\uc5c5\ud560 \uc218 \uc788\ub294 \uac1c\uc778 \uc800\uc7a5\uc18c \uc815\ubcf4\ub97c \uc124\uc815\ud569\ub2c8\ub2e4. \uac1c\uc778\uc800\uc7a5\uc18c\ub294 \uc800\uc7a5\uc18c \uad00\ub9ac\ub97c \ud1b5\ud574 \ub4f1\ub85d\ud558\uc5ec \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> <li>\uc800\uc7a5\uc18c \uc778\uc99d : \uac1c\uc778 \uc800\uc7a5\uc18c\uc5d0 \uc788\ub294 \ucee8\ud14c\uc774\ub108 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud560 \uacbd\uc6b0 \uccb4\ud06c\ud569\ub2c8\ub2e4. \ub2e8, \uc800\uc7a5\uc18c \uad00\ub9ac\ub97c \ud1b5\ud574 \uac1c\uc778\uc800\uc7a5\uc18c \uc778\uc99d\uc774 \uc644\ub8cc\ub41c \uacbd\uc6b0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> </ul>"},{"location":"user-guide/workload/register-new-workload/#gpu","title":"GPU \uc120\ud0dd","text":"<p>\uc6cc\ud06c\ub85c\ub4dc \uc774\uc6a9 \uc2dc \uc0ac\uc6a9\ud560 \ubaa9\uc801 \ub178\ub4dc\ub97c \uc120\ud0dd\ud560 \uc218 \uc788\uc73c\uba70, \uc0ac\uc6a9\uac00\ub2a5\ud55c GPU\ub9cc \ubcf4\uae30\ub97c \ud65c\uc131\ud654\ud560 \uacbd\uc6b0 \ud604\uc7ac \uc0ac\uc6a9\uac00\ub2a5\ud55c GPU \ubaa9\ub85d\ub9cc \uc870\ud68c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c \ubaa8\ub378\uba85, vRAM,  \ube44\uc6a9\uae30\uc900\uc73c\ub85c GPU\ub97c \uac80\uc0c9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <ul> <li>GPU \ubaa8\ub378\uba85 : GPU \ubaa8\ub378\ubcc4 \uc785\ub825 \uc2dc \uacf5\uae09 \uac00\ub2a5\ud55c GPU \ub9ac\uc18c\uc2a4 \ud56d\ubaa9\uc774 \ub098\ud0c0\ub0a9\ub2c8\ub2e4. \uac01 \ub178\ub4dc\uc758 \uc815\ubcf4 \uc911 Tier \uad6c\ubd84\uc740 \uc544\ub798 \uae30\uc900\uc5d0 \ub530\ub77c \ub098\ub258\uc5b4\uc9d1\ub2c8\ub2e4.<ul> <li><code>Tier 1</code> : \ud074\ub77c\uc6b0\ub4dc \uc0ac\uc5c5\uc790</li> <li><code>Tier 2</code> : \uc804\uc6a9 \uc11c\ubc84</li> <li><code>Tier 3</code> : PC\ubc29, \uac1c\uc778</li> </ul> </li> <li>GPU \uba54\ubaa8\ub9ac : \ud544\uc694\ud55c GPU \uba54\ubaa8\ub9ac\uc758 \uc6a9\ub7c9\uc744 \uc124\uc815\ud569\ub2c8\ub2e4. \uc124\uc815\uac12\uc5d0 \ub530\ub77c \uc0ac\uc6a9 \uac00\ub2a5\ud55c GPU\uac00 \ud544\ud130\ub9c1\ub429\ub2c8\ub2e4.</li> <li>\ube44\uc6a9 : \uc2dc\uac04\ub2f9 \ucd5c\uc18c \ube44\uc6a9\uacfc \ucd5c\ub300 \ube44\uc6a9\uc744 \uc785\ub825 \uc2dc \ud574\ub2f9 \uad6c\uac04\uc5d0 \uc77c\uce58\ud558\ub294 GPU \ubaa8\ub378\uc774 \ud45c\uc2dc\ub418\uba70, \uc608\uc0b0\uc5d0 \ub9de\ub294GPU \ubaa8\ub378\uc744 \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> </ul>"},{"location":"user-guide/workload/register-new-workload/#_3","title":"\uc635\uc158","text":"<ul> <li>\ub808\ud50c\ub9ac\uce74 : \ubc30\ud3ec\ud560 \ucee8\ud14c\uc774\ub108 \uc778\uc2a4\ud134\uc2a4\uc758 \uc218\ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4.</li> <li>\ucd5c\uc18c CUDA \ubc84\uc804 : CUDA\uc758 \ubc84\uc804\uc744 \uc9c0\uc815\ud569\ub2c8\ub2e4.</li> <li>\uacf5\uc720 \uba54\ubaa8\ub9ac : \ud504\ub85c\uc138\uc2a4 \uac04 \ub370\uc774\ud130 \uacf5\uc720\ub97c \uc704\ud574 \uc124\uacc4\ub41c \uc601\uc5ed \ud06c\uae30\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.</li> </ul>"},{"location":"user-guide/workload/register-new-workload/#_4","title":"\ub4f1\ub85d","text":"<ul> <li>\ucd1d \uc608\uc0c1 \uae08\uc561\uc744 \ud655\uc778\ud558\uace0 \uc989\uc2dc\ubc30\ud3ec \uc5ec\ubd80\ub97c \uc120\ud0dd\ud55c \ud6c4 \u201c\ub4f1\ub85d\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694.</li> </ul> <p>3. \uc6cc\ud06c\ub85c\ub4dc\uac00 \uc0dd\uc131\ub418\uc5b4 \ubaa9\ub85d\uc5d0\uc11c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/workload/terminate-workload/","title":"\uc6cc\ud06c\ub85c\ub4dc \uc885\ub8cc","text":"<p>\uc6cc\ud06c\ub85c\ub4dc\ub294 \u2018\ubc30\ud3ec\uc911\uc9c0\u2019 \ubc84\ud2bc\uc744 \ud1b5\ud574 \uc0ac\uc6a9\uc744 \uc911\ub2e8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  </p> <p></p> <p>1. \uc6cc\ud06c\ub85c\ub4dc \uc885\ub8cc\ub97c \uc6d0\ud558\uc2e0\ub2e4\uba74, \ubc30\ud3ec\ub41c \ud56d\ubaa9\uc758 \u201c\ubc30\ud3ec\uc911\uc9c0\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad \ud6c4, \u201c\ud655\uc778\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uc138\uc694. </p> <p></p> <p>2. \uc6b0\uce21 \uc0c1\ub2e8\uc758 \uc6cc\ud06c\ub85c\ub4dc \uc0c1\ud0dc\uac00 \ubc30\ud3ec \u2192 \uc885\ub8cc \uc0c1\ud0dc\ub85c \ubcc0\uacbd\ub418\uba70, \uc11c\ube44\uc2a4\uac00 \uc911\ub2e8\ub429\ub2c8\ub2e4. </p>  \u26a0\ufe0f  \uc885\ub8cc \uc2dc, \ubc31\uc5c5 \uc800\uc7a5\uc18c\ub97c \uc124\uc815\ud558\uc9c0 \uc54a\uc740 \uacbd\uc6b0 \uc791\uc5c5 \uc911\uc774\ub358 \ub370\uc774\ud130 \ubc0f \ud658\uacbd\uc740 \uc800\uc7a5\ub418\uc9c0 \uc54a\uc73c\ub2c8 \uc720\uc758\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.  ( \uc800\uc7a5\uc18c \uad00\ub9ac &gt; \ubc31\uc5c5 \ub370\uc774\ud130 \uac1c\uc778 \uc800\uc7a5\uc18c \uc5f0\uacb0 \uc124\uc815 \ud6c4 \uc6cc\ud06c\ub85c\ub4dc \uc0dd\uc131 \uc2dc \uac1c\uc778 Storage \uc124\uc815\ud55c \uacbd\uc6b0 \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. )"},{"location":"user-guide/workload/workload-expenses/","title":"\uc6cc\ud06c\ub85c\ub4dc \uc774\uc6a9\ub0b4\uc5ed","text":"<p>\uc6cc\ud06c\ub85c\ub4dc \uc0ac\uc6a9\uc5d0 \ub530\ub978 \ud3ec\uc778\ud2b8 \uc774\uc6a9 \uc0c1\uc138\ub0b4\uc5ed\uc740 \u2018\uc774\uc6a9\uc0c1\uc138\u2019 \uae30\ub2a5\uc744 \ud1b5\ud574 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>1. \uc6cc\ud06c\ub85c\ub4dc \ud56d\ubaa9 \uc6b0\uce21 \ud558\ub2e8\uc758 \u201c\uc774\uc6a9\uc0c1\uc138\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud569\ub2c8\ub2e4. </p> <p></p> <p>2. \uc6cc\ud06c\ub85c\ub4dc \ud56d\ubaa9\uc5d0 \ub300\ud55c \uc0ac\uc6a9 \ud3ec\uc778\ud2b8 \ubc0f \uc774\uc6a9 \uae08\uc561\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>3. \u201c\uc138\ubd80\ub0b4\uc5ed\u201d \ubc84\ud2bc\uc744 \ud074\ub9ad\ud558\uba74 \ud30c\ub4dc\ub098 \uc774\uc6a9\uc2dc\uac04 \ubcc4\ub85c \uacfc\uae08 \ub41c \uc138\ubd80 \ub0b4\uc5ed\uc744 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"user-guide/workload/workload-home/","title":"Home","text":"<p>Home \uba54\ub274\ub294 \uc6cc\ud06c\ub85c\ub4dc\uc758 \ud074\ub7ec\uc2a4\ud130 \uc804\uccb4 \ud604\ud669\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p></p> <p>1. \uc88c\uce21 \uba54\ub274\uc5d0\uc11c \u201cHome\u201d \uba54\ub274\ub97c \ud074\ub9ad\ud558\uba74 \ubcf4\uc720 \ud3ec\uc778\ud2b8 \uae08\uc561\uacfc \uc6b4\uc601\uc911\uc778 \uc6cc\ud06c\ub85c\ub4dc\uc758 \uc694\uc57d \uc815\ubcf4\uc640 \ud604\ud669\ub4e4\uc744 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p></p> <p>2. \uc0dd\uc131\ud55c \uc6cc\ud06c\ub85c\ub4dc\uc758 \uc804\uccb4 \uc694\uc57d \uc6b4\uc601 \ud604\ud669\uacfc \ud568\uaed8 \uac1c\ubcc4 \uc6cc\ud06c\ub85c\ub4dc \uc124\uba85\uc744 \ud074\ub9ad\ud558\uba74 \uc6cc\ud06c\ub85c\ub4dc\ubcc4 \uc0c1\uc138 \uc815\ubcf4\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"en/","title":"Overview","text":"<p>The Efficient GPU Sharing Platform</p>"},{"location":"en/#welcome-to-gcube-the-efficient-gpu-sharing-platform","title":"Welcome to gcube, the Efficient GPU Sharing Platform!","text":"<p>Unlock the potential of idle GPUs worldwide to generate additional revenue for providers and provide cost-saving benefits for consumers.</p> <p>Before you get started, here is an essential overview of what you need to know when using gcube for the first time.</p>"},{"location":"en/user-guide/node/NVIDIA-graphic-driver-error/","title":"Troubleshooting: NVIDIA Graphics Driver Recognition Error","text":"<p>During the node provisioning process, the node status may be marked as \"Failed.\"</p> <p>This issue often occurs when the operating system is running multiple graphic drivers simultaneously.</p> <p>For example, this conflict is common when both the NVIDIA discrete GPU and an Integrated GPU (iGPU)\u2014such as AMD Radeon graphics or Intel HD graphics\u2014are active at the same time.</p> <p>|  |  |</p> <p>To ensure stable Gcube node operation, you must disable the integrated GPU (iGPU) to prevent driver conflicts and ensure the agent exclusively utilizes the required NVIDIA hardware.</p> <p>To resolve driver conflicts, use the AMD Display Driver Uninstaller (DDU) to completely remove the iGPU drivers, then proceed with the Gcube Agent reinstallation.</p> <p>Other troubleshooting methods include disabling the iGPU function in the BIOS, or identifying the iGPU in the Device Manager to disable the device and uninstall its driver.</p> <p>Once the conflicting graphics drivers are removed, the issue will be resolved and the status will be displayed as shown below. </p>"},{"location":"en/user-guide/node/Ubuntu-OS-setup/","title":"Tier 2 Ubuntu OS Setup Guide","text":"<p>Downloading Ubuntu Server 22.04 LTS and Creating a Bootable Drive  Ubuntu Server 22.04 LTS Download</p> <ul> <li> <p>Running Ubuntu Server 22.04 LTS</p> <p></p> </li> <li> <p>Language Selection (English)</p> <p></p> </li> <li> <p>Skip Installer Update</p> <p></p> </li> <li> <p>Keyboard Configuration(English)</p> <p></p> </li> <li> <p>Ubuntu Installation Type</p> <ul> <li>Ubuntu Server Installation</li> </ul> <p></p> </li> <li> <p>During the installation, configure the network settings to ensure the OS can access the external internet. (At least 100Mbps)</p> <ul> <li>Verify that the IP address is displayed next to DHCPv4 before proceeding.</li> </ul> <p></p> </li> <li> <p>Configure Ubuntu Archive Mirror</p> <ul> <li>Change the Mirror Address from the default address to http://mirror.kakao.com/ubuntu</li> </ul> <p></p> </li> <li> <p>Storage Configuration</p> <ul> <li>Select Custom Storage Layout </li> </ul> <p></p> <ul> <li>Select free space \u2192 Add GPT Partition </li> </ul> <p></p> <ul> <li>Use the entire space of the target disk for OS installation.<ul> <li>[Allocate 2GB to /boot first]</li> <li>[Assign all remaining capacity to the /(root) space]</li> </ul> </li> </ul> <p></p> </li> <li> <p>Profile Setup</p> <ul> <li>Set the Ubuntu OS user account ID and Password</li> <li>\u203b It is recommended to save the ID/Password separately as they are required for future Agent installation.</li> </ul> <p></p> </li> <li> <p>Skip Ubuntu Pro Upgrade</p> <p></p> </li> <li> <p>SSH Setup</p> <ul> <li>Check \"Install OpenSSH server\".</li> <li>Do not enter an SSH KEY.</li> </ul> <p></p> </li> <li> <p>Featured Server Snaps</p> <ul> <li>Do not select any additional software; proceed directly.</li> <li>Select \"Done\" to finalize the installation.</li> </ul> <p></p> </li> <li> <p>Proceed with Installation and Reboot after completion.</p> </li> </ul>"},{"location":"en/user-guide/node/agent-setup/","title":"Agent Setup","text":"<p>In the Agent Setup, you can update your Graphics Drivers and configure VM (Virtual Machine) settings. </p> <p></p> <p>1. Click on \"Setting.\" </p> <p></p> <p>2. You can modify settings such as reinstalling graphics drivers or deleting VMs.</p>"},{"location":"en/user-guide/node/check-agent-node-monitoring/","title":"Check Agent Node Monitoring","text":"<p>You can monitor the real-time status and performance of your GPU directly through the agent interface. </p> <p></p> <p>1. Click on \"Monitoring.\" </p> <p></p> <p>2. Through the Node Monitoring screen, you can check real-time information and utilization rates for the following resources on your currently shared node</p>"},{"location":"en/user-guide/node/check-gpu-sharing-income/","title":"GPU Sharing Income Details","text":"<p>You can track your earnings and monitor how much profit each GPU is generating through the detailed revenue report. </p> <p></p> <p>1. Please click the \"Usage Details\" button on the GPU sharing information screen</p> <p></p> <p>2. You can check your recent earnings by date through the Revenue History List. 3. If you need to view more specific information, click the \"Detailed View\" button on the right side.</p> <p></p> <p>4. As shown in the screen above, you can check the detailed revenue information broken down by the hour.</p>"},{"location":"en/user-guide/node/check-gpu-sharing-info/","title":"Check GPU Sharing Info","text":"<p>On the Node screen, you can check the current status of the node you are sharing. </p> <p></p> <p>1. If you have only one GPU sharing device, you can check your sharing information as shown in the screen above.  2. The execution status and Node Name will be displayed. Clicking on the node name will take you to a detailed page where you can view more specific information.   - GPU Specs &amp; Device Specs: Hardware model and technical specifications.  - Uptime: The total duration the node has been running.  - Sharing Status: Whether the node is currently \"Running\" or \"Stopped.\"  - Financial Data: Total Revenue, Base Fee, and Usage Fee.  - Timestamps: The exact date and time of the last update. </p> <p></p> <p>3. If you have multiple GPU sharing devices, they will be displayed as shown in the screen above. You can view the specific information and execute functions for each individual GPU.</p> <p></p> <p>4. If you have a large number of GPU sharing devices, you can use the List View to see a summary of all information at a glance.</p>"},{"location":"en/user-guide/node/check-gpu-sharing-monitoring/","title":"Check GPU Sharing Monitoring","text":"<p>You can monitor the real-time status of your GPU sharing activities through the Node interface.  </p> <p></p> <p>1. Please click the \"Monitoring\" button on the GPU sharing information screen. </p> <p></p> <p>2. As shown in the screen above, you can view the complete node monitoring information. </p> <p></p> <p>3. By clicking on \"Select Time Range\", you can review your node's past performance history broken down by specific time periods. </p> <p></p> <p>4. By clicking on \"Custom Time Range\", you can set a specific \"Start Time\" and \"End Time\" to view monitoring information only for your desired period. </p> <p></p> <p>5. By clicking on \"Sampling Interval\", you can adjust the time units of the graph. (Default is 10 minutes; you can set it from a minimum of 1 minute to a maximum of 5 hours.)</p>"},{"location":"en/user-guide/node/connect-new-node/","title":"Connect New Node","text":"<p>To begin GPU sharing and earning rewards, you must first connect a new node to the platform. </p> <p></p> <p>1. In Share Mode, click on the \"Connect New Node\" menu in the left-hand sidebar.</p> <p></p> <p>2. Click the \"Download Program\" button to download the agent software.</p> <p></p> <p>3. Install the agent program on your system.</p> <p></p> <p>4. After downloading and running the agent, please follow the step-by-step instructions provided in the Agent Execution menu to proceed with the installation.</p> <p></p> <p>5. Once the installation is complete, sharing will begin automatically, as shown on the screen.</p>"},{"location":"en/user-guide/node/","title":"Index","text":""},{"location":"en/user-guide/node/#todo-translate-this-page-to-english","title":"TODO: Translate this page to English","text":""},{"location":"en/user-guide/node/node-home/","title":"Home","text":"<p>Navigate to the \"Home\" tab to view the overall status of your node clusters at a glance</p> <p> </p> <p>1. Click on the \"Home\" menu in the left-hand sidebar to view your point balance, along with a summary and status of your connected nodes. </p> <p></p> <p>2. On the Home screen, you can check the total revenue generated from your operating nodes and your remaining balance (profit points) after settlement. Additionally, key notifications required for node operation and site usage are displayed here for your review. </p> <p></p> <p>3. Real-time Node Monitoring: You can view the current operational status of your active nodes at a glance. By clicking on a Node Name, you will be directed to the Node Details page for more in-depth information.</p>"},{"location":"en/user-guide/node/set-gpu-sharing-pricing/","title":"Set GPU Sharing Pricing","text":"<p>Through the Set GPU Sharing Pricing, you can configure both the Base Price and the Usage Unit Price. </p> <p></p> <p>1. Please click the \"Price Setting\" button on the GPU sharing information screen.</p> <p></p> <p>2. A screen where you can modify the unit price will appear, as shown above. You can simply enter your desired amount in the \"Hourly Usage Fee\" section.  3. If you enter the same amount as the current setting, a message saying \"It is the same as the default value\"  will be displayed, as shown on the screen. </p> <p>4. If you enter a price that is above the maximum limit or below the minimum threshold, a message indicating the price criteria will be displayed as shown in the screen above, and the input will not be accepted.</p> <p></p> <p>5. Enter the desired amount in the \"Hourly Usage Fee\" section and click the \"Set Price\" button.</p> <p></p> <p>6. Once a valid amount is entered, a popup will appear as shown in the screen above. 7. After a final review of the amount, click the \"Confirm\" button to complete the price modification.  8. If you wish to edit the amount again, click \"Cancel\" to return to the previous screen.</p>"},{"location":"en/user-guide/node/stop-gpu-sharing/","title":"Stop GPU Sharing","text":"<p>You can stop GPU sharing through the agent. </p> <p></p> <p>1. Click on the \"Running\" status in the center of the agent interface, then select \"Stop\" from the options (Run / Stop).</p> <p></p> <p>2. During the sharing suspension process, the status will change to \"Turning off\", as shown in the image above.</p> <p></p> <p>3. Once the sharing has been successfully stopped, the status will be displayed as \"Stopped.\"</p>"},{"location":"en/user-guide/node/tier-2-ubuntu-setting-guide/","title":"Tier 2 Node Provider Setup Guide","text":"<p>To all Tier 2 Node Providers: Please complete the Ubuntu OS setup according to the guide below before proceeding with the node installation.  Tier 2 Ubuntu OS Setting Guide </p>"},{"location":"en/user-guide/node/tier-2-ubuntu-setting-guide/#1-nvidia-graphics-driver-installation","title":"1. NVIDIA Graphics Driver Installation","text":"<ul> <li>After logging into Ubuntu, you must install the NVIDIA driver to ensure the system recognizes the GPU correctly.</li> <li> <p>Remove Existing Drivers</p> <pre><code>$ sudo apt-get purge nvidia*\n$ sudo apt-get autoremove\n$ sudo apt-get autoclean\n\n$ sudo dpkg -l | grep nvidia\n$ sudo apt remove --purge {Package Name from the output}\n</code></pre> </li> <li> <p>Installing the New NVIDIA Driver</p> <ul> <li>Install Prerequisite Packages for NVIDIA Driver</li> </ul> <pre><code>$ sudo apt install ubuntu-drivers-common\n$ sudo add-apt-repository ppa:graphics-drivers/ppa\n$ sudo apt update\n$ sudo apt install alsa-utils -y\n</code></pre> </li> <li> <p>Install the graphics driver labeled as \"recommended\" after executing the command.</p> <ul> <li>Example: Installing Driver for NVIDIA GeForce RTX 3060</li> </ul> <pre><code>$ sudo ubuntu-drivers devices\n\n== /sys/devices/pci0000:00/0000:00:03.1/0000:09:00.0 ==\nmodalias : pci:v000010DEd00002504sv00001458sd0000407Bbc03sc00i00\nvendor   : NVIDIA Corporation\nmodel    : GA106 [GeForce RTX 3060 Lite Hash Rate]\ndriver   : nvidia-driver-550-open - distro non-free\ndriver   : nvidia-driver-545 - distro non-free\ndriver   : nvidia-driver-535 - distro non-free\ndriver   : nvidia-driver-535-server-open - distro non-free\n**driver   : nvidia-driver-550 - distro non-free recommended**\ndriver   : nvidia-driver-545-open - distro non-free\ndriver   : nvidia-driver-535-server - distro non-free\ndriver   : nvidia-driver-535-open - distro non-free\ndriver   : nvidia-driver-470 - distro non-free\ndriver   : nvidia-driver-470-server - distro non-free\ndriver   : xserver-xorg-video-nouveau - distro free builtin\n\n$ sudo apt install nvidia-driver-550\n\n# Please install the \"recommended\" driver as displayed on your own screen\n</code></pre> </li> <li> <p>Reboot the OS after the graphics driver installation is complete.</p> <pre><code>$ sudo reboot\n</code></pre> </li> <li> <p>After the OS starts, execute the nvidia-smi command to verify that the graphics driver is installed correctly.</p> <pre><code>$ nvidia-smi\n\nTue Feb 25 09:47:42 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce RTX 3060        On  |   00000000:09:00.0 Off |                  N/A |\n|  0%   42C    P8             23W /  170W |       2MiB /  12288MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n</code></pre> </li> </ul>"},{"location":"en/user-guide/node/tier-2-ubuntu-setting-guide/#2-gcube-agent-installation","title":"2. Gcube Agent Installation","text":"<ul> <li>Pre-installation Preparation for Gcube Agent<ol> <li>Ensure all prerequisites are met before running the installation script.<ul> <li>gcube.ai Website Account: Your login credentials for the official platform. </li> <li>Email Address: The email where you will receive essential configuration files and access tokens.</li> </ul> </li> <li>Agent Installation File and Personal User Token Delivery  After Gcube receives your information, the Agent installation file and the Personal User Token required for installation will be sent to you. \u203b Note: These will be delivered to the email address you provided.<ul> <li>gai_svr_inst: The executable installation file for the Gcube server.</li> <li>Personal User Token: Your unique authentication key required during the setup process.</li> </ul> </li> </ol> </li> <li> <p>Proceed with the installation after logging into Ubuntu.</p> </li> <li> <p>Create Agent Installation Directory and Grant Execution Permissions</p> <pre><code># Create a dedicated directory\n$ mkdir -p ~/work/gcube_instller\n\n# Locate the Agent Installation File in the Dedicated Directory\n$ cd ~/work/gcube_installer/\n\n# Granting Execution Permission to the Agent Installation File\n$ chmod +x gai_svr_inst\n</code></pre> </li> <li> <p>Basic File Installation</p> <pre><code># Basic File Installation\n$ sudo ./gai_svr_inst base\n\nINFO[0000] Rnd initialized...                           \nINFO   [2025-02-25T06:11:15Z] Install Base All ...                         \nINFO   [2025-02-25T06:11:38Z] baseNetools complete.                        \nINFO   [2025-02-25T06:11:46Z] procWireGuard complete.                      \nINFO   [2025-02-25T06:11:46Z] PktPathBase: /root/packages/ubuntu22/ k8s_packages_u22_v1.28.tar.gz \nINFO   [2025-02-25T06:12:10Z] procK8sPackage complete.                     \nERROR  [2025-02-25T06:13:28Z] Failed to run                                 error=\"exit status 1\"\nWARNING[2025-02-25T06:13:28Z] util.ExecCommand dpkg crio                    error=\"exit status 1\"\nINFO   [2025-02-25T06:13:29Z] procCrio complete.                           \nINFO   [2025-02-25T06:14:31Z] procKubernetes complete.                     \nERROR  [2025-02-25T06:14:36Z] Failed to run                                 error=\"exit status 100\"\nWARNING[2025-02-25T06:14:36Z] ExecCommand apt install                       error=\"exit status 100\"\nINFO   [2025-02-25T06:14:36Z] apt fix broken                               \nINFO   [2025-02-25T06:14:42Z] retry install nvidia-container-toolkit       \nINFO   [2025-02-25T06:14:52Z] procNvidiaPlugin complete.                   \nINFO   [2025-02-25T06:14:53Z] clearAutoUpdate complete.                    \nINFO   [2025-02-25T06:14:53Z] **procGaiClientInstaller complete.**  \n</code></pre> <ul> <li> <p>When procGaiClientInstaller complete is displayed on the last line, it indicates that the installation of all core components has been successfully finished.</p> </li> <li> <p>Terminal Output Example</p> </li> </ul> <p></p> </li> <li> <p>Proceeding with Node Activation</p> <ul> <li> <p>Run the following command to finalize the node setup and initiate the service.</p> <ul> <li>Ethernet NIC Name: The specific name of your network interface (e.g., eth0, enp3s0).</li> <li>Access Token: Your unique personal token (Case-sensitive).</li> </ul> <pre><code># View all Using Ethernet Interface\n\n$ ifconfig -a \n</code></pre> <pre><code># Command to open Node\n\n$ sudo ./gai_svr_inst --nic &lt;ethernet nic name&gt; reg &lt;access token&gt;\n</code></pre> <pre><code># Execution Example\n# Verify active network interface name -&gt; (enp5s0)\n\n$ ifconfig -a\n\ndocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::7807:f9ff:fe9c:6967  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 7a:07:f9:9c:69:67  txqueuelen 0  (Ethernet)\n        RX packets 1779  bytes 49812 (49.8 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 1189  bytes 130886 (130.8 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nenp5s0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 10.39.60.65  netmask 255.255.254.0  broadcast 10.39.61.255\n        inet6 fe80::642:1aff:fe94:5edd  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 04:42:1a:94:5e:dd  txqueuelen 1000  (Ethernet)\n        RX packets 2283880  bytes 2164088878 (2.1 GB)\n        RX errors 0  dropped 10  overruns 0  frame 0\n        TX packets 1513085  bytes 1359887094 (1.3 GB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n        device memory 0xfc400000-fc4fffff  \n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 46784  bytes 3534359 (3.5 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 46784  bytes 3534359 (3.5 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp4s0: flags=4098&lt;BROADCAST,MULTICAST&gt;  mtu 1500\n        *ether f4:b3:01:39:2b:91  txqueuelen 1000  (Ethernet)*\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre> <pre><code># Proceed to register Node by sudo ./gai_svr_inst --nic &lt;ethernet nic name&gt; reg &lt;access token&gt; \n\n$ sudo ./gai_svr_inst --nic enp5s0 reg eyJh...\uc0dd\ub7b5...X63w\n\nINFO[0000] Rnd initialized...                           \nINFO   [2025-02-25T06:23:16Z] access token : &amp;[eyJh...X63w] enp5s0 \nINFO   [2025-02-25T06:23:16Z] MAC address                                   mac=\"00:00:00:00:00:00\"\nINFO   [2025-02-25T06:23:16Z] mac address 000000000000                     \nDEBUG  [2025-02-25T06:23:16Z] url https://api.gcube.ai/api/node/register   \nDEBUG  [2025-02-25T06:23:16Z] body {\"category\":\"svr\",\"macId\":\"000000000000\"} \nDEBUG  [2025-02-25T06:23:16Z] res &amp;{200 6150125230709283 eyJh...xsHS  } \nINFO   [2025-02-25T06:23:16Z] provision code 0000000000000000              \nINFO   [2025-02-25T06:23:16Z] start provision ...                          \nDEBUG  [2025-02-25T06:23:16Z] body {\"provision_code\":\"0000000000000000\"}\n</code></pre> </li> <li> <p>Execution Example</p> </li> </ul> <p></p> </li> <li> <p>Verify Registered Nodes on the gcube.ai Node Page</p> <ul> <li>Move to Node Page</li> </ul> <p></p> </li> </ul>"},{"location":"en/user-guide/node/troubleshooting_agent_errors/","title":"Troubleshooting Agent Errors","text":"<p>If an \"Initializing\" error occurs, you should check if Hyper-V is enabled on your system.</p>"},{"location":"en/user-guide/node/troubleshooting_agent_errors/#how-to-enable-hyper-v","title":"How to Enable Hyper-V","text":"<p>1. Search for and run \"Turn Windows features on or off\" in the Windows search bar. </p> <p></p> <p>2. Find \"Hyper-V\" in the list and check the box.</p> <p>\u203b Please note: The Hyper-V feature is natively available only on Windows Pro (Professional) and Enterprise versions. </p> <p></p> <p>3. Click Restart to reboot your system. </p>"},{"location":"en/user-guide/node/troubleshooting_agent_errors/#hyper-v-configuration-after-reboot","title":"Hyper-V Configuration After Reboot","text":"<p>1. Search for \"Hyper-V Manager\" in the search bar and run the application. </p> <p></p> <p>2. Right-click on your computer name, then select \"New\" &gt; \"Virtual Machine\". </p> <p></p> <p>3. Set the Name and Storage Location for the virtual machine, then click Next.</p> <p>\u203b Note: Since virtual Windows machines take up a significant amount of storage, it is recommended to designate a drive with sufficient free space. </p> <p></p> <p>4. Select the Generation of the virtual machine. While Generation 1 supports 32-bit versions of Windows, Generation 2 supports only 64-bit versions of Windows.</p> <p>\u203b Note: You cannot change the generation once it has been selected. If an issue occurs, you must delete the virtual machine and create a new one. </p> <p></p> <p>5. Set the amount of memory (RAM) to allocate to the virtual machine. Choose a value based on your physical RAM capacity and the tasks you plan to perform within the virtual environment. (1GB = 1024MB) </p> <p></p> <p>6. Next, enter the location and size of the virtual hard disk. Since the capacity can be expanded later, please set it based on your available physical hard disk space. </p> <p>\u203b Example: In this case, the laptop's disk was assigned as the D drive, and approximately half of its capacity was allocated. </p>"},{"location":"en/user-guide/node/troubleshooting_agent_errors/#if-the-failed-to-change-vm-state-message-appears-it-means-the-initialization-has-failed","title":"If the \"Failed to change VM state\" message appears, it means the initialization has failed.","text":""},{"location":"en/user-guide/node/troubleshooting_agent_errors/#bios-settings","title":"BIOS Settings","text":"<p>How to Enter the BIOS</p> <p>Turn on the power and immediately press the [F2] key repeatedly at high speed.</p> <p>\u203b Note: On systems equipped with an SSD, the boot speed is extremely fast. Please start tapping the [F2] key immediately after pressing the power button.</p> <p>BIOS Entry Methods by Manufacturer</p> Manufacturer BIOS Entry Key Selecting Boot Priority Key Site Links Intel F2 F10 Link AMD F2 F10 Link MSI DEL F11 Link ASUS F2 or Del ESC or F8 or F12 Link <p>\u203b The following instructions describe the BIOS setup process for Intel systems. Steps may vary depending on the manufacturer. For detailed assistance, if you encounter the Failed to change VM state (0x???????)error, please contact the manufacturer's support center with the specific error code shown in the parentheses.</p>"},{"location":"en/user-guide/node/troubleshooting_agent_errors/#how-to-enter-intel-bios","title":"How to Enter Intel BIOS","text":"<p>1. Press the [F2] key as soon as the logo screen first appears during the boot process.  2. In the Main (or Basic) tab, change Fast Boot to Disabled. </p> <p></p> <p>3. Return to the top-level menu. Press the right arrow key until the Save &amp; Exit tab is displayed. 4. Select Save Changes and Exit (or Save Changes and Reset) to reboot the system with your changes applied.</p>"},{"location":"en/user-guide/platform-guide/QnA-user-guide/","title":"QnA User Guide","text":"<p>If you have any inquiries regarding the use of workloads or nodes, you can find answers through\u00a0Customer Support</p>"},{"location":"en/user-guide/platform-guide/QnA-user-guide/#accessing-the-qna-page","title":"Accessing the QnA Page","text":"<p>Click on\u00a0\u201cCustomer Support\u201d\u00a0located in the left sidebar menu. This service is available in both\u00a0Deploy Mode\u00a0and\u00a0Share Mode. </p> <p></p>"},{"location":"en/user-guide/platform-guide/QnA-user-guide/#qna-faq-overview","title":"QnA FAQ Overview","text":"<p>1. FAQ categories are displayed on the QnA page 2. There are 6 categories:\u00a0\u201cAll,\u201d \u201cGPU Rent,\u201d \u201cPayment,\u201d \u201cTechnology,\u201d \u201cAccount,\u201d\u00a0and\u00a0\u201cGPU Share.\u201d  The top 3 frequently asked questions(FAQs) are displayed for each category. </p> <p></p> <p>3. If you cannot find the information you need in the FAQ, you can submit an inquiry by writing your own\u00a0QnA.  By selecting an\u00a0Inquiry Type\u00a0and, if necessary, specifying the\u00a0Node\u00a0or\u00a0Workload\u00a0in question, you can receive a more detailed response.  Inquiries are received via email, and the answers will also be sent to your account's registered email address.  At the bottom of the page, you will find links for the\u00a0\"Detailed FAQ\"\u00a0and the\u00a0\"KakaoTalk Channel.\"\u00a0 You can browse a more comprehensive FAQ list or use the KakaoTalk Channel for real-time inquiries.</p> <p></p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/","title":"Wan2.2 User Guide","text":"<p>The prerequisites are as follows:</p> <p>1. gcube Sign-up</p> <p>First, please proceed with the sign-up process on the Gcube official website[gcube \ud648\ud398\uc774\uc9c0].  You can sign up using your\u00a0Microsoft\u00a0or\u00a0Google\u00a0account. </p> <p>2. Refill Points(Recharge Points)</p> <p>After logging into Gcube, you must refill your points to run the models. [Point Refill] Please proceed with the recharge on the Point Refill Page.</p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#what-is-wan22","title":"What is Wan2.2?","text":"<p>This document provides a comprehensive guide to\u00a0Wan2.2, an AI model designed to automatically transform images into videos (Image-to-Video)</p> <p>For detailed information regarding its operational principles or technical inquiries, please visit the\u00a0Hugging Face\u00a0link below. Comprehensive details about the\u00a0Docker image\u00a0can be found at the subsequent link</p> <ul> <li>Hugging Face (Technical Details):https://huggingface.co/QuantStack/Wan2.2-I2V-A14B-GGUF</li> <li>Docker Hub (Image Documentation):https://hub.docker.com/r/nykk3/comfyui-wan2.2-gguf</li> </ul>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#creating-a-workload","title":"Creating a Workload","text":"<p>Once you have completed all the prerequisites, let's proceed with creating a workload.</p> <p>1. Log in to the\u00a0Gcube Official Website\u00a0and navigate to the Workload main page.</p> <p>2. Click on \u201cCreate New Workload\u201d in the left sidebar</p> <p></p> <p>3. Enter your desired workload title in the Description field</p> <p></p> <p>4. Container Repository Type:\u00a0Select\u00a0Docker Hub</p> <p>5. Container Image:\u00a0Enter\u00a0[nykk3/comfyui-wan2.2-gguf:q4ks-14b-i2v-cuda12.8]\u00a0and click\u00a0\"Verify Image\".  Once verified, enter\u00a0[ 8188 ]\u00a0in the\u00a0Container Port\u00a0field </p> <p></p> <p>6. Under Container Settings, enter the [Container Environment Variables]</p> Key Value WEB_PASSWORD Str0ngP@ssw0rd123! COMFYUI_USERNAME admin COMFYUI_PASSWORD MyS3cureP@ssw0rd! COMFYUI_ARGS --listen 0.0.0.0 --port 8188 --use-sage-attention <p>\u203b Note: You may set the\u00a0PASSWORD\u00a0freely, but it must be at least 12 characters long. </p> <p></p> <p>7. Select the GPU you wish to use.\u00a0(Note: As this model requires significant VRAM, we strongly recommend using the\u00a0RTX 5090.) </p> <p></p> <p>8. Check the Immediate Deployment box\u00a0and click the\u00a0Register\u00a0button to finalize </p> <p></p> <p>9.Once the workload is created, click the Service URL to experience the Wan 2.2 model yourself.</p> <p>\u203b Note: It takes approximately 3 to 5 minutes for the workload to be fully created after deployment. (This may vary depending on the GPU specifications.)</p> <p> </p> <p>the screen above appears when clicking the Service URL, it means the system is not yet ready.   Please try clicking the Service URL again after 2 to 3 minutes.</p> <p>10. If it runs normally, click the Workflow icon (folder shape) in the left sidebar and select the Wan 2.2 model. The following screen will be displayed.</p> <p></p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#how-to-use-wan22","title":"How to Use Wan2.2","text":"<p>Once Wan2.2 is running correctly, you can transform images into videos through various settings.   This guide provides a simple explanation of the video generation process</p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#step-1-upload-image","title":"Step 1. Upload Image","text":"<p>Upload the image you wish to transform into a video</p> <p></p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#step-2-video-settings","title":"Step 2. Video Settings","text":"<p>Configure the video's pixel width, height, duration, and the number of videos to generate</p> <p></p> <p></p> <p>\u203b Recommendations and Cautions for Video Settings:.  1. Wan2.2 recommends video resolutions of\u00a0480p [854 x 480]\u00a0and\u00a0720p [1280 x 720]. 2. Higher resolutions and longer durations will result in significantly longer processing times. 3. Video duration is indicated by the number of frames. The final length is determined by combining the frame count with the FPS.      Example: [Length: 121 frames] / [FPS: 24] = Approx. 5 seconds</p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#optional-prompt-settings","title":"(Optional) Prompt Settings","text":"<p>You can guide the AI by entering prompts to include or exclude specific elements.  (Korean is supported.) Since this is an optional feature, you may proceed with the default settings.  The\u00a0Negative Prompt\u00a0field is pre-filled with elements that could adversely affect the video conversion. </p> <p></p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#step-4-execute-image-to-video-conversion","title":"Step 4. Execute Image-to-Video Conversion","text":"<p>Click the\u00a0Execute\u00a0(or Run) button at the bottom of the screen to start the conversion.  Depending on your settings, this process may take from\u00a010 minutes to up to 1 hour and 30 minutes. </p> <p></p>"},{"location":"en/user-guide/platform-guide/Wan2.2-user-guide/#step-5-verify-results","title":"Step 5. Verify Results","text":"<p>Perform a final check to see if the conversion meets your expectations.  You can also save the video if needed.</p> <p></p>"},{"location":"en/user-guide/platform-guide/ollama-deepseek/","title":"Ollama User Guide - DeepSeek","text":""},{"location":"en/user-guide/platform-guide/ollama-deepseek/#0-overview","title":"0. Overview","text":"<ul> <li>What is Ollama?<ul> <li>A platform designed to execute and manage LLMs (Large Language Models)</li> <li>Enables users to download and test open-source language models in a local environment</li> <li>Key supported language models include:<ul> <li>Llama3<ul> <li>The latest language model developed by Meta, featuring superior natural language processing performance</li> </ul> </li> <li>Phi 3<ul> <li>Developed by Microsoft Research, this model possesses exceptional reasoning and language understanding capabilities</li> </ul> </li> <li>Mistral<ul> <li>Optimized for various linguistic tasks, boasting high-performance efficiency</li> </ul> </li> <li>Gemma 2<ul> <li>Developed by Google, showing strength in natural language processing and generation tasks</li> </ul> </li> <li>CodeGemma<ul> <li>Specialized in code generation and completion, supporting a wide range of programming tasks</li> </ul> </li> </ul> </li> <li>Users can run and manage open-source or custom models via a user-friendly interface using Ollama, including model creation and deployment</li> </ul> </li> </ul>"},{"location":"en/user-guide/platform-guide/ollama-deepseek/#1-gcube-platform-workload-service-registration-process","title":"1. gcube Platform Workload Service Registration Process","text":"<ul> <li>Workload Creation and Deployment<ul> <li>Access gcube.ai and navigate to the Workload page ( https://gcube.ai/ko/demand/workload/list )</li> <li>Register a new workload or modify an existing one by entering the required information on the page.</li> </ul> </li> </ul> <ul> <li>Description Overview<ul> <li>Enter the workload name<ul> <li>ex : ollama</li> </ul> </li> </ul> </li> </ul> <ul> <li>Container Overview<ul> <li>Select the storage type and container image<ul> <li>Use the official image provided by Ollama on Docker Hub<ul> <li>Reference URL : https://hub.docker.com/r/ollama/ollama</li> </ul> </li> <li>Storage Type:\u00a0Docker Hub</li> <li>Container Image: ollama/ollama:latest</li> <li>Container ports are automatically populated by checking the metadata (ExposedPorts) of the container image layer. (For Ollama, the port is\u00a011434)</li> </ul> </li> </ul> </li> </ul> <ul> <li>GPU Selection Overview<ul> <li>Select the desired performance specification<ul> <li>Tier1 : High Performance</li> <li>Tier2 : High Reliability</li> <li>Tier3 : Individual Users</li> <li>GPU Memory:\u00a0Filter available GPUs<ul> <li>In this example, select\u00a0Tier 3 RTX 3070</li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li>Option Overview (optional)<ul> <li>Container Command<ul> <li>Corresponds to the\u00a0CMD\u00a0instruction in a Dockerfile (the command to be executed when the container starts)<ul> <li>Format : CMD [\"executable\", \"param1\", \"param2\"] / CMD [\u201cecho\u201c, \u201cHello, world!\u201c]</li> </ul> </li> </ul> </li> <li>Container Environment Variables<ul> <li>Corresponds to the\u00a0ENV\u00a0instruction in a Dockerfile (environment variables to be used inside the container)<ul> <li>\ud615\uc2dd : ENV   / ENV DEF_PORT 9999 <li>Replicas<ul> <li>The number of container instances running simultaneously across different nodes</li> <li>Purpose:<ul> <li>Enhances application reliability and throughput</li> <li>Ensures service continuity even if a specific node fails</li> <li>Reduces latency and improves the developer experience</li> <li>L7 Consistent Hashing Technique:<ul> <li>Routes requests to specific backends based on a key</li> <li>Uses a hashing algorithm to distribute traffic consistently</li> <li>Guarantees that only a minimum number of requests are shifted to other servers when nodes or servers are added or removed</li> </ul> </li> </ul> </li> </ul> </li> <li>CUDA<ul> <li>Select the CUDA version</li> </ul> </li> <li>Shared Memory<ul> <li>Refers to the shared memory area (/dev/shm) provided by Linux systems</li> <li>An area designed for inter-process data sharing (acts as high-speed temporary storage for large-scale data processing)</li> </ul> </li> <ul> <li>Estimated Cost Overview<ul> <li>Displays the maximum hourly price information based on the selected specifications</li> <li>Proceed with registration after reviewing the details<ul> <li>If\u00a0\u2018Instant Deployment\u2019\u00a0is selected, registration and deployment will proceed immediately</li> </ul> </li> </ul> </li> </ul>"},{"location":"en/user-guide/platform-guide/ollama-deepseek/#2-how-to-use-gcube-platform-workload-services","title":"2. How to Use gcube Platform Workload Services","text":"<ul> <li>Checking Created Workloads<ul> <li>On the Workload page(https://gcube.ai/ko/demand/workload/list ), click on the\u00a0Workload Name\u00a0to enter the Workload Details page</li> </ul> </li> </ul> <ul> <li>Workload Details Overview<ul> <li>General:\u00a0Workload ID, description, type, status, Service URL, etc.</li> <li>Container:\u00a0Container image, container port, storage type, creation date/time, deployment date/time, termination date/time, etc.</li> <li>Target Specification:\u00a0Target node, GPU memory, GPU information, etc.</li> <li>Options:\u00a0Container command, container environment variables, replicas, minimum CUDA version, shared memory information, etc.</li> <li>Deployment Status:\u00a0Container deployment events, node information, pod details, pod status, container logs,\u00a0container terminal, container SSH access, etc.</li> </ul> </li> </ul> <ul> <li>When Pod Status is \u2018Running\u2019<ul> <li>Click\u00a0\u2018Container SSH\u2019\u00a0to view the Public IP and register access credentials<ul> <li>Verify SSH access information during the credential registration process.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Connect to the container by entering the SSH access information confirmed above into a terminal program (e.g., PuTTY)<ul> <li>Enter the IP address, Port, User ID, and Password</li> </ul> </li> </ul> <ul> <li>In the CLI, enter the following command to download and run the DeepSeek language model (approx. 4.7GB)<ul> <li>ollama run deepseek-r1:8b</li> </ul> </li> </ul> <ul> <li>You can now use AI inference services with the DeepSeek model, similar to ChatGPT<ul> <li>ex)</li> </ul> </li> </ul> <p>Q : How to make pizza?</p> <p>A :</p> <p> <p></p> <p>Making pizza can be a fun and rewarding process! Here's a basic guide to making your own pizza at home:</p>"},{"location":"en/user-guide/platform-guide/ollama-llama3/","title":"Ollama User Guide - llama3","text":""},{"location":"en/user-guide/platform-guide/ollama-llama3/#0-overview","title":"0. Overview","text":"<ul> <li>What is Ollama?<ul> <li>A platform designed to execute and manage LLMs (Large Language Models)</li> <li>Enables users to download and test open-source language models in a local environment</li> <li>Key supported language models include:<ul> <li>Llama3<ul> <li>The latest language model developed by Meta, featuring superior natural language processing performance</li> </ul> </li> <li>Phi 3<ul> <li>Developed by Microsoft Research, this model possesses exceptional reasoning and language understanding capabilities</li> </ul> </li> <li>Mistral<ul> <li>Optimized for various linguistic tasks, boasting high-performance efficiency</li> </ul> </li> <li>Gemma 2<ul> <li>Developed by Google, showing strength in natural language processing and generation tasks</li> </ul> </li> <li>CodeGemma<ul> <li>Specialized in code generation and completion, supporting a wide range of programming tasks</li> </ul> </li> </ul> </li> <li>Users can run and manage open-source or custom models via a user-friendly interface using Ollama, including model creation and deployment</li> </ul> </li> </ul>"},{"location":"en/user-guide/platform-guide/ollama-llama3/#1-gcube-platform-workload-service-registration-process","title":"1. gcube Platform Workload Service Registration Process","text":"<ul> <li>Workload Creation and Deployment<ul> <li>Access gcube.ai and navigate to the Workload page ( https://gcube.ai/ko/demand/workload/list )</li> <li>Register a new workload or modify an existing one by entering the required information on the page.</li> </ul> </li> </ul> <ul> <li>Description Overview<ul> <li>Enter the workload name<ul> <li>ex : ollama</li> </ul> </li> </ul> </li> </ul> <ul> <li>Container Overview<ul> <li>Select the storage type and container image<ul> <li>Use the official image provided by Ollama on Docker Hub<ul> <li>Reference URL : https://hub.docker.com/r/ollama/ollama</li> </ul> </li> <li>Storage Type:\u00a0Docker Hub</li> <li>Container Image: ollama/ollama:latest</li> <li>Container ports are automatically populated by checking the metadata (ExposedPorts) of the container image layer. (For Ollama, the port is\u00a011434)</li> </ul> </li> </ul> </li> </ul> <ul> <li>GPU Selection Overview<ul> <li>Select the desired performance specification<ul> <li>Tier1 : High Performance</li> <li>Tier2 : High Reliability</li> <li>Tier3 : Individual Users</li> <li>GPU Memory:\u00a0Filter available GPUs<ul> <li>In this example, select\u00a0Tier 3 RTX 3070</li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li>Option Overview (optional)<ul> <li>Container Command<ul> <li>Corresponds to the\u00a0CMD\u00a0instruction in a Dockerfile (the command to be executed when the container starts)<ul> <li>Format : CMD [\"executable\", \"param1\", \"param2\"] / CMD [\u201cecho\u201c, \u201cHello, world!\u201c]</li> </ul> </li> </ul> </li> <li>Container Environment Variables<ul> <li>Corresponds to the\u00a0ENV\u00a0instruction in a Dockerfile (environment variables to be used inside the container)<ul> <li>\ud615\uc2dd : ENV   / ENV DEF_PORT 9999 <li>Replicas<ul> <li>The number of container instances running simultaneously across different nodes</li> <li>Purpose:<ul> <li>Enhances application reliability and throughput</li> <li>Ensures service continuity even if a specific node fails</li> <li>Reduces latency and improves the developer experience</li> <li>L7 Consistent Hashing Technique:<ul> <li>Routes requests to specific backends based on a key</li> <li>Uses a hashing algorithm to distribute traffic consistently</li> <li>Guarantees that only a minimum number of requests are shifted to other servers when nodes or servers are added or removed</li> </ul> </li> </ul> </li> </ul> </li> <li>CUDA<ul> <li>Select the CUDA version</li> </ul> </li> <li>Shared Memory<ul> <li>Refers to the shared memory area (/dev/shm) provided by Linux systems</li> <li>An area designed for inter-process data sharing (acts as high-speed temporary storage for large-scale data processing)</li> </ul> </li> <ul> <li>Estimated Cost Overview<ul> <li>Displays the maximum hourly price information based on the selected specifications</li> <li>Proceed with registration after reviewing the details<ul> <li>If\u00a0\u2018Instant Deployment\u2019\u00a0is selected, registration and deployment will proceed immediately</li> </ul> </li> </ul> </li> </ul>"},{"location":"en/user-guide/platform-guide/ollama-llama3/#2-how-to-use-gcube-platform-workload-services","title":"2. How to Use gcube Platform Workload Services","text":"<ul> <li>Checking Created Workloads<ul> <li>On the Workload page(https://gcube.ai/ko/demand/workload/list ), click on the\u00a0Workload Name\u00a0to enter the Workload Details page</li> </ul> </li> </ul> <ul> <li>Workload Details Overview<ul> <li>General:\u00a0Workload ID, description, type, status, Service URL, etc.</li> <li>Container:\u00a0Container image, container port, storage type, creation date/time, deployment date/time, termination date/time, etc.</li> <li>Target Specification:\u00a0Target node, GPU memory, GPU information, etc.</li> <li>Options:\u00a0Container command, container environment variables, replicas, minimum CUDA version, shared memory information, etc.</li> <li>Deployment Status:\u00a0Container deployment events, node information, pod details, pod status, container logs,\u00a0container terminal, container SSH access, etc.</li> </ul> </li> </ul> <ul> <li>When Pod Status is \u2018Running\u2019<ul> <li>Click\u00a0\u2018Container SSH\u2019\u00a0to view the Public IP and register access credentials<ul> <li>Verify SSH access information during the credential registration process.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Connect to the container by entering the SSH access information confirmed above into a terminal program (e.g., PuTTY)<ul> <li>Enter the IP address, Port, User ID, and Password</li> </ul> </li> </ul> <ul> <li>Enter the following command in the CLI to download and run the Llama 3 language model (approx. 4.7GB):<ul> <li>ollama run llama3</li> </ul> </li> </ul> <ul> <li>Afterward, utilize Llama 3 for AI inference services similar to ChatGPT.<ul> <li>ex)</li> </ul> </li> </ul> <p>Q : How to make pizza?</p> <p>A : Ingredients:</p> <ul> <li>2 cups of warm water</li> <li>1 tablespoon of sugar</li> <li>2 teaspoons of active dry yeast</li> <li>3 1/2 cups of all-purpose flour</li> <li>1 teaspoon of salt</li> <li>2 tablespoons of olive oil</li> <li>Pizza sauce (homemade or store-bought)</li> <li>Shredded mozzarella cheese (and any other toppings you like!)</li> <li>Fresh basil leaves, chopped (optional)</li> </ul> <p>Instructions:</p> <ol> <li>Make the dough: In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for 5-10 minutes until the yeast is activated and foamy.</li> <li>Add the flour, salt, and olive oil to the bowl. Mix until a shaggy dough forms.</li> <li>Knead the dough: Turn the dough out onto a floured surface and knead for 5-10 minutes, until the dough becomes smooth and elastic.</li> <li>Let it rise: Place the dough in a lightly oiled bowl, cover it with plastic wrap or a damp cloth, and let it rise in a warm place for about an hour, or until it has doubled in size.</li> <li>Punch down the dough: Gently punch down the dough to release any air bubbles.</li> <li>Shape the crust: Use your hands to shape the dough into your desired pizza crust shape (e.g., circle, rectangle, etc.).</li> <li>Roll out the crust: Roll out the crust to your desired thickness (about 1/4 inch is a good starting point).</li> <li>Preheat the oven: Preheat your oven to 425\u00b0F (220\u00b0C) with a baking sheet or pizza stone inside.</li> <li>Add sauce and toppings: Spread a thin layer of pizza sauce over the crust, leaving a small border around the edges. Add your desired toppings, such as shredded mozzarella cheese, pepperoni slices, mushrooms, bell peppers, olives, etc.</li> <li>Bake the pizza: Place the pizza on the preheated baking sheet or stone and bake for 12-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.</li> <li>Add fresh basil (optional): Sprinkle some chopped fresh basil leaves over the top of the pizza for a pop of color and flavor.</li> <li>Enjoy your pizza: Remove the pizza from the oven and let it cool for a few minutes before slicing and serving.</li> </ol> <p>Tips and Variations:</p> <ul> <li>Use a pizza peel or piece of parchment paper to transfer the dough to the preheated baking sheet or stone if you don't have a pizza stone.</li> <li>Try different topping combinations, such as Hawaiian-style with ham and pineapple, or Mediterranean-style with feta cheese and olives.</li> <li>Experiment with various crust flavors by adding herbs, spices, or garlic powder to the dough before kneading.</li> <li>Make mini pizzas using individual portions of dough and toppings for a fun appetizer or snack.</li> </ul> <p>Remember, making pizza is all about having fun and being creative! Don't be afraid to try new things and experiment with different flavors and combinations. Happy baking!</p> <p>ex2)</p> <p></p>"},{"location":"en/user-guide/platform-guide/stable-diffusion/","title":"Stable Diffusion User Guide","text":""},{"location":"en/user-guide/platform-guide/stable-diffusion/#0-prerequisites","title":"0. Prerequisites","text":"<ul> <li> <p>What is Stable Diffusion?</p> <ul> <li>An open-source generative AI model for\u00a0Text-to-Image\u00a0and\u00a0Image-to-Image\u00a0tasks</li> <li>Designed to run on personal computers equipped with GPUs by significantly reducing computing resource requirements</li> <li>Can be installed and executed in a\u00a0'local environment'\u00a0on a private PC, independent of an online connection </li> </ul> </li> <li> <p>Gcube Sign-up and Point Purchase</p> <ul> <li>Sign up on the Gcube official website(http://gcube.ai)</li> </ul> <p></p> <p></p> <ul> <li>Log in and access\u00a0User Mode</li> </ul> <p></p> <ul> <li>Click the\u00a0\u201cPoint Charge\" menu on the left sidebar</li> </ul> <p></p> <ul> <li>Select the desired amount of points to refill, and Choose a payment method and click the\u00a0\u201cPayment\u201d\u00a0button to complete the transaction.</li> </ul> <p></p> </li> </ul>"},{"location":"en/user-guide/platform-guide/stable-diffusion/#1-gcube-platform-stable-diffusion-workload-preparation","title":"1. gcube Platform Stable Diffusion Workload Preparation","text":"<ul> <li> <p>Register a New Workload</p> <ul> <li>After logging in, click the\u00a0\u201cCreate New Workload\u201d\u00a0menu on the left sidebar</li> </ul> <p></p> </li> <li> <ul> <li>Workload Information: Stable Diffusion Setup</li> <li>Description:\u00a0Enter [\u00a0Stable Diffusion\u00a0] in the workload description field</li> </ul> <p></p> <ul> <li>Container: Configure the Container Image for Stable Diffusion<ul> <li>Storage Type:\u00a0Docker Hub</li> <li>Container Image : [ universonic/stable-diffusion-webui ]<ul> <li>Click the \"Verify Image\" button next to the input field. Most of the time, the container port will be automatically populated</li> </ul> </li> <li>Container Port:\u00a08080\u00a0(Automatically configured)</li> </ul> </li> </ul> <p></p> <ul> <li>GPU Selection : Configure the Execution Environment<ul> <li>Target Tier:\u00a0Tier 3\u00a0(Tier for individual users)</li> <li>GPU Memory:\u00a08GB</li> <li>GPU : RTX 3070 X 1 10GB</li> </ul> </li> </ul> <p></p> <ul> <li>Options (Optional): Detailed Container Settings<ul> <li>Replicas:\u00a0Set the number of identical container instances to run in parallel</li> <li>Minimum CUDA Version:\u00a0Specify the minimum CUDA version required by the container</li> <li>Shared Memory:\u00a0Specify the size of the shared memory available to the container</li> <li>\u203b Note : For this guide, we will proceed without configuring any optional settings</li> </ul> </li> </ul> <p></p> <ul> <li>Estimated Cost: Calculate the Expected Usage Fee<ul> <li>Click the checkbox next to\u00a0\u201cImmediate Deploy\u201d\u00a0to deploy immediately upon registration</li> <li>Click the checkbox next to\u00a0\u201cManual Deploy\u201d\u00a0to deploy manually after registration</li> <li>Click the\u00a0\u201cRegister\u201d\u00a0button to complete the workload registration</li> </ul> </li> </ul> <p></p> </li> </ul>"},{"location":"en/user-guide/platform-guide/stable-diffusion/#2-running-the-stable-diffusion-workload-on-gcube-platform","title":"2. Running the Stable Diffusion Workload on Gcube Platform","text":"<ul> <li>Post-Registration Screen</li> </ul> <ul> <li> <p>Verify the information of the created workload</p> <ul> <li>Click on\u00a0\u201cStable Diffusion\u201d\u00a0to view details</li> </ul> <p></p> <ul> <li>Scroll to the bottom of the Workload Details screen to check the\u00a0\u201cDeploy Status\u201d</li> </ul> <p></p> <ul> <li>Ensure the Pod status in the Deployment Status section is\u00a0\u201cRunning\u201d</li> <li>Click the\u00a0\u201cContainer Log\u201d\u00a0button</li> </ul> <p></p> <ul> <li>Installation is complete when you see the message shown in the image within the logs</li> <li>\u203b Note: Installation time may vary depending on container settings and hardware specifications</li> </ul> <p></p> <ul> <li>Return to the Workload Details screen and click the\u00a0\u201cService URL Link\u201d</li> <li>\u203b Note: If you click the link before confirming the container logs, the interface may not display correctly</li> </ul> <p></p> <ul> <li>If the screen below appears, Stable Diffusion has been successfully launched</li> </ul> <p></p> </li> </ul>"},{"location":"en/user-guide/platform-guide/stable-diffusion/#3-stable-diffusion-execution-example-on-gcube-platform","title":"3. Stable Diffusion Execution Example on gcube Platform","text":"<ul> <li> <p>Stable Diffusion Execution Example</p> <ul> <li>Enter the prompt \"A cat in a Hat\" in the\u00a0txt2img\u00a0input field and click the \"Generate\" button</li> </ul> <p></p> <ul> <li>Confirm that an image similar to the one below is generated</li> <li>\u203b Note: Generated images may vary</li> </ul> <p></p> </li> </ul>"},{"location":"en/user-guide/sign-up/sign-up/","title":"Account Creation","text":""},{"location":"en/user-guide/sign-up/sign-up/#sign-up-login-instructions","title":"Sign Up &amp; Login Instructions","text":"<p>1. Click the \"Login\" button located at the top right corner of the homepage.</p> <p></p> <p>2. Click the \"Sign Up\" button at the bottom of the login screen.</p> <p></p> <p>3. Proceed with a simple sign-up using your preferred account: Google or Microsoft.</p> <p></p> <p>4. Select the account you wish to use, agree to the Terms and Conditions, and enter your user information to complete the registration. </p> <p></p> <p>5. Return to the login page and select your registered email account to log in. </p> <p></p> <p>6. Once logged in, you can access all of gcube\u2019s services.  Use the Mode Toggle button at the top of the left-hand menu to switch between Workload Deployment Mode (for users) and Node Provider Mode (for suppliers). </p> <p>Go to GCUBE Login Page</p>"},{"location":"en/user-guide/workload/deploy-workload/","title":"Workload Deployment","text":"<p>Once a workload is registered, you can begin utilizing resources by deploying it. </p> <p></p> <p>1. Locate the registered workload you wish to deploy and click the \"Deploy\" button. Click the \"Confirm\" button in the pop-up window. </p> <p></p> <p>2. Observe the workload status in the top-right corner change from \"Finished\" to \"Running.\"   Once the status changes, the Service URL will be activated. (Please note that this process may take several minutes.)</p>"},{"location":"en/user-guide/workload/example-workload/","title":"Workload Registration Example","text":"<p>This document provides examples of workload registration for deep learning development  For detailed instructions on the actual registration process, please refer to the Register New Workload documentation. </p>"},{"location":"en/user-guide/workload/example-workload/#overview","title":"Overview","text":"<p>The <code>koojy717/lora-tuning-blackwell:1.01</code> image contains essential frameworks and tools required for deep learning development.</p>"},{"location":"en/user-guide/workload/example-workload/#key-components","title":"Key Components","text":"<ul> <li>PyTorch 2.7.0 (Supports CUDA 12.8)</li> <li>TensorFlow 2.12.0</li> <li>Transformers 4.28.0</li> <li>PEFT 0.3.0</li> <li>Jupyter Notebook/Lab environment</li> <li>System Management Tools (net-tools, ping, traceroute)</li> </ul> <p>\u203b Note: PyTorch version 2.7.0 is a nightly build rapidly developed for NVIDIA\u2019s Blackwell architecture; as such, it may not exhibit consistent performance.</p> <p>If you prefer a more stable, previous version of PyTorch, please use the<code>koojy717/lora-tuning:1.02</code> image, which includes Pytorch 2.01(CUDA 11.8 \uc9c0\uc6d0).</p>"},{"location":"en/user-guide/workload/example-workload/#workload-configuration-guide","title":"Workload Configuration Guide","text":""},{"location":"en/user-guide/workload/example-workload/#container-image","title":"Container Image","text":"<pre><code>=== \"GitHub\"\n    ```\n    data-alliance/lora-tuning-blackwell:1.01\n    ```\n\n=== \"Docker Hub\"\n    ```\n    koojy717/lora-tuning-blackwell:1.01\n    ```\n\n=== \"Lower Pytorch Version Docker Hub\"\n        ```\n        koojy717/lora-tuning:1.02\n        ```\n</code></pre>"},{"location":"en/user-guide/workload/example-workload/#target-specifications","title":"Target Specifications","text":"<p>Recommended settings based on workload scale:</p> Target Tier GPU Memory Usage Large-scale Training Tier 1 (A100, H100) 40GB+ Large-scale model training, requiring high performance. Mid-scale Experiment Tier 2 (\uc804\uc6a9 \uc11c\ubc84) 20GB General model development and mid-scale experiments. Dev / Testing Tier 3 (PC\ubc29, \uac1c\uc778) 10GB Code development and small-scale experiments. <p>\u26a1 For detailed instructions on how to register a workload, please refer to the Register New Workload page.</p>"},{"location":"en/user-guide/workload/example-workload/#getting-started-with-jupyter-notebook","title":"Getting Started with Jupyter Notebook","text":"<p>After the workload has been successfully created, access the environment using the Service URL provided on the workload details page.</p> <p>You can verify your development environment and perform basic computational tests by creating a new notebook in the default working directory.</p>"},{"location":"en/user-guide/workload/example-workload/#1-verifying-the-environment","title":"1. Verifying the Environment","text":"<p>Execution Code:</p> <pre><code>import torch\nimport tensorflow as tf\nimport transformers\n# Check Version print(f\"PyTorch: {torch.__version__}\")\nprint(f\"TensorFlow: {tf.__version__}\")\nprint(f\"Transformers: {transformers.__version__}\")\n# Check GPU print(f\"PyTorch GPU: {torch.cuda.is_available()}\")\nprint(f\"TensorFlow GPU: {tf.config.list_physical_devices('GPU')}\")\n</code></pre> <p>Expected Results:</p> <pre><code>PyTorch: 2.0.1+cu118\nTensorFlow: 2.12.0\nTransformers: 4.28.0\nPyTorch GPU: True\nTensorFlow GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n</code></pre>"},{"location":"en/user-guide/workload/example-workload/#2-pytorch-environment-test","title":"2. PyTorch Environment Test","text":"<p>Execution Code:</p> <pre><code>import torch\nif torch.cuda.is_available():\n    # GPU Information    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    # Matrix Operation Test    a = torch.tensor([[1.0, 2.0], [3.0, 4.0]]).cuda()\n    b = torch.tensor([[5.0, 6.0], [7.0, 8.0]]).cuda()\n    # Matrix Multiplication    c = torch.matmul(a, b)\n    print(\"\\nMatrix A:\")\n    print(a.cpu().numpy())\n    print(\"\\nMatrix B:\")\n    print(b.cpu().numpy())\n    print(\"\\nMatrix Multiplication Result (A \u00d7 B):\")\n    print(c.cpu().numpy())\n</code></pre> <p>Expected Results:</p> <pre><code>GPU: NVIDIA GeForce RTX 3060\nMemory: 12.88 GB\n\nMatrix A:\n[[1. 2.]\n [3. 4.]]\n\nMatrix B:\n[[5. 6.]\n [7. 8.]]\n\nMatrix Multiplication Result (A \u00d7 B):\n[[19. 22.]\n [43. 50.]]\n</code></pre> <p>\ud83d\udd17 View More PyTorch Tutorials</p>"},{"location":"en/user-guide/workload/example-workload/#3-tensorflow-environment-test","title":"3. TensorFlow Environment Test","text":"<p>Execution Code:</p> <pre><code>import tensorflow as tf\nif tf.config.list_physical_devices('GPU'):\n    # GPU Meomory Configuration   gpus = tf.config.experimental.list_physical_devices('GPU')\n    tf.config.experimental.set_memory_growth(gpus[0], True)\n    # Simple Computation Test    with tf.device('/GPU:0'):\n        x = tf.random.normal([1000, 1000])\n        y = tf.matmul(x, x)\n        print(\"GPU Computation Test Completed Successfully\")\n</code></pre> <p>Expected Results:</p> <pre><code>GPU Computation Test Completed Successfully\n</code></pre> <p>\ud83d\udd17 Getting Started with TensorFlow</p>"},{"location":"en/user-guide/workload/example-workload/#4-transformers-environment-test","title":"4. Transformers Environment Test","text":"<p>Execution Code:</p> <pre><code>from transformers import AutoModel, AutoTokenizer\nmodel_name = \"bert-base-uncased\"tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\nif torch.cuda.is_available():\n    model = model.cuda()\n    print(\"Model successfully loaded onto GPU\")\n</code></pre> <p>Expected Results:</p> <pre><code>Model successfully loaded onto GPU\n</code></pre> <p>\ud83d\udd17 View More Transformers Tutorials</p> <p>Warning</p> <p>Please be aware that all data and environmental settings currently in use will not be saved when the workload is terminated. Training data and results can be stored using a persistent volume (PV).</p>"},{"location":"en/user-guide/workload/example-workload/#references-resources","title":"References &amp; Resources","text":"<ul> <li>PyTorch Documentation</li> <li>TensorFlow GPU Guide</li> <li>Transformers Documentation</li> </ul>"},{"location":"en/user-guide/workload/example-workload/#contact-support","title":"Contact Support","text":"<p>If you encounter any issues or require further assistance, please contact the gcube Support Team \ud83d\udce7 gcube.ai@data-alliance.com</p>"},{"location":"en/user-guide/workload/","title":"Index","text":""},{"location":"en/user-guide/workload/#todo-translate-this-page-to-english","title":"TODO: Translate this page to English","text":""},{"location":"en/user-guide/workload/monitor-workload/","title":"Workload Monitoring","text":"<p>You can track and manage the resource usage of your registered workloads through the \"Monitoring\" feature.</p> <p></p> <p>1. Click the \"Monitoring\" button located at the bottom right of the workload item. </p> <p>2. A real-time monitoring dashboard will be displayed, allowing you to track the following metrics: - GPU Utilization (%)  - GPU Memory Usage (MB)  - CPU Utilization (%)  - Memory Usage (MB)  - Network Inbound Packets (Kbps)  - Network Outbound Packets (Kbps) </p> <p></p>"},{"location":"en/user-guide/workload/profile-settings/","title":"Profile Setup","text":"<p>You can configure your account information through the Profile Settings menu. </p> <p></p> <p>1. Click the arrow next to your name \u2192 Click \"My Profile\".</p> <p></p> <p>2. As shown in the screen above, you can view and verify your \"User Information\".</p> <p></p> <p>3. Click \"Edit Profile\" \u2192 Modify the desired information in the profile update pop-up window, then click the \"Edit\" button to complete the profile modification.</p>"},{"location":"en/user-guide/workload/pv-user-guide/","title":"Storage Management Setup","text":"<p>Through Storage Management, you can configure container image repository and backup data storage information. </p> <p></p> <p>1. Click the arrow next to your name \u2192 Click\u00a0\u201cStorage Management\u201d </p> <p></p> <p>2. As shown in the screen above, you can configure \u201cRegister Authentication\u201d and \u201cConnect Personal Backup Storage.\u201d </p> <ul> <li>Register Authentication:\u00a0To use container images from a private repository when setting up a workload, you must register your repository credentials to access the image information.</li> <li>Connect Personal Backup Storage:\u00a0You can connect and save your trained data to a personal storage space.   </li> </ul> <p></p> <p>3. Register Authentication: Click\u00a0\u201c+ Register Authentication\u201d\u00a0\u2192 Select the\u00a0\u201cRepository\u201d\u00a0provider \u2192 Enter the required information \u2192 Click the\u00a0\u201cRegister\u201d\u00a0button to complete the process. </p> <p></p> <p>4. Click the\u00a0\u201cEdit\u201d\u00a0button for user credentials \u2192 Modify the information in the pop-up window \u2192 Click the\u00a0\u201cRegister\u201d\u00a0button to complete the modification. </p> <p></p> <p>5. Connect Personal Backup Storage: Click\u00a0\u201c+ Connect Personal Backup Storage\u201d\u00a0\u2192 Select the\u00a0\u201cType\u201d\u00a0in the storage registration pop-up \u2192 Enter the required information \u2192 Click the\u00a0\u201cRegister\u201d\u00a0button to complete the process.  6. When registering storage information, set a\u00a0Storage Alias\u00a0to be displayed in the list and specify the\u00a0Folder Path\u00a0within the storage to be linked before saving.    [Example: \u201c/data/data\u201d is the path where Dropbox is mounted inside the container. You can read and write files at this location.] </p> <p>The access method and capacity can be adjusted as needed.</p> <ul> <li> <p>dropbox </p> </li> <li> <p>aws s3 [For AWS storage, you must enter the IAM access key, secret access key, and the bucket region.]   </p> </li> </ul>"},{"location":"en/user-guide/workload/register-new-workload/","title":"Register New Workload","text":"<p>To utilize Gcube\u2019s GPU resources, you must complete the 'Register New Workload' process. </p> <p></p> <p>1. In Deploy mode, click the \"Create New Workload menu.</p> <p>2. Enter the required information into each field on the Workload Registration page.</p> <p></p> <ul> <li>Workload Description: Provide a brief summary of the workload's purpose and key features.</li> </ul>"},{"location":"en/user-guide/workload/register-new-workload/#_1","title":"\ucee8\ud14c\uc774\ub108","text":"<ul> <li>Storage Type: Select the platform where your container image is stored.</li> <li>Container Image: Enter the container image URL, referring to the input format for each storage type provided below.</li> <li>Container Port: The network port used by the container. This will be automatically populated during image verification.</li> </ul> <pre><code>=== \"Docker Hub\"\n    ```\n    username/repository:tag\n    ```\n    \uc608\uc2dc: `ollama/ollama:latest`\n\n=== \"NVIDIA NGC\"\n    ```\n    nvcr.io/nvidia/repository:tag\n    ```\n    \uc608\uc2dc: `nvcr.io/nvidia/cuda:12.0.0-base-ubuntu22.04`\n\n=== \"GitHub\"\n    ```\n    ghcr.io/owner/repository:tag\n    ```\n    \uc608\uc2dc: `ghcr.io/organization/app:1.0`\n\n=== \"Red Hat Quay\"\n    ```\n    quay.io/namespace/repository:tag\n    ```\n    \uc608\uc2dc: `quay.io/redhat/ubi8:latest`\n\n=== \"Hugging Face\"\n    ```\n    registry.hf.space/username/repository:tag\n    ```\n    \uc608\uc2dc: `registry.hf.space/username/model-server:v1`\n</code></pre> <p>Example:</p> <pre><code>ollama/ollama:latest\n</code></pre> <p>Image Verification Check</p> <ul> <li>If a valid image URL is entered, a green checkmark will appear and the port will be automatically populated.</li> <li> <p>If the image is invalid, a red checkmark will appear and the port will not be entered.</p> </li> <li> <p>Container Command: Sets the <code>CMD</code> item from the Dockerfile (the command to be executed when the container starts).</p> </li> <li>Container Environment Variables: Sets the <code>ENV</code> items from the Dockerfile (environment variables to be used inside the container).</li> <li>Personal Storage: Set up personal storage information to back up trained data. Personal storage can be used after being registered through \"Storage Management.\"</li> <li>Storage Authentication: Check this if you are using a container image from a private repository. This is only available if the private storage authentication has been completed via \"Storage Management.\"</li> </ul>"},{"location":"en/user-guide/workload/register-new-workload/#gpu","title":"GPU \uc120\ud0dd","text":"<p>You can select the target node to be used for your workload. By enabling the 'View Available GPUs Only' toggle, you can filter the list to show only GPUs that are currently ready for use. Additionally, you can search for and filter GPUs based on Model Name, vRAM, and Cost.</p> <ul> <li>GPU Model Name: When you enter or select a GPU model, the available GPU resource items for that specific model will be displayed.<ul> <li><code>Tier 1</code> : Cloud Service Providers (CSPs)</li> <li><code>Tier 2</code> : Dedicated Servers (Data Centers)</li> <li><code>Tier 3</code> : Internet Cafes (PC Bangs) and Individuals</li> </ul> </li> <li>GPU Memory: Set the required GPU memory capacity. The available GPUs will be filtered according to the value you set.</li> <li>Cost: Enter the minimum and maximum hourly cost to display GPU models that fall within that price range. This allows you to select a GPU model that fits your budget.</li> </ul>"},{"location":"en/user-guide/workload/register-new-workload/#_2","title":"\uc635\uc158","text":"<ul> <li>Replica: Specifies the number of container instances to be deployed.</li> <li>Minimum CUDA Version: Specifies the required version of CUDA.</li> <li>Shared Memory: Sets the size of the area designed for data sharing between processes.</li> </ul>"},{"location":"en/user-guide/workload/register-new-workload/#register","title":"Register","text":"<ul> <li>Check the total estimated cost, choose whether to deploy immediately, and then click the 'Register' button.</li> </ul> <p>3. The workload has been created and can now be viewed in the list.</p>"},{"location":"en/user-guide/workload/terminate-workload/","title":"Terminate Workload","text":"<p>To stop a workload, click the 'Stop' button. </p> <p></p> <p>1.To terminate a workload, click the 'Stop' button on the deployed item, then click 'Confirm'. </p> <p></p> <p>2. The workload status in the top right changes from 'Running' to 'Finished', and the service is discontinued. </p>  \u26a0\ufe0f  Please note that if a backup storage is not configured, your work data and environment will not be saved upon termination. (Data can be saved if you have configured personal storage settings when creating a workload after setting up the link in\u00a0Storage Management &gt; Backup Data Personal Storage.)"},{"location":"en/user-guide/workload/workload-expenses/","title":"Workload Usage History","text":"<p>You can check the detailed breakdown of points consumed based on your workload activity through the \"Usage Details\" feature. </p> <p></p> <p>1. Click the 'Usage Details' button located at the bottom right of the workload item. </p> <p></p> <p>2. You can check the points consumed and the total usage fees for each workload item. </p> <p></p> <p>3. By clicking the 'Details' button, you can check the granular billing breakdown by individual pod or usage duration.</p>"},{"location":"en/user-guide/workload/workload-home/","title":"Home","text":"<p>The Home menu allows you to monitor the overall cluster status of the current workloads.</p> <p></p> <p>1. By clicking the \"Home\" menu on the left sidebar, you can view your total earned points, along with a summary and real-time status of your active workloads.</p> <p></p> <p>2. You can view the overall operational summary of your created workloads, and by clicking on an individual workload description, you can access detailed information for each specific task.</p>"}]}