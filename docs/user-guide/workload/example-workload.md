# ì›Œí¬ë¡œë“œ ë“±ë¡ ì˜ˆì‹œ

ì´ ë¬¸ì„œëŠ” ë”¥ëŸ¬ë‹ ê°œë°œì„ ìœ„í•œ ì›Œí¬ë¡œë“œ ë“±ë¡ ì˜ˆì‹œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.
ì‹¤ì œ ë“±ë¡ ë°©ë²•ì€ [ìƒˆ ì›Œí¬ë¡œë“œ ë“±ë¡](https://data-alliance.github.io/gai-platform-docs/user-guide/workload/register-new-workload/) ë¬¸ì„œë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”.


## ê°œìš”
`data-alliance/lora-tuning:1.02` ì´ë¯¸ì§€ëŠ” ë”¥ëŸ¬ë‹ ê°œë°œì— í•„ìš”í•œ ì£¼ìš” í”„ë ˆì„ì›Œí¬ì™€ ë„êµ¬ë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ
- PyTorch 2.0.1 (CUDA 11.8 ì§€ì›)
- TensorFlow 2.12.0
- Transformers 4.28.0
- PEFT 0.3.0
- Jupyter Notebook/Lab í™˜ê²½
- ì‹œìŠ¤í…œ ê´€ë¦¬ ë„êµ¬ (net-tools, ping, traceroute)

- - -

## ì›Œí¬ë¡œë“œ ì„¤ì • ê°€ì´ë“œ

### ì»¨í…Œì´ë„ˆ ì„¤ì •
![input-workload-description](img/register-new-workload/03_workload_container.png) <br>

- **ì €ì¥ì†Œ ìœ í˜•**: ê¹ƒí—ˆë¸Œ <br>

- **ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€**: `data-alliance/lora-tuning:1.02` <br>

- **ì»¨í…Œì´ë„ˆ í¬íŠ¸**: 8888 (ì´ë¯¸ì§€ ê²€ì¦ ì‹œ ìë™ì…ë ¥ë¨) <br>


### ëª©ì ìŠ¤í™ ì„¤ì •
ì‘ì—… ê·œëª¨ì— ë”°ë¥¸ ê¶Œì¥ ì„¤ì •:

| ëª©ì  | Tier | GPU ë©”ëª¨ë¦¬ | ìš©ë„ |
|------|------|------------|-------|
| ëŒ€ê·œëª¨ í•™ìŠµ | Tier 1 (A100, H100) | 40GB+ | ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµ, ë†’ì€ ì„±ëŠ¥ í•„ìš” ì‹œ |
| ì¤‘ê·œëª¨ ì‹¤í—˜ | Tier 2 (ì „ìš© ì„œë²„) | 20GB | ì¼ë°˜ì ì¸ ëª¨ë¸ ê°œë°œ, ì¤‘ê·œëª¨ ì‹¤í—˜ |
| ê°œë°œ/í…ŒìŠ¤íŠ¸ | Tier 3 (PCë°©, ê°œì¸) | 10GB | ì½”ë“œ ê°œë°œ, ì†Œê·œëª¨ ì‹¤í—˜ |

âš¡ ìì„¸í•œ ì›Œí¬ë¡œë“œ ë“±ë¡ ë°©ë²•ì€ [ìƒˆ ì›Œí¬ë¡œë“œ ë“±ë¡](https://data-alliance.github.io/gai-platform-docs/user-guide/workload/register-new-workload/) í˜ì´ì§€ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”.

- - -

## Jupyter Notebook ì‹œì‘í•˜ê¸°
ì›Œí¬ë¡œë“œ ìƒì„± ì™„ë£Œ í›„, ìƒì„¸ í˜ì´ì§€ì—ì„œ ì œê³µë˜ëŠ” Service URLë¡œ ì ‘ì†í•˜ì„¸ìš”. <br>
ê¸°ë³¸ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ ìƒˆ ë…¸íŠ¸ë¶ì„ ìƒì„±í•˜ì—¬ ê°œë°œ í™˜ê²½ì„ í™•ì¸í•˜ê³ , ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1. ê¸°ë³¸ í™˜ê²½ í™•ì¸
ì‹¤í–‰ ì½”ë“œ: 
```python
import torch
import tensorflow as tf
import transformers

# ë²„ì „ í™•ì¸
print(f"PyTorch: {torch.__version__}")
print(f"TensorFlow: {tf.__version__}")
print(f"Transformers: {transformers.__version__}")

# GPU í™•ì¸
print(f"PyTorch GPU: {torch.cuda.is_available()}")
print(f"TensorFlow GPU: {tf.config.list_physical_devices('GPU')}")
```
ê²°ê³¼:
```
PyTorch: 2.0.1+cu118
TensorFlow: 2.12.0
Transformers: 4.28.0
PyTorch GPU: True
TensorFlow GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
```

### 2. PyTorch í™˜ê²½ í…ŒìŠ¤íŠ¸
ì‹¤í–‰ ì½”ë“œ: 
```python
import torch

if torch.cuda.is_available():
    # GPU ì •ë³´
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # í–‰ë ¬ ì—°ì‚° í…ŒìŠ¤íŠ¸
    a = torch.tensor([[1.0, 2.0], [3.0, 4.0]]).cuda()
    b = torch.tensor([[5.0, 6.0], [7.0, 8.0]]).cuda()
    
    # í–‰ë ¬ ê³± ì—°ì‚°
    c = torch.matmul(a, b)
    print("\ní–‰ë ¬ A:")
    print(a.cpu().numpy())
    print("\ní–‰ë ¬ B:")
    print(b.cpu().numpy())
    print("\ní–‰ë ¬ ê³± ê²°ê³¼ (A Ã— B):")
    print(c.cpu().numpy())
```
ê²°ê³¼: 
```
GPU: NVIDIA GeForce RTX 3060
ë©”ëª¨ë¦¬: 12.88 GB

í–‰ë ¬ A:
[[1. 2.]
 [3. 4.]]

í–‰ë ¬ B:
[[5. 6.]
 [7. 8.]]

í–‰ë ¬ ê³± ê²°ê³¼ (A Ã— B):
[[19. 22.]
 [43. 50.]]
```
ğŸ”— [PyTorch íŠœí† ë¦¬ì–¼ ë” ë³´ê¸°](https://pytorch.org/tutorials/beginner/basics/intro.html)

### 3. TensorFlow í™˜ê²½ í…ŒìŠ¤íŠ¸
ì‹¤í–‰ ì½”ë“œ: 
```python
import tensorflow as tf

if tf.config.list_physical_devices('GPU'):
    # GPU ë©”ëª¨ë¦¬ ì„¤ì •
    gpus = tf.config.experimental.list_physical_devices('GPU')
    tf.config.experimental.set_memory_growth(gpus[0], True)
    
    # ê°„ë‹¨í•œ ì—°ì‚° í…ŒìŠ¤íŠ¸
    with tf.device('/GPU:0'):
        x = tf.random.normal([1000, 1000])
        y = tf.matmul(x, x)
        print("GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
```
ê²°ê³¼:
```
GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì™„ë£Œ
```
ğŸ”— [TensorFlow ì‹œì‘í•˜ê¸°](https://www.tensorflow.org/tutorials/quickstart/beginner)

### 4. Transformers í™˜ê²½ í…ŒìŠ¤íŠ¸
ì‹¤í–‰ ì½”ë“œ: 
```python
from transformers import AutoModel, AutoTokenizer

model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

if torch.cuda.is_available():
    model = model.cuda()
    print("ëª¨ë¸ GPU ë¡œë“œ ì™„ë£Œ")
```
ê²°ê³¼:
```
ëª¨ë¸ GPU ë¡œë“œ ì™„ë£Œ
```
ğŸ”— [Transformers íŠœí† ë¦¬ì–¼ ë” ë³´ê¸°](https://huggingface.co/docs/transformers/training)

- - -

!!! Warning  
      ì›Œí¬ë¡œë“œ ì¢…ë£Œ ì‹œ, ì‘ì—… ì¤‘ì´ë˜ ë°ì´í„° ë° í™˜ê²½ì€ **ì €ì¥ë˜ì§€ ì•Šìœ¼ë‹ˆ** ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.   
      (í–¥í›„ ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ë¥¼ ì´ìš©í•˜ì—¬ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ ì—…ë°ì´íŠ¸ í•  ì˜ˆì •ì…ë‹ˆë‹¤.)


## ì°¸ê³  ìë£Œ
- [PyTorch ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)
- [TensorFlow GPU ê°€ì´ë“œ](https://www.tensorflow.org/guide/gpu)
- [Transformers ë¬¸ì„œ](https://huggingface.co/docs/transformers)

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì¶”ê°€ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° gcube ì§€ì›íŒ€(gcube.ai@data-alliance.com)ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”.


